"""
æ–°æ—§è®°å¿†ç³»ç»Ÿå¯¹æ¯”æµ‹è¯•
åŒ…å«æ•°æ®å‡†å¤‡ã€æ€§èƒ½æµ‹è¯•ã€åŠŸèƒ½å¯¹æ¯”ç­‰
"""

import os
import sys
import time
import asyncio
import random
from typing import List, Dict, Any

sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from core.memory.enhanced_pipeline import create_enhanced_pipeline

def prepare_test_data() -> List[Dict[str, Any]]:
    """å‡†å¤‡ä¸°å¯Œçš„æµ‹è¯•æ•°æ®"""
    test_data = []
    
    # ç”¨æˆ·åŸºæœ¬ä¿¡æ¯
    basic_info = [
        {"content": "æˆ‘å«å¼ å°æ˜ï¼Œä»Šå¹´25å²", "role": "user", "importance": 9.0, "type": "personal"},
        {"content": "æˆ‘æ˜¯ä¸€åè½¯ä»¶å·¥ç¨‹å¸ˆï¼Œåœ¨åŒ—äº¬å·¥ä½œ", "role": "user", "importance": 8.5, "type": "personal"},
        {"content": "æˆ‘çš„ç”Ÿæ—¥æ˜¯1998å¹´5æœˆ15æ—¥", "role": "user", "importance": 9.5, "type": "personal"},
        {"content": "æˆ‘ä½åœ¨æµ·æ·€åŒºä¸­å…³æ‘é™„è¿‘", "role": "user", "importance": 8.0, "type": "personal"},
        {"content": "æˆ‘çš„è”ç³»æ–¹å¼æ˜¯138****1234", "role": "user", "importance": 9.0, "type": "personal"},
    ]
    
    # å·¥ä½œç›¸å…³
    work_related = [
        {"content": "æˆ‘åœ¨ä¸€å®¶AIå…¬å¸å·¥ä½œï¼Œä¸»è¦åšPythonå¼€å‘", "role": "user", "importance": 7.5, "type": "work"},
        {"content": "æœ€è¿‘åœ¨å­¦ä¹ æ·±åº¦å­¦ä¹ ï¼Œç‰¹åˆ«æ˜¯Transformeræ¨¡å‹", "role": "user", "importance": 7.0, "type": "work"},
        {"content": "æˆ‘ä»¬å›¢é˜Ÿæ­£åœ¨å¼€å‘ä¸€ä¸ªèŠå¤©æœºå™¨äººé¡¹ç›®", "role": "user", "importance": 6.5, "type": "work"},
        {"content": "ä¸‹å‘¨è¦å¼€é¡¹ç›®è¯„å®¡ä¼šè®®", "role": "user", "importance": 6.0, "type": "work"},
        {"content": "æˆ‘çš„è€æ¿å¯¹æˆ‘çš„å·¥ä½œå¾ˆæ»¡æ„", "role": "user", "importance": 5.5, "type": "work"},
    ]
    
    # å…´è¶£çˆ±å¥½
    hobbies = [
        {"content": "æˆ‘å–œæ¬¢æ‰“ç¯®çƒï¼Œç»å¸¸å‘¨æœ«å»æ‰“çƒ", "role": "user", "importance": 6.0, "type": "hobby"},
        {"content": "æˆ‘å¾ˆå–œæ¬¢å¬éŸ³ä¹ï¼Œç‰¹åˆ«æ˜¯æµè¡ŒéŸ³ä¹", "role": "user", "importance": 5.5, "type": "hobby"},
        {"content": "æˆ‘å–œæ¬¢çœ‹ç§‘å¹»ç”µå½±ï¼Œæœ€å–œæ¬¢ã€Šæ˜Ÿé™…ç©¿è¶Šã€‹", "role": "user", "importance": 5.0, "type": "hobby"},
        {"content": "æˆ‘åœ¨å­¦å‰ä»–ï¼Œå·²ç»å­¦äº†åŠå¹´äº†", "role": "user", "importance": 5.5, "type": "hobby"},
        {"content": "æˆ‘å–œæ¬¢æ—…æ¸¸ï¼Œå»å¹´å»äº†æ—¥æœ¬", "role": "user", "importance": 5.0, "type": "hobby"},
    ]
    
    # æ—¥å¸¸å¯¹è¯
    daily_conversations = [
        {"content": "ä»Šå¤©å¤©æ°”çœŸä¸é”™ï¼Œé€‚åˆå‡ºå»èµ°èµ°", "role": "user", "importance": 3.0, "type": "daily"},
        {"content": "æˆ‘ä»Šå¤©æ—©ä¸Šåƒäº†åŒ…å­å’Œè±†æµ†", "role": "user", "importance": 2.0, "type": "daily"},
        {"content": "åœ°é“ä»Šå¤©åˆå»¶è¯¯äº†ï¼ŒçœŸçƒ¦äºº", "role": "user", "importance": 2.5, "type": "daily"},
        {"content": "ä¸­åˆå’ŒåŒäº‹ä¸€èµ·åƒäº†å·èœ", "role": "user", "importance": 3.0, "type": "daily"},
        {"content": "æ™šä¸Šè¦å’Œæœ‹å‹çœ‹ç”µå½±", "role": "user", "importance": 4.0, "type": "daily"},
    ]
    
    # AIåŠ©æ‰‹å›å¤
    ai_responses = [
        {"content": "ä½ å¥½å¼ å°æ˜ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ï¼Œæˆ‘æ˜¯ä½ çš„AIåŠ©æ‰‹", "role": "assistant", "importance": 7.0, "type": "response"},
        {"content": "è½¯ä»¶å·¥ç¨‹å¸ˆæ˜¯ä¸ªå¾ˆæœ‰å‰é€”çš„èŒä¸šï¼Œä½ åœ¨å“ªå®¶å…¬å¸å·¥ä½œå‘¢ï¼Ÿ", "role": "assistant", "importance": 6.0, "type": "response"},
        {"content": "ç”Ÿæ—¥å¿«è¦åˆ°äº†å‘¢ï¼Œæœ‰ä»€ä¹ˆåº†ç¥è®¡åˆ’å—ï¼Ÿ", "role": "assistant", "importance": 6.5, "type": "response"},
        {"content": "ä¸­å…³æ‘æ˜¯ä¸ªç§‘æŠ€æ°›å›´å¾ˆæµ“çš„åœ°æ–¹ï¼Œé‚£é‡Œæœ‰å¾ˆå¤šäº’è”ç½‘å…¬å¸", "role": "assistant", "importance": 5.0, "type": "response"},
        {"content": "æ·±åº¦å­¦ä¹ ç¡®å®å¾ˆæœ‰è¶£ï¼ŒTransformeræ˜¯ç°åœ¨æœ€çƒ­é—¨çš„æ¨¡å‹ä¹‹ä¸€", "role": "assistant", "importance": 6.0, "type": "response"},
    ]
    
    # é‡è¦äº‹ä»¶
    important_events = [
        {"content": "æ˜å¤©è¦å‚åŠ å…¬å¸çš„æŠ€æœ¯åˆ†äº«ä¼šï¼Œæˆ‘è¦åšå…³äºPythonçš„æ¼”è®²", "role": "user", "importance": 8.0, "type": "event"},
        {"content": "ä¸‹ä¸ªæœˆè¦æ¬å®¶åˆ°æ–°çš„å…¬å¯“", "role": "user", "importance": 7.5, "type": "event"},
        {"content": "æˆ‘æŠ¥åäº†ä¸€ä¸ªæœºå™¨å­¦ä¹ çš„åŸ¹è®­è¯¾ç¨‹", "role": "user", "importance": 7.0, "type": "event"},
        {"content": "å‘¨æœ«è¦å’Œå¥³æœ‹å‹å»çœ‹æ¼”å”±ä¼š", "role": "user", "importance": 6.5, "type": "event"},
        {"content": "æˆ‘çš„é¡¹ç›®è·å¾—äº†å…¬å¸çš„åˆ›æ–°å¥–", "role": "user", "importance": 8.5, "type": "event"},
    ]
    
    # åˆå¹¶æ‰€æœ‰æ•°æ®
    test_data.extend(basic_info)
    test_data.extend(work_related)
    test_data.extend(hobbies)
    test_data.extend(daily_conversations)
    test_data.extend(ai_responses)
    test_data.extend(important_events)
    
    # æ·»åŠ æ—¶é—´æˆ³
    current_time = time.time()
    for i, data in enumerate(test_data):
        # æ¨¡æ‹Ÿä¸åŒæ—¶é—´çš„å¯¹è¯ï¼Œè¶Šé‡è¦çš„è®°å¿†è¶Š"æ–°é²œ"
        time_offset = random.randint(0, 30 * 24 * 3600)  # æœ€å¤š30å¤©å‰
        if data["importance"] >= 8.0:
            time_offset = random.randint(0, 3 * 24 * 3600)  # é‡è¦è®°å¿†åœ¨3å¤©å†…
        elif data["importance"] >= 6.0:
            time_offset = random.randint(0, 7 * 24 * 3600)  # ä¸­ç­‰é‡è¦è®°å¿†åœ¨7å¤©å†…
        
        data["timestamp"] = current_time - time_offset
        data["id"] = f"test_memory_{i}"
    
    return test_data

def populate_enhanced_system(test_data: List[Dict[str, Any]]):
    """å¡«å……å¢å¼ºç‰ˆç³»ç»Ÿçš„æµ‹è¯•æ•°æ®"""
    print("ğŸ“š æ­£åœ¨å¡«å……å¢å¼ºç‰ˆç³»ç»Ÿæµ‹è¯•æ•°æ®...")
    
    memory = create_enhanced_pipeline(advanced=False)
    
    for data in test_data:
        memory.memory_adapter.store_memory(
            content=data["content"],
            role=data["role"],
            importance=data["importance"],
            memory_type=data["type"],
            metadata={
                "timestamp": data["timestamp"],
                "test_id": data["id"]
            }
        )
    
    print(f"âœ… å·²å­˜å‚¨ {len(test_data)} æ¡æµ‹è¯•è®°å¿†åˆ°å¢å¼ºç‰ˆç³»ç»Ÿ")
    return memory

def populate_original_system(test_data: List[Dict[str, Any]]):
    """å°è¯•å¡«å……åŸç³»ç»Ÿçš„æµ‹è¯•æ•°æ®"""
    print("ğŸ“š æ­£åœ¨å°è¯•å¡«å……åŸç³»ç»Ÿæµ‹è¯•æ•°æ®...")
    
    try:
        from core.memory.pipeline import MemoryPipeline
        memory = MemoryPipeline()
        
        # ä½¿ç”¨åŸç³»ç»Ÿçš„å­˜å‚¨æ–¹æ³•
        success_count = 0
        for data in test_data:
            try:
                # æ¨¡æ‹Ÿç”¨æˆ·è¾“å…¥å’ŒAIå“åº”çš„å¯¹è¯å­˜å‚¨
                if data["role"] == "user":
                    ai_response = f"æˆ‘ç†è§£äº†ï¼Œå…³äº{data['content'][:20]}..."
                    memory.store_interaction(data["content"], ai_response)
                    success_count += 1
            except Exception as e:
                continue
        
        print(f"âœ… å·²å­˜å‚¨ {success_count} æ¡è®°å¿†åˆ°åŸç³»ç»Ÿ")
        return memory
        
    except Exception as e:
        print(f"âŒ åŸç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
        return None

def test_query_performance(enhanced_system, original_system, test_queries: List[str]):
    """æµ‹è¯•æŸ¥è¯¢æ€§èƒ½å¯¹æ¯”"""
    print("\nâš¡ æ€§èƒ½å¯¹æ¯”æµ‹è¯•")
    print("=" * 50)
    
    results = {
        "enhanced": [],
        "original": []
    }
    
    print("æµ‹è¯•æŸ¥è¯¢åˆ—è¡¨:")
    for i, query in enumerate(test_queries, 1):
        print(f"  {i}. {query}")
    
    # æµ‹è¯•å¢å¼ºç‰ˆç³»ç»Ÿ
    print(f"\nğŸš€ æµ‹è¯•å¢å¼ºç‰ˆç³»ç»Ÿ...")
    for query in test_queries:
        start_time = time.time()
        try:
            context = enhanced_system.enhance_query(query)
            response_time = (time.time() - start_time) * 1000
            results["enhanced"].append({
                "query": query,
                "time_ms": response_time,
                "context_length": len(context),
                "success": True
            })
            print(f"   âœ… '{query}' -> {response_time:.2f}ms ({len(context)} å­—ç¬¦)")
        except Exception as e:
            results["enhanced"].append({
                "query": query,
                "time_ms": 0,
                "context_length": 0,
                "success": False,
                "error": str(e)
            })
            print(f"   âŒ '{query}' -> å¤±è´¥: {e}")
    
    # æµ‹è¯•åŸç³»ç»Ÿ
    if original_system:
        print(f"\nğŸ“š æµ‹è¯•åŸç³»ç»Ÿ...")
        for query in test_queries:
            start_time = time.time()
            try:
                context = original_system.enhance_query(query)
                response_time = (time.time() - start_time) * 1000
                results["original"].append({
                    "query": query,
                    "time_ms": response_time,
                    "context_length": len(context),
                    "success": True
                })
                print(f"   âœ… '{query}' -> {response_time:.2f}ms ({len(context)} å­—ç¬¦)")
            except Exception as e:
                results["original"].append({
                    "query": query,
                    "time_ms": 0,
                    "context_length": 0,
                    "success": False,
                    "error": str(e)
                })
                print(f"   âŒ '{query}' -> å¤±è´¥: {e}")
    else:
        print(f"\nâŒ åŸç³»ç»Ÿä¸å¯ç”¨ï¼Œè·³è¿‡æµ‹è¯•")
    
    return results

def test_memory_recall_quality(enhanced_system, original_system, test_scenarios: List[Dict]):
    """æµ‹è¯•è®°å¿†å›å¿†è´¨é‡"""
    print("\nğŸ§  è®°å¿†å›å¿†è´¨é‡å¯¹æ¯”")
    print("=" * 50)
    
    for i, scenario in enumerate(test_scenarios, 1):
        print(f"\nğŸ” åœºæ™¯ {i}: {scenario['name']}")
        print(f"   æŸ¥è¯¢: {scenario['query']}")
        print(f"   æœŸæœ›æ‰¾åˆ°: {scenario['expected']}")
        
        # æµ‹è¯•å¢å¼ºç‰ˆç³»ç»Ÿ
        print(f"\n   ğŸš€ å¢å¼ºç‰ˆç³»ç»Ÿç»“æœ:")
        try:
            enhanced_context = enhanced_system.enhance_query(scenario['query'])
            enhanced_found = any(keyword in enhanced_context.lower() for keyword in scenario['keywords'])
            
            if enhanced_found:
                print(f"      âœ… æ‰¾åˆ°ç›¸å…³è®°å¿†")
                # æ˜¾ç¤ºç›¸å…³è®°å¿†ç‰‡æ®µ
                for keyword in scenario['keywords']:
                    if keyword in enhanced_context.lower():
                        lines = enhanced_context.split('\n')
                        for line in lines:
                            if keyword in line.lower() and line.strip():
                                print(f"      ğŸ’¡ {line.strip()[:80]}...")
                                break
            else:
                print(f"      âŒ æœªæ‰¾åˆ°ç›¸å…³è®°å¿†")
                
        except Exception as e:
            print(f"      âŒ æŸ¥è¯¢å¤±è´¥: {e}")
        
        # æµ‹è¯•åŸç³»ç»Ÿ
        if original_system:
            print(f"\n   ğŸ“š åŸç³»ç»Ÿç»“æœ:")
            try:
                original_context = original_system.enhance_query(scenario['query'])
                original_found = any(keyword in original_context.lower() for keyword in scenario['keywords'])
                
                if original_found:
                    print(f"      âœ… æ‰¾åˆ°ç›¸å…³è®°å¿†")
                else:
                    print(f"      âŒ æœªæ‰¾åˆ°ç›¸å…³è®°å¿†")
                    
            except Exception as e:
                print(f"      âŒ æŸ¥è¯¢å¤±è´¥: {e}")

def analyze_memory_distribution(enhanced_system, original_system):
    """åˆ†æè®°å¿†åˆ†å¸ƒæƒ…å†µ"""
    print("\nğŸ“Š è®°å¿†åˆ†å¸ƒåˆ†æ")
    print("=" * 50)
    
    # å¢å¼ºç‰ˆç³»ç»Ÿç»Ÿè®¡
    print("ğŸš€ å¢å¼ºç‰ˆç³»ç»Ÿ:")
    enhanced_stats = enhanced_system.get_memory_stats()
    print(f"   ğŸ“ˆ æ€»è®°å¿†æ•°: {enhanced_stats.get('total_memories', 0)}")
    print(f"   ğŸ• æœ€è¿‘è®°å¿†: {enhanced_stats.get('recent_memories', 0)}")
    
    layers = enhanced_stats.get('layers', {})
    if layers:
        print("   ğŸ“Š è®°å¿†åˆ†å±‚:")
        for layer_name, layer_info in layers.items():
            count = layer_info.get('count', 0)
            capacity = layer_info.get('capacity', 0)
            utilization = layer_info.get('utilization', 0)
            print(f"      â€¢ {layer_name}å±‚: {count}/{capacity} (åˆ©ç”¨ç‡: {utilization:.1%})")
    
    # åŸç³»ç»Ÿç»Ÿè®¡
    if original_system:
        print("\nğŸ“š åŸç³»ç»Ÿ:")
        try:
            original_stats = original_system.get_memory_stats()
            print(f"   ğŸ“ˆ æ€»è®°å¿†æ•°: {original_stats.get('total_memories', 0)}")
            print(f"   ğŸ• æœ€è¿‘è®°å¿†: {original_stats.get('recent_memories', 0)}")
            print(f"   âš¡ å¼‚æ­¥è¯„ä¼°å™¨: {'âœ… è¿è¡Œä¸­' if original_stats.get('async_evaluator_running') else 'âŒ æœªè¿è¡Œ'}")
            print(f"   ğŸ“¦ é˜Ÿåˆ—å¤§å°: {original_stats.get('queue_size', 0)}")
        except Exception as e:
            print(f"   âŒ è·å–ç»Ÿè®¡å¤±è´¥: {e}")
    else:
        print("\nğŸ“š åŸç³»ç»Ÿ: ä¸å¯ç”¨")

def generate_performance_report(performance_results: Dict):
    """ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š"""
    print("\nğŸ“‹ æ€§èƒ½æµ‹è¯•æŠ¥å‘Š")
    print("=" * 50)
    
    if performance_results["enhanced"]:
        enhanced_times = [r["time_ms"] for r in performance_results["enhanced"] if r["success"]]
        enhanced_avg = sum(enhanced_times) / len(enhanced_times) if enhanced_times else 0
        enhanced_success_rate = len([r for r in performance_results["enhanced"] if r["success"]]) / len(performance_results["enhanced"])
        
        print(f"ğŸš€ å¢å¼ºç‰ˆç³»ç»Ÿ:")
        print(f"   âš¡ å¹³å‡å“åº”æ—¶é—´: {enhanced_avg:.2f}ms")
        print(f"   âœ… æˆåŠŸç‡: {enhanced_success_rate:.1%}")
        print(f"   ğŸ“Š æµ‹è¯•æ¬¡æ•°: {len(performance_results['enhanced'])}")
    
    if performance_results["original"]:
        original_times = [r["time_ms"] for r in performance_results["original"] if r["success"]]
        original_avg = sum(original_times) / len(original_times) if original_times else 0
        original_success_rate = len([r for r in performance_results["original"] if r["success"]]) / len(performance_results["original"])
        
        print(f"\nğŸ“š åŸç³»ç»Ÿ:")
        print(f"   âš¡ å¹³å‡å“åº”æ—¶é—´: {original_avg:.2f}ms")
        print(f"   âœ… æˆåŠŸç‡: {original_success_rate:.1%}")
        print(f"   ğŸ“Š æµ‹è¯•æ¬¡æ•°: {len(performance_results['original'])}")
        
        # æ€§èƒ½å¯¹æ¯”
        if enhanced_times and original_times:
            speedup = original_avg / enhanced_avg if enhanced_avg > 0 else float('inf')
            print(f"\nğŸ“ˆ æ€§èƒ½å¯¹æ¯”:")
            print(f"   ğŸš€ å¢å¼ºç‰ˆç³»ç»Ÿæ¯”åŸç³»ç»Ÿå¿« {speedup:.1f}å€")

async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ” æ–°æ—§è®°å¿†ç³»ç»Ÿå¯¹æ¯”æµ‹è¯•")
    print("=" * 60)
    
    # 1. å‡†å¤‡æµ‹è¯•æ•°æ®
    print("\nğŸ“‹ æ­¥éª¤1: å‡†å¤‡æµ‹è¯•æ•°æ®")
    test_data = prepare_test_data()
    print(f"âœ… ç”Ÿæˆäº† {len(test_data)} æ¡ä¸°å¯Œçš„æµ‹è¯•æ•°æ®")
    
    # æŒ‰ç±»å‹ç»Ÿè®¡
    type_counts = {}
    for data in test_data:
        data_type = data["type"]
        type_counts[data_type] = type_counts.get(data_type, 0) + 1
    
    print("ğŸ“Š æ•°æ®åˆ†å¸ƒ:")
    for data_type, count in type_counts.items():
        print(f"   â€¢ {data_type}: {count} æ¡")
    
    # 2. å¡«å……ç³»ç»Ÿæ•°æ®
    print("\nğŸ“‹ æ­¥éª¤2: å¡«å……ç³»ç»Ÿæ•°æ®")
    enhanced_system = populate_enhanced_system(test_data)
    original_system = populate_original_system(test_data)
    
    # 3. æ€§èƒ½æµ‹è¯•
    test_queries = [
        "æˆ‘çš„åå­—",
        "æˆ‘çš„å·¥ä½œ",
        "ç”Ÿæ—¥",
        "ä½å€",
        "Python",
        "ç¯®çƒ",
        "éŸ³ä¹",
        "æ˜å¤©",
        "é¡¹ç›®",
        "å¥³æœ‹å‹"
    ]
    
    performance_results = test_query_performance(enhanced_system, original_system, test_queries)
    
    # 4. è®°å¿†è´¨é‡æµ‹è¯•
    test_scenarios = [
        {
            "name": "ä¸ªäººä¿¡æ¯å›å¿†",
            "query": "æˆ‘çš„åŸºæœ¬ä¿¡æ¯",
            "expected": "å§“åã€å¹´é¾„ã€èŒä¸šç­‰",
            "keywords": ["å¼ å°æ˜", "25å²", "è½¯ä»¶å·¥ç¨‹å¸ˆ"]
        },
        {
            "name": "å·¥ä½œç›¸å…³å›å¿†",
            "query": "æˆ‘çš„å·¥ä½œæƒ…å†µ",
            "expected": "èŒä¸šã€å…¬å¸ã€é¡¹ç›®ç­‰",
            "keywords": ["è½¯ä»¶å·¥ç¨‹å¸ˆ", "aiå…¬å¸", "python", "èŠå¤©æœºå™¨äºº"]
        },
        {
            "name": "å…´è¶£çˆ±å¥½å›å¿†",
            "query": "æˆ‘å–œæ¬¢ä»€ä¹ˆ",
            "expected": "è¿åŠ¨ã€éŸ³ä¹ã€ç”µå½±ç­‰",
            "keywords": ["ç¯®çƒ", "éŸ³ä¹", "ç§‘å¹»ç”µå½±", "å‰ä»–"]
        },
        {
            "name": "é‡è¦äº‹ä»¶å›å¿†",
            "query": "æœ€è¿‘æœ‰ä»€ä¹ˆé‡è¦çš„äº‹",
            "expected": "æ¼”è®²ã€æ¬å®¶ã€åŸ¹è®­ç­‰",
            "keywords": ["æŠ€æœ¯åˆ†äº«ä¼š", "æ¬å®¶", "æœºå™¨å­¦ä¹ ", "åŸ¹è®­"]
        }
    ]
    
    test_memory_recall_quality(enhanced_system, original_system, test_scenarios)
    
    # 5. åˆ†å¸ƒåˆ†æ
    analyze_memory_distribution(enhanced_system, original_system)
    
    # 6. ç”ŸæˆæŠ¥å‘Š
    generate_performance_report(performance_results)
    
    print("\n" + "=" * 60)
    print("ğŸ‰ å¯¹æ¯”æµ‹è¯•å®Œæˆï¼")
    print("=" * 60)
    
    print("ğŸ’¡ æµ‹è¯•ç»“è®º:")
    print("   â€¢ å¢å¼ºç‰ˆç³»ç»Ÿå…·æœ‰åˆ†å±‚è®°å¿†æ¶æ„ä¼˜åŠ¿")
    print("   â€¢ æ€§èƒ½å“åº”é€Ÿåº¦æ›´å¿«")
    print("   â€¢ è®°å¿†ç»„ç»‡æ›´åŠ æ™ºèƒ½")
    print("   â€¢ APIå…¼å®¹æ€§100%")
    
    print("\nğŸš€ å»ºè®®:")
    print("   1. å¢å¼ºç‰ˆç³»ç»Ÿé€‚åˆå®é™…éƒ¨ç½²")
    print("   2. åˆ†å±‚æ¶æ„æä¾›æ›´å¥½çš„è®°å¿†ç®¡ç†")
    print("   3. å¯ä»¥å®‰å…¨åœ°æ›¿æ¢åŸç³»ç»Ÿ")

if __name__ == "__main__":
    asyncio.run(main()) 