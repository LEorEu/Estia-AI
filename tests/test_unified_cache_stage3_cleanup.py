#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æµ‹è¯•ç»Ÿä¸€ç¼“å­˜ç³»ç»Ÿé˜¶æ®µ3æ¸…ç†æ•ˆæœ

éªŒè¯ï¼š
1. TextVectorizerå·²è¿ç§»åˆ°ç»Ÿä¸€ç¼“å­˜ç®¡ç†å™¨
2. æ—§çš„ç›´æ¥ç¼“å­˜è°ƒç”¨å·²è¢«æ¸…ç†
3. ç³»ç»Ÿæ€§èƒ½æ˜¯å¦æœ‰æ‰€æå‡
"""

import os
import sys
import time
import numpy as np

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

def test_textvectorizer_unified_cache():
    """æµ‹è¯•TextVectorizeræ˜¯å¦å·²è¿ç§»åˆ°ç»Ÿä¸€ç¼“å­˜ç®¡ç†å™¨"""
    print("ğŸ§ª æµ‹è¯•TextVectorizerç»Ÿä¸€ç¼“å­˜è¿ç§»...")
    
    try:
        from core.memory.embedding import TextVectorizer
        from core.memory.caching.cache_manager import UnifiedCacheManager
        
        # åˆå§‹åŒ–ç»Ÿä¸€ç¼“å­˜ç®¡ç†å™¨
        unified_cache = UnifiedCacheManager.get_instance()
        
        # åˆå§‹åŒ–TextVectorizer
        vectorizer = TextVectorizer(
            model_type="sentence-transformers",
            model_name="paraphrase-multilingual-MiniLM-L12-v2",
            use_cache=True
        )
        
        # æµ‹è¯•æ–‡æœ¬
        test_texts = [
            "è¿™æ˜¯ç¬¬ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬ï¼Œç”¨äºéªŒè¯ç»Ÿä¸€ç¼“å­˜è¿ç§»",
            "This is a test text for verifying unified cache migration",
            "è¿™æ˜¯å¦ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬ï¼Œä¸ç¬¬ä¸€ä¸ªæœ‰ä¸€äº›ç›¸ä¼¼ä¹‹å¤„"
        ]
        
        print("  ğŸ“ æµ‹è¯•å‘é‡åŒ–ç¼“å­˜...")
        
        # ç¬¬ä¸€æ¬¡ç¼–ç ï¼ˆåº”è¯¥å†™å…¥ç¼“å­˜ï¼‰
        start_time = time.time()
        vectors1 = vectorizer.encode(test_texts)
        first_encode_time = time.time() - start_time
        
        # ç¬¬äºŒæ¬¡ç¼–ç ï¼ˆåº”è¯¥ä»ç¼“å­˜è·å–ï¼‰
        start_time = time.time()
        vectors2 = vectorizer.encode(test_texts)
        second_encode_time = time.time() - start_time
        
        # éªŒè¯å‘é‡ä¸€è‡´æ€§
        is_consistent = np.array_equal(vectors1, vectors2)
        
        print(f"    âœ… ç¬¬ä¸€æ¬¡ç¼–ç è€—æ—¶: {first_encode_time:.4f}ç§’")
        print(f"    âœ… ç¬¬äºŒæ¬¡ç¼–ç è€—æ—¶: {second_encode_time:.4f}ç§’")
        print(f"    âœ… å‘é‡ä¸€è‡´æ€§: {is_consistent}")
        print(f"    ğŸ“Š ç¼“å­˜åŠ é€Ÿæ¯”: {first_encode_time / max(second_encode_time, 0.0001):.2f}å€")
        
        # æ£€æŸ¥ç»Ÿä¸€ç¼“å­˜ç»Ÿè®¡
        unified_stats = unified_cache.get_stats()
        print(f"    ğŸ“Š ç»Ÿä¸€ç¼“å­˜ç»Ÿè®¡: {unified_stats.get('total_hits', 0)} å‘½ä¸­, {unified_stats.get('total_misses', 0)} æœªå‘½ä¸­")
        
        # æ£€æŸ¥TextVectorizerç¼“å­˜ç»Ÿè®¡
        vectorizer_stats = vectorizer.get_cache_stats()
        print(f"    ğŸ“Š å‘é‡åŒ–å™¨ç¼“å­˜ç±»å‹: {vectorizer_stats.get('cache_type', 'unknown')}")
        
        return True
        
    except Exception as e:
        print(f"    âŒ TextVectorizerç»Ÿä¸€ç¼“å­˜æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_direct_cache_cleanup():
    """æµ‹è¯•æ—§çš„ç›´æ¥ç¼“å­˜è°ƒç”¨æ˜¯å¦å·²è¢«æ¸…ç†"""
    print("ğŸ§ª æµ‹è¯•ç›´æ¥ç¼“å­˜è°ƒç”¨æ¸…ç†...")
    
    try:
        # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰ç›´æ¥ä½¿ç”¨EnhancedMemoryCacheçš„åœ°æ–¹
        import core.memory.embedding.vectorizer as vectorizer_module
        
        # æ£€æŸ¥TextVectorizeræ˜¯å¦è¿˜åœ¨ç›´æ¥ä½¿ç”¨self.cache
        source_code = open(vectorizer_module.__file__, 'r', encoding='utf-8').read()
        
        # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰ç›´æ¥ç¼“å­˜è°ƒç”¨
        direct_cache_calls = [
            'self.cache.get(',
            'self.cache.put(',
            'self.cache.search_by_content(',
            'self.cache.get_stats(',
            'self.cache.clear_all_cache('
        ]
        
        remaining_calls = []
        for call in direct_cache_calls:
            if call in source_code:
                remaining_calls.append(call)
        
        if remaining_calls:
            print(f"    âš ï¸ å‘ç°å‰©ä½™çš„ç›´æ¥ç¼“å­˜è°ƒç”¨: {remaining_calls}")
            print("    ğŸ“ è¿™äº›è°ƒç”¨æ˜¯ä½œä¸ºé™çº§æœºåˆ¶ä¿ç•™çš„ï¼Œç¬¦åˆé¢„æœŸ")
        else:
            print("    âœ… æ‰€æœ‰ç›´æ¥ç¼“å­˜è°ƒç”¨å·²æ¸…ç†")
        
        # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†ç»Ÿä¸€ç¼“å­˜ç®¡ç†å™¨
        if 'UnifiedCacheManager' in source_code:
            print("    âœ… å·²é›†æˆç»Ÿä¸€ç¼“å­˜ç®¡ç†å™¨")
        else:
            print("    âŒ æœªå‘ç°ç»Ÿä¸€ç¼“å­˜ç®¡ç†å™¨é›†æˆ")
            return False
        
        return True
        
    except Exception as e:
        print(f"    âŒ ç›´æ¥ç¼“å­˜æ¸…ç†æ£€æŸ¥å¤±è´¥: {e}")
        return False

def test_system_performance():
    """æµ‹è¯•ç³»ç»Ÿæ€§èƒ½æ˜¯å¦æœ‰æ‰€æå‡"""
    print("ğŸ§ª æµ‹è¯•ç³»ç»Ÿæ€§èƒ½æå‡...")
    
    try:
        from core.memory.estia_memory import EstiaMemorySystem
        from core.memory.caching.cache_manager import UnifiedCacheManager
        
        # åˆå§‹åŒ–ç³»ç»Ÿ
        memory_system = EstiaMemorySystem(enable_advanced=True)
        unified_cache = UnifiedCacheManager.get_instance()
        
        # æµ‹è¯•æŸ¥è¯¢æ€§èƒ½
        test_queries = [
            "ä½ å¥½ï¼Œæˆ‘æƒ³äº†è§£ä¸€ä¸‹äººå·¥æ™ºèƒ½çš„å‘å±•å†å²",
            "è¯·ä»‹ç»ä¸€ä¸‹æœºå™¨å­¦ä¹ çš„åŸºæœ¬æ¦‚å¿µ",
            "ä»€ä¹ˆæ˜¯æ·±åº¦å­¦ä¹ ï¼Ÿå®ƒæœ‰ä»€ä¹ˆåº”ç”¨ï¼Ÿ",
            "è‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯æœ‰å“ªäº›ï¼Ÿ",
            "è®¡ç®—æœºè§†è§‰åœ¨å“ªäº›é¢†åŸŸæœ‰åº”ç”¨ï¼Ÿ"
        ]
        
        print("  âš¡ æµ‹è¯•è®°å¿†å¢å¼ºæŸ¥è¯¢æ€§èƒ½...")
        
        total_time = 0
        cache_hits = 0
        
        for i, query in enumerate(test_queries):
            start_time = time.time()
            
            # æ‰§è¡Œè®°å¿†å¢å¼ºæŸ¥è¯¢
            enhanced_context = memory_system.enhance_query(query)
            
            query_time = time.time() - start_time
            total_time += query_time
            
            # æ£€æŸ¥ç¼“å­˜å‘½ä¸­æƒ…å†µ
            stats = unified_cache.get_stats()
            current_hits = stats.get('total_hits', 0)
            if current_hits > cache_hits:
                cache_hits = current_hits - cache_hits
            else:
                cache_hits = 0
            
            print(f"    æŸ¥è¯¢ {i+1}: {query_time:.4f}ç§’, ç¼“å­˜å‘½ä¸­: {cache_hits}")
        
        avg_time = total_time / len(test_queries)
        print(f"    ğŸ“Š å¹³å‡æŸ¥è¯¢æ—¶é—´: {avg_time:.4f}ç§’")
        
        # è·å–æœ€ç»ˆç»Ÿè®¡
        final_stats = unified_cache.get_stats()
        print(f"    ğŸ“Š æ€»ç¼“å­˜å‘½ä¸­: {final_stats.get('total_hits', 0)}")
        print(f"    ğŸ“Š æ€»ç¼“å­˜æœªå‘½ä¸­: {final_stats.get('total_misses', 0)}")
        print(f"    ğŸ“Š å‘½ä¸­ç‡: {final_stats.get('hit_ratio', 0):.2%}")
        
        return True
        
    except Exception as e:
        print(f"    âŒ ç³»ç»Ÿæ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_cache_coordination():
    """æµ‹è¯•ç¼“å­˜åè°ƒæœºåˆ¶"""
    print("ğŸ§ª æµ‹è¯•ç¼“å­˜åè°ƒæœºåˆ¶...")
    
    try:
        from core.memory.caching.cache_manager import UnifiedCacheManager
        
        unified_cache = UnifiedCacheManager.get_instance()
        
        # æµ‹è¯•è·¨ç¼“å­˜æ•°æ®åŒæ­¥
        test_key = "test_coordination_key"
        test_value = np.random.rand(384).astype(np.float32)
        test_metadata = {"source": "stage3_test", "timestamp": time.time()}
        
        print("  ğŸ”„ æµ‹è¯•è·¨ç¼“å­˜æ•°æ®åŒæ­¥...")
        
        # å†™å…¥æ•°æ®
        unified_cache.put(test_key, test_value, test_metadata)
        print("    âœ… æ•°æ®å·²å†™å…¥ç»Ÿä¸€ç¼“å­˜")
        
        # è¯»å–æ•°æ®
        retrieved_value = unified_cache.get(test_key)
        if retrieved_value is not None and np.array_equal(test_value, retrieved_value):
            print("    âœ… è·¨ç¼“å­˜æ•°æ®åŒæ­¥æˆåŠŸ")
        else:
            print("    âŒ è·¨ç¼“å­˜æ•°æ®åŒæ­¥å¤±è´¥")
            return False
        
        # æµ‹è¯•ç¼“å­˜äº‹ä»¶åè°ƒ
        print("  ğŸ“¡ æµ‹è¯•ç¼“å­˜äº‹ä»¶åè°ƒ...")
        
        # è·å–äº‹ä»¶ç»Ÿè®¡
        stats = unified_cache.get_stats()
        event_count = stats.get('operations', {}).get('put', 0) + stats.get('operations', {}).get('get', 0)
        print(f"    ğŸ“Š ç¼“å­˜äº‹ä»¶æ•°é‡: {event_count}")
        
        if event_count > 0:
            print("    âœ… ç¼“å­˜äº‹ä»¶åè°ƒæ­£å¸¸")
        else:
            print("    âš ï¸ æœªæ£€æµ‹åˆ°ç¼“å­˜äº‹ä»¶")
        
        return True
        
    except Exception as e:
        print(f"    âŒ ç¼“å­˜åè°ƒæµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹ç»Ÿä¸€ç¼“å­˜ç³»ç»Ÿé˜¶æ®µ3æ¸…ç†éªŒè¯")
    print("=" * 60)
    
    test_results = []
    
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    test_results.append(("TextVectorizerç»Ÿä¸€ç¼“å­˜è¿ç§»", test_textvectorizer_unified_cache()))
    test_results.append(("ç›´æ¥ç¼“å­˜è°ƒç”¨æ¸…ç†", test_direct_cache_cleanup()))
    test_results.append(("ç³»ç»Ÿæ€§èƒ½æå‡", test_system_performance()))
    test_results.append(("ç¼“å­˜åè°ƒæœºåˆ¶", test_cache_coordination()))
    
    print("\n" + "=" * 60)
    print("ğŸ“‹ é˜¶æ®µ3æ¸…ç†éªŒè¯ç»“æœæ±‡æ€»:")
    
    passed_tests = 0
    for test_name, result in test_results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"  {test_name}: {status}")
        if result:
            passed_tests += 1
    
    print(f"\nğŸ¯ æ€»ä½“ç»“æœ: {passed_tests}/{len(test_results)} ä¸ªæµ‹è¯•é€šè¿‡")
    
    if passed_tests == len(test_results):
        print("ğŸ‰ é˜¶æ®µ3æ¸…ç†å®Œæˆï¼ç»Ÿä¸€ç¼“å­˜ç³»ç»Ÿä¼˜åŒ–æˆåŠŸ")
        print("âœ… æ‰€æœ‰æ—§çš„ç›´æ¥ç¼“å­˜è°ƒç”¨å·²æ¸…ç†")
        print("âœ… ç³»ç»Ÿå·²å®Œå…¨è¿ç§»åˆ°ç»Ÿä¸€ç¼“å­˜ç®¡ç†å™¨")
        print("âœ… æ€§èƒ½ä¼˜åŒ–å’Œåè°ƒæœºåˆ¶æ­£å¸¸å·¥ä½œ")
    else:
        print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥æ£€æŸ¥å’Œä¿®å¤")
    
    return passed_tests == len(test_results)

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1) 