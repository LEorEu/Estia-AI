#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
è°ƒè¯•æ¨¡å‹è·¯å¾„é—®é¢˜
"""

import os
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(__file__))

def debug_model_path():
    """è°ƒè¯•æ¨¡å‹è·¯å¾„é…ç½®"""
    print("ğŸ” è°ƒè¯•æ¨¡å‹è·¯å¾„é…ç½®")
    print("=" * 60)
    
    # å½“å‰å·¥ä½œç›®å½•
    current_dir = os.getcwd()
    print(f"å½“å‰å·¥ä½œç›®å½•: {current_dir}")
    
    # é¡¹ç›®æ ¹ç›®å½•
    project_root = os.path.dirname(__file__)
    print(f"é¡¹ç›®æ ¹ç›®å½•: {project_root}")
    
    # æœŸæœ›çš„æ¨¡å‹ç¼“å­˜ç›®å½•
    expected_cache_dir = os.path.join(project_root, "cache")
    print(f"æœŸæœ›ç¼“å­˜ç›®å½•: {expected_cache_dir}")
    print(f"ç¼“å­˜ç›®å½•æ˜¯å¦å­˜åœ¨: {os.path.exists(expected_cache_dir)}")
    
    # æ£€æŸ¥æ¨¡å‹ç›®å½•
    model_dir = os.path.join(expected_cache_dir, "models--Qwen--Qwen3-Embedding-0.6B")
    print(f"æ¨¡å‹ç›®å½•: {model_dir}")
    print(f"æ¨¡å‹ç›®å½•æ˜¯å¦å­˜åœ¨: {os.path.exists(model_dir)}")
    
    if os.path.exists(model_dir):
        print("âœ… æ¨¡å‹ç›®å½•å­˜åœ¨")
        # åˆ—å‡ºæ¨¡å‹æ–‡ä»¶
        for item in os.listdir(model_dir):
            item_path = os.path.join(model_dir, item)
            print(f"  - {item} {'(ç›®å½•)' if os.path.isdir(item_path) else '(æ–‡ä»¶)'}")
    else:
        print("âŒ æ¨¡å‹ç›®å½•ä¸å­˜åœ¨")
    
    # æ£€æŸ¥å‘é‡åŒ–å™¨ä¸­çš„è·¯å¾„è®¡ç®—
    print("\nğŸ”§ å‘é‡åŒ–å™¨è·¯å¾„è®¡ç®—")
    print("-" * 40)
    
    # æ¨¡æ‹Ÿå‘é‡åŒ–å™¨çš„è·¯å¾„è®¡ç®—
    from core.memory.shared.embedding.vectorizer import TextVectorizer
    vectorizer_file = Path(TextVectorizer.__file__)
    print(f"å‘é‡åŒ–å™¨æ–‡ä»¶: {vectorizer_file}")
    
    # è®¡ç®—è·¯å¾„
    calculated_cache = str(vectorizer_file.parent.parent.parent.parent.parent / "cache")
    print(f"è®¡ç®—çš„ç¼“å­˜è·¯å¾„: {calculated_cache}")
    print(f"è®¡ç®—çš„ç¼“å­˜è·¯å¾„æ˜¯å¦å­˜åœ¨: {os.path.exists(calculated_cache)}")
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    print("\nğŸŒ ç¯å¢ƒå˜é‡æ£€æŸ¥")
    print("-" * 40)
    
    env_vars = [
        'HUGGINGFACE_HUB_CACHE',
        'SENTENCE_TRANSFORMERS_HOME', 
        'HF_HOME',
        'HF_HUB_OFFLINE',
        'TRANSFORMERS_OFFLINE'
    ]
    
    for var in env_vars:
        value = os.environ.get(var, 'æœªè®¾ç½®')
        print(f"{var}: {value}")
    
    # æµ‹è¯•æœ¬åœ°æ¨¡å‹åŠ è½½
    print("\nğŸ§ª æµ‹è¯•æœ¬åœ°æ¨¡å‹åŠ è½½")
    print("-" * 40)
    
    # è®¾ç½®ç¯å¢ƒå˜é‡
    os.environ['HUGGINGFACE_HUB_CACHE'] = calculated_cache
    os.environ['SENTENCE_TRANSFORMERS_HOME'] = calculated_cache
    os.environ['HF_HOME'] = calculated_cache
    os.environ['HF_HUB_OFFLINE'] = '1'
    os.environ['TRANSFORMERS_OFFLINE'] = '1'
    
    try:
        from sentence_transformers import SentenceTransformer
        
        model_name = "Qwen/Qwen3-Embedding-0.6B"
        print(f"å°è¯•åŠ è½½æ¨¡å‹: {model_name}")
        
        # æ£€æŸ¥æ˜¯å¦èƒ½æ‰¾åˆ°æ¨¡å‹
        expected_model_path = os.path.join(calculated_cache, f"models--{model_name.replace('/', '--')}")
        print(f"æœŸæœ›æ¨¡å‹è·¯å¾„: {expected_model_path}")
        print(f"æ¨¡å‹è·¯å¾„æ˜¯å¦å­˜åœ¨: {os.path.exists(expected_model_path)}")
        
        if os.path.exists(expected_model_path):
            print("âœ… å‘ç°æœ¬åœ°æ¨¡å‹ï¼Œå°è¯•åŠ è½½...")
            model = SentenceTransformer(
                model_name,
                device='cpu',
                cache_folder=calculated_cache,
                trust_remote_code=True
            )
            print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼")
            print(f"æ¨¡å‹ç»´åº¦: {model.get_sentence_embedding_dimension()}")
        else:
            print("âŒ æœ¬åœ°æ¨¡å‹ä¸å­˜åœ¨")
            
    except ImportError:
        print("âŒ sentence-transformers æœªå®‰è£…")
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    
    print("\nğŸ è°ƒè¯•å®Œæˆ")

if __name__ == "__main__":
    debug_model_path()