#!/usr/bin/env python3
"""
æµ‹è¯•å¢å¼ºç‰ˆç¼“å­˜ç³»ç»Ÿ
éªŒè¯ä¸‰ä¸ªæ ¸å¿ƒç‰¹æ€§ï¼š
1. å¤šçº§ç¼“å­˜ç­–ç•¥ï¼ˆçƒ­ç¼“å­˜+æ¸©ç¼“å­˜+æŒä¹…åŒ–ç¼“å­˜ï¼‰
2. å…³é”®è¯ç¼“å­˜åŠ é€Ÿæ–‡æœ¬æ£€ç´¢
3. æ™ºèƒ½ç¼“å­˜æå‡æœºåˆ¶
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import numpy as np
import time
from core.memory.embedding.cache import EnhancedMemoryCache

def test_multi_level_cache():
    """æµ‹è¯•å¤šçº§ç¼“å­˜ç­–ç•¥"""
    print("=" * 60)
    print("æµ‹è¯• 1: å¤šçº§ç¼“å­˜ç­–ç•¥")
    print("=" * 60)
    
    # åˆå§‹åŒ–ç¼“å­˜ç³»ç»Ÿ
    cache = EnhancedMemoryCache(
        cache_dir="data/memory/test_enhanced_cache",
        hot_capacity=3,    # å°å®¹é‡ä¾¿äºæµ‹è¯•
        warm_capacity=5,
        persist=True
    )
    
    # å‡†å¤‡æµ‹è¯•æ•°æ®
    test_texts = [
        ("è¿™æ˜¯ä¸€ä¸ªé‡è¦çš„è®°å¿†", 9.0),  # é«˜æƒé‡ï¼Œåº”è¯¥ç›´æ¥è¿›å…¥çƒ­ç¼“å­˜
        ("è¿™æ˜¯ä¸€ä¸ªæ™®é€šçš„è®°å¿†", 5.0),  # æ™®é€šæƒé‡ï¼Œè¿›å…¥æ¸©ç¼“å­˜
        ("è¿™æ˜¯å¦ä¸€ä¸ªé‡è¦è®°å¿†", 8.0),  # é«˜æƒé‡ï¼Œè¿›å…¥çƒ­ç¼“å­˜
        ("è¿™æ˜¯ç¬¬ä¸‰ä¸ªæ™®é€šè®°å¿†", 4.0),  # æ™®é€šæƒé‡ï¼Œè¿›å…¥æ¸©ç¼“å­˜
        ("è¿™æ˜¯ç¬¬å››ä¸ªæ™®é€šè®°å¿†", 3.0),  # æ™®é€šæƒé‡ï¼Œè¿›å…¥æ¸©ç¼“å­˜
        ("è¿™æ˜¯ç¬¬äº”ä¸ªæ™®é€šè®°å¿†", 2.0),  # æ™®é€šæƒé‡ï¼Œè¿›å…¥æ¸©ç¼“å­˜
        ("è¿™æ˜¯ç¬¬å…­ä¸ªæ™®é€šè®°å¿†", 1.0),  # æ™®é€šæƒé‡ï¼Œåº”è¯¥å¯¼è‡´æ¸©ç¼“å­˜æº¢å‡º
    ]
    
    # æ·»åŠ æµ‹è¯•å‘é‡
    print("æ·»åŠ æµ‹è¯•æ•°æ®åˆ°ç¼“å­˜...")
    for i, (text, weight) in enumerate(test_texts):
        vector = np.random.rand(384).astype(np.float32)  # æ¨¡æ‹Ÿå‘é‡
        cache.put(text, vector, memory_weight=weight)
        print(f"  æ·»åŠ : {text[:20]}... (æƒé‡: {weight})")
    
    # æ£€æŸ¥ç¼“å­˜åˆ†å¸ƒ
    stats = cache.get_stats()
    print(f"\nç¼“å­˜åˆ†å¸ƒ:")
    print(f"  çƒ­ç¼“å­˜å¤§å°: {stats['cache_levels']['hot_cache_size']}/{stats['cache_levels']['hot_capacity']}")
    print(f"  æ¸©ç¼“å­˜å¤§å°: {stats['cache_levels']['warm_cache_size']}/{stats['cache_levels']['warm_capacity']}")
    print(f"  å…³é”®è¯æ•°é‡: {stats['cache_management']['keyword_count']}")
    
    # éªŒè¯é‡è¦è®°å¿†åœ¨çƒ­ç¼“å­˜ä¸­
    important_texts = [text for text, weight in test_texts if weight >= 7.0]
    print(f"\néªŒè¯é‡è¦è®°å¿†åœ¨çƒ­ç¼“å­˜ä¸­:")
    for text in important_texts:
        vector = cache.get(text, memory_weight=9.0)
        if vector is not None:
            print(f"  âœ… {text[:20]}... åœ¨çƒ­ç¼“å­˜ä¸­")
        else:
            print(f"  âŒ {text[:20]}... æœªæ‰¾åˆ°")
    
    print(f"\nâœ… å¤šçº§ç¼“å­˜ç­–ç•¥æµ‹è¯•å®Œæˆ")
    return cache

def test_keyword_cache(cache):
    """æµ‹è¯•å…³é”®è¯ç¼“å­˜åŠ é€Ÿæ£€ç´¢"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 2: å…³é”®è¯ç¼“å­˜åŠ é€Ÿæ–‡æœ¬æ£€ç´¢")
    print("=" * 60)
    
    # æ·»åŠ ä¸€äº›æœ‰æ˜ç¡®å…³é”®è¯çš„è®°å¿†
    keyword_tests = [
        ("æˆ‘ä»Šå¤©å­¦ä¹ äº†Pythonç¼–ç¨‹å’Œæœºå™¨å­¦ä¹ ", 6.0),
        ("ä½¿ç”¨PyTorchè®­ç»ƒäº†ä¸€ä¸ªæ·±åº¦å­¦ä¹ æ¨¡å‹", 7.0),
        ("ç ”ç©¶äº†è‡ªç„¶è¯­è¨€å¤„ç†å’Œæ–‡æœ¬åˆ†æ", 5.0),
        ("å¼€å‘äº†ä¸€ä¸ªWebåº”ç”¨ä½¿ç”¨Flaskæ¡†æ¶", 6.0),
        ("å­¦ä¹ äº†æ•°æ®åº“è®¾è®¡å’ŒSQLæŸ¥è¯¢ä¼˜åŒ–", 5.0),
    ]
    
    print("æ·»åŠ åŒ…å«å…³é”®è¯çš„è®°å¿†...")
    for text, weight in keyword_tests:
        vector = np.random.rand(384).astype(np.float32)
        cache.put(text, vector, memory_weight=weight)
        print(f"  æ·»åŠ : {text}")
    
    # æµ‹è¯•å…³é”®è¯æœç´¢
    search_queries = [
        "Pythonç¼–ç¨‹",
        "æ·±åº¦å­¦ä¹ ",
        "Webå¼€å‘",
        "æ•°æ®åº“",
        "æœºå™¨å­¦ä¹ "
    ]
    
    print(f"\næµ‹è¯•å…³é”®è¯æœç´¢:")
    for query in search_queries:
        start_time = time.time()
        results = cache.search_by_content(query, limit=3)
        search_time = time.time() - start_time
        
        print(f"\n  æŸ¥è¯¢: '{query}'")
        print(f"  æœç´¢æ—¶é—´: {search_time*1000:.2f}ms")
        print(f"  æ‰¾åˆ° {len(results)} ä¸ªç»“æœ:")
        
        for result in results:
            metadata = result['metadata']
            text_preview = metadata.get('text_preview', '')
            score = result['score']
            cache_level = result['cache_level']
            print(f"    ğŸ“„ {text_preview[:40]}... (åˆ†æ•°: {score:.3f}, ç¼“å­˜çº§åˆ«: {cache_level})")
    
    # æ£€æŸ¥å…³é”®è¯ç¼“å­˜å‘½ä¸­ç»Ÿè®¡
    stats = cache.get_stats()
    print(f"\nå…³é”®è¯ç¼“å­˜ç»Ÿè®¡:")
    print(f"  å…³é”®è¯ç¼“å­˜å‘½ä¸­: {stats['hit_statistics']['keyword_hits']}")
    print(f"  æ€»å…³é”®è¯æ•°é‡: {stats['cache_management']['keyword_count']}")
    
    print(f"\nâœ… å…³é”®è¯ç¼“å­˜æµ‹è¯•å®Œæˆ")

def test_intelligent_promotion(cache):
    """æµ‹è¯•æ™ºèƒ½ç¼“å­˜æå‡æœºåˆ¶"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 3: æ™ºèƒ½ç¼“å­˜æå‡æœºåˆ¶")
    print("=" * 60)
    
    # æ·»åŠ ä¸€ä¸ªæ™®é€šæƒé‡çš„è®°å¿†
    test_text = "è¿™æ˜¯ä¸€ä¸ªéœ€è¦è¢«é¢‘ç¹è®¿é—®çš„è®°å¿†"
    vector = np.random.rand(384).astype(np.float32)
    cache.put(test_text, vector, memory_weight=3.0)  # æ™®é€šæƒé‡ï¼Œåº”è¯¥åœ¨æ¸©ç¼“å­˜
    
    print(f"æ·»åŠ æ™®é€šè®°å¿†: {test_text}")
    print(f"åˆå§‹æƒé‡: 3.0 (åº”è¯¥åœ¨æ¸©ç¼“å­˜)")
    
    # æ£€æŸ¥åˆå§‹ä½ç½®
    stats_before = cache.get_stats()
    print(f"\næå‡å‰ç¼“å­˜çŠ¶æ€:")
    print(f"  çƒ­ç¼“å­˜å¤§å°: {stats_before['cache_levels']['hot_cache_size']}")
    print(f"  æ¸©ç¼“å­˜å¤§å°: {stats_before['cache_levels']['warm_cache_size']}")
    
    # å¤šæ¬¡è®¿é—®è¯¥è®°å¿†ä»¥è§¦å‘æå‡
    print(f"\né¢‘ç¹è®¿é—®è¯¥è®°å¿†ä»¥è§¦å‘æ™ºèƒ½æå‡...")
    for i in range(5):
        vector_retrieved = cache.get(test_text, memory_weight=3.0)
        if vector_retrieved is not None:
            print(f"  ç¬¬ {i+1} æ¬¡è®¿é—®: âœ… æˆåŠŸ")
        else:
            print(f"  ç¬¬ {i+1} æ¬¡è®¿é—®: âŒ å¤±è´¥")
        time.sleep(0.1)  # çŸ­æš‚å»¶è¿Ÿ
    
    # æ£€æŸ¥æ˜¯å¦è¢«æå‡
    stats_after = cache.get_stats()
    print(f"\næå‡åç¼“å­˜çŠ¶æ€:")
    print(f"  çƒ­ç¼“å­˜å¤§å°: {stats_after['cache_levels']['hot_cache_size']}")
    print(f"  æ¸©ç¼“å­˜å¤§å°: {stats_after['cache_levels']['warm_cache_size']}")
    print(f"  ç¼“å­˜æå‡æ¬¡æ•°: {stats_after['cache_management']['promotions']}")
    
    # éªŒè¯è®°å¿†æ˜¯å¦åœ¨çƒ­ç¼“å­˜ä¸­
    if test_text in [cache._text_to_key(test_text)] and cache._text_to_key(test_text) in cache.hot_cache:
        print(f"  âœ… è®°å¿†å·²è¢«æå‡åˆ°çƒ­ç¼“å­˜")
    else:
        print(f"  âš ï¸ è®°å¿†å¯èƒ½è¿˜åœ¨æ¸©ç¼“å­˜ä¸­ï¼ˆéœ€è¦æ›´å¤šè®¿é—®ï¼‰")
    
    # æµ‹è¯•é«˜æƒé‡è®°å¿†çš„ç›´æ¥æå‡
    print(f"\næµ‹è¯•é«˜æƒé‡è®°å¿†çš„ç›´æ¥æå‡...")
    high_weight_text = "è¿™æ˜¯ä¸€ä¸ªéå¸¸é‡è¦çš„è®°å¿†"
    high_weight_vector = np.random.rand(384).astype(np.float32)
    cache.put(high_weight_text, high_weight_vector, memory_weight=8.5)  # é«˜æƒé‡
    
    print(f"æ·»åŠ é«˜æƒé‡è®°å¿†: {high_weight_text}")
    print(f"æƒé‡: 8.5 (åº”è¯¥ç›´æ¥è¿›å…¥çƒ­ç¼“å­˜)")
    
    # æ£€æŸ¥æœ€ç»ˆçŠ¶æ€
    final_stats = cache.get_stats()
    print(f"\næœ€ç»ˆç¼“å­˜ç»Ÿè®¡:")
    print(f"  çƒ­ç¼“å­˜: {final_stats['cache_levels']['hot_cache_size']}/{final_stats['cache_levels']['hot_capacity']}")
    print(f"  æ¸©ç¼“å­˜: {final_stats['cache_levels']['warm_cache_size']}/{final_stats['cache_levels']['warm_capacity']}")
    print(f"  æ€»æå‡æ¬¡æ•°: {final_stats['cache_management']['promotions']}")
    print(f"  æ€»é©±é€æ¬¡æ•°: {final_stats['cache_management']['evictions']}")
    
    print(f"\nâœ… æ™ºèƒ½ç¼“å­˜æå‡æœºåˆ¶æµ‹è¯•å®Œæˆ")

def test_cache_performance():
    """æµ‹è¯•ç¼“å­˜æ€§èƒ½"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 4: ç¼“å­˜æ€§èƒ½å¯¹æ¯”")
    print("=" * 60)
    
    cache = EnhancedMemoryCache(
        cache_dir="data/memory/test_performance_cache",
        hot_capacity=100,
        warm_capacity=500,
        persist=True
    )
    
    # å‡†å¤‡å¤§é‡æµ‹è¯•æ•°æ®
    test_data = []
    for i in range(200):
        text = f"è¿™æ˜¯ç¬¬{i}æ¡æµ‹è¯•è®°å¿†ï¼ŒåŒ…å«ä¸€äº›éšæœºå†…å®¹å’Œæ•°å­—{i*123}"
        weight = 1.0 + (i % 10)  # æƒé‡åœ¨1.0-10.0ä¹‹é—´
        vector = np.random.rand(384).astype(np.float32)
        test_data.append((text, weight, vector))
    
    # æµ‹è¯•å†™å…¥æ€§èƒ½
    print("æµ‹è¯•å†™å…¥æ€§èƒ½...")
    start_time = time.time()
    for text, weight, vector in test_data:
        cache.put(text, vector, memory_weight=weight)
    write_time = time.time() - start_time
    print(f"  å†™å…¥ {len(test_data)} æ¡è®°å¿†è€—æ—¶: {write_time:.3f}ç§’")
    print(f"  å¹³å‡æ¯æ¡è®°å¿†: {write_time/len(test_data)*1000:.2f}ms")
    
    # æµ‹è¯•è¯»å–æ€§èƒ½ï¼ˆç¼“å­˜å‘½ä¸­ï¼‰
    print(f"\næµ‹è¯•è¯»å–æ€§èƒ½ï¼ˆç¼“å­˜å‘½ä¸­ï¼‰...")
    hit_times = []
    for i in range(50):  # æµ‹è¯•å‰50æ¡
        text, weight, _ = test_data[i]
        start_time = time.time()
        vector = cache.get(text, memory_weight=weight)
        read_time = time.time() - start_time
        hit_times.append(read_time)
        if vector is None:
            print(f"  âŒ ç¬¬{i}æ¡è®°å¿†è¯»å–å¤±è´¥")
    
    avg_hit_time = sum(hit_times) / len(hit_times)
    print(f"  å¹³å‡ç¼“å­˜å‘½ä¸­æ—¶é—´: {avg_hit_time*1000:.2f}ms")
    
    # æµ‹è¯•å…³é”®è¯æœç´¢æ€§èƒ½
    print(f"\næµ‹è¯•å…³é”®è¯æœç´¢æ€§èƒ½...")
    search_queries = ["æµ‹è¯•", "è®°å¿†", "å†…å®¹", "æ•°å­—", "éšæœº"]
    search_times = []
    
    for query in search_queries:
        start_time = time.time()
        results = cache.search_by_content(query, limit=10)
        search_time = time.time() - start_time
        search_times.append(search_time)
        print(f"  æŸ¥è¯¢ '{query}': {search_time*1000:.2f}ms, æ‰¾åˆ° {len(results)} ä¸ªç»“æœ")
    
    avg_search_time = sum(search_times) / len(search_times)
    print(f"  å¹³å‡æœç´¢æ—¶é—´: {avg_search_time*1000:.2f}ms")
    
    # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
    final_stats = cache.get_stats()
    print(f"\næœ€ç»ˆæ€§èƒ½ç»Ÿè®¡:")
    print(f"  æ€»å‘½ä¸­ç‡: {final_stats['hit_statistics']['hit_rate']}")
    print(f"  çƒ­ç¼“å­˜å‘½ä¸­: {final_stats['hit_statistics']['hot_hits']}")
    print(f"  æ¸©ç¼“å­˜å‘½ä¸­: {final_stats['hit_statistics']['warm_hits']}")
    print(f"  æŒä¹…åŒ–ç¼“å­˜å‘½ä¸­: {final_stats['hit_statistics']['persistent_hits']}")
    print(f"  å…³é”®è¯ç¼“å­˜å‘½ä¸­: {final_stats['hit_statistics']['keyword_hits']}")
    print(f"  ç¼“å­˜æœªå‘½ä¸­: {final_stats['hit_statistics']['misses']}")
    
    print(f"\nâœ… ç¼“å­˜æ€§èƒ½æµ‹è¯•å®Œæˆ")

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹æµ‹è¯•å¢å¼ºç‰ˆç¼“å­˜ç³»ç»Ÿ")
    print("æµ‹è¯•ä¸‰ä¸ªæ ¸å¿ƒç‰¹æ€§ï¼šå¤šçº§ç¼“å­˜ã€å…³é”®è¯ç¼“å­˜ã€æ™ºèƒ½æå‡")
    
    try:
        # æµ‹è¯•1: å¤šçº§ç¼“å­˜ç­–ç•¥
        cache = test_multi_level_cache()
        
        # æµ‹è¯•2: å…³é”®è¯ç¼“å­˜
        test_keyword_cache(cache)
        
        # æµ‹è¯•3: æ™ºèƒ½ç¼“å­˜æå‡
        test_intelligent_promotion(cache)
        
        # æµ‹è¯•4: æ€§èƒ½æµ‹è¯•
        test_cache_performance()
        
        print("\n" + "=" * 60)
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼å¢å¼ºç‰ˆç¼“å­˜ç³»ç»Ÿå·¥ä½œæ­£å¸¸")
        print("=" * 60)
        
        print("\nğŸ“Š æ ¸å¿ƒç‰¹æ€§éªŒè¯ç»“æœ:")
        print("âœ… å¤šçº§ç¼“å­˜ç­–ç•¥ï¼šçƒ­ç¼“å­˜+æ¸©ç¼“å­˜+æŒä¹…åŒ–ç¼“å­˜")
        print("âœ… å…³é”®è¯ç¼“å­˜ï¼šå¿«é€Ÿæ–‡æœ¬æ£€ç´¢å’ŒåŒ¹é…")
        print("âœ… æ™ºèƒ½ç¼“å­˜æå‡ï¼šåŸºäºè®¿é—®é¢‘ç‡å’Œé‡è¦æ€§çš„è‡ªåŠ¨è°ƒæ•´")
        print("âœ… æ€§èƒ½ä¼˜åŒ–ï¼šç¼“å­˜å‘½ä¸­ç‡é«˜ï¼Œæ£€ç´¢é€Ÿåº¦å¿«")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    return True

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1) 