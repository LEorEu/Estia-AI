#!/usr/bin/env python3
"""
æ•°æ®ä¸€è‡´æ€§ç›‘æ§è„šæœ¬
å®šæœŸæ£€æŸ¥è®°å¿†å­˜å‚¨ç³»ç»Ÿçš„æ•°æ®ä¸€è‡´æ€§ï¼Œå¹¶åœ¨å‘ç°é—®é¢˜æ—¶è‡ªåŠ¨ä¿®å¤
"""

import os
import sys
import time
import json
import schedule
from datetime import datetime
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

try:
    from core.memory.storage.memory_store import MemoryStore
    from core.utils.logger import get_logger
    logger = get_logger("estia.monitor.consistency")
except ImportError:
    import logging
    logging.basicConfig(level=logging.INFO)
    logger = logging.getLogger("estia.monitor.consistency")

class DataConsistencyMonitor:
    """æ•°æ®ä¸€è‡´æ€§ç›‘æ§å™¨"""
    
    def __init__(self, 
                 db_path: str = None,
                 index_path: str = None,
                 report_dir: str = "logs/consistency_reports",
                 auto_repair: bool = True,
                 alert_threshold: str = "warning"):
        """
        åˆå§‹åŒ–ç›‘æ§å™¨
        
        å‚æ•°:
            db_path: æ•°æ®åº“è·¯å¾„
            index_path: å‘é‡ç´¢å¼•è·¯å¾„  
            report_dir: æŠ¥å‘Šå­˜å‚¨ç›®å½•
            auto_repair: æ˜¯å¦è‡ªåŠ¨ä¿®å¤é—®é¢˜
            alert_threshold: å‘Šè­¦é˜ˆå€¼ ("healthy", "warning", "critical")
        """
        self.db_path = db_path or os.path.join("assets", "memory.db")
        self.index_path = index_path or os.path.join("data", "vectors", "memory_index.bin")
        self.report_dir = report_dir
        self.auto_repair = auto_repair
        self.alert_threshold = alert_threshold
        
        # ç¡®ä¿æŠ¥å‘Šç›®å½•å­˜åœ¨
        os.makedirs(self.report_dir, exist_ok=True)
        
        self.memory_store = None
        
    def initialize_memory_store(self):
        """åˆå§‹åŒ–å†…å­˜å­˜å‚¨"""
        try:
            if self.memory_store is None:
                self.memory_store = MemoryStore(
                    db_path=self.db_path,
                    index_path=self.index_path
                )
                logger.info("å†…å­˜å­˜å‚¨åˆå§‹åŒ–æˆåŠŸ")
            return True
        except Exception as e:
            logger.error(f"åˆå§‹åŒ–å†…å­˜å­˜å‚¨å¤±è´¥: {e}")
            return False
    
    def check_consistency(self) -> dict:
        """æ‰§è¡Œä¸€è‡´æ€§æ£€æŸ¥"""
        try:
            if not self.initialize_memory_store():
                return {"status": "error", "error": "æ— æ³•åˆå§‹åŒ–å†…å­˜å­˜å‚¨"}
            
            logger.info("å¼€å§‹æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥...")
            report = self.memory_store.check_data_consistency()
            
            # ä¿å­˜æŠ¥å‘Š
            self.save_report(report)
            
            # è®°å½•æ£€æŸ¥ç»“æœ
            status = report.get("status", "unknown")
            logger.info(f"ä¸€è‡´æ€§æ£€æŸ¥å®Œæˆï¼ŒçŠ¶æ€: {status}")
            
            if status != "healthy":
                logger.warning(f"å‘ç°æ•°æ®ä¸€è‡´æ€§é—®é¢˜: {report.get('recommendations', [])}")
                
                # å¦‚æœå¯ç”¨è‡ªåŠ¨ä¿®å¤ä¸”çŠ¶æ€ä¸æ˜¯é”™è¯¯
                if self.auto_repair and status != "error":
                    self.auto_repair_issues(report)
            else:
                logger.info("æ•°æ®ä¸€è‡´æ€§æ­£å¸¸")
            
            return report
            
        except Exception as e:
            logger.error(f"ä¸€è‡´æ€§æ£€æŸ¥å¤±è´¥: {e}")
            return {"status": "error", "error": str(e)}
    
    def auto_repair_issues(self, consistency_report: dict):
        """è‡ªåŠ¨ä¿®å¤æ•°æ®ä¸€è‡´æ€§é—®é¢˜"""
        try:
            logger.info("å¼€å§‹è‡ªåŠ¨ä¿®å¤æ•°æ®ä¸€è‡´æ€§é—®é¢˜...")
            
            # ç¡®å®šä¿®å¤é€‰é¡¹
            repair_options = {
                "fix_missing_vectors": len(consistency_report.get("missing_vectors", [])) > 0,
                "remove_orphaned_vectors": len(consistency_report.get("orphaned_vectors", [])) > 0,
                "rebuild_faiss": len(consistency_report.get("faiss_sync_issues", [])) > 0
            }
            
            if any(repair_options.values()):
                repair_result = self.memory_store.repair_data_consistency(repair_options)
                
                # ä¿å­˜ä¿®å¤æŠ¥å‘Š
                self.save_repair_report(repair_result)
                
                repair_status = repair_result.get("status", "unknown")
                logger.info(f"è‡ªåŠ¨ä¿®å¤å®Œæˆï¼ŒçŠ¶æ€: {repair_status}")
                
                if repair_status == "success":
                    logger.info("âœ… æ‰€æœ‰é—®é¢˜å·²æˆåŠŸä¿®å¤")
                elif repair_status == "partial_success":
                    logger.warning("âš ï¸ éƒ¨åˆ†é—®é¢˜å·²ä¿®å¤ï¼Œä»æœ‰é”™è¯¯")
                else:
                    logger.error("âŒ è‡ªåŠ¨ä¿®å¤å¤±è´¥")
            else:
                logger.info("æ²¡æœ‰éœ€è¦ä¿®å¤çš„é—®é¢˜")
                
        except Exception as e:
            logger.error(f"è‡ªåŠ¨ä¿®å¤å¤±è´¥: {e}")
    
    def save_report(self, report: dict):
        """ä¿å­˜ä¸€è‡´æ€§æ£€æŸ¥æŠ¥å‘Š"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            report_file = os.path.join(self.report_dir, f"consistency_report_{timestamp}.json")
            
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(report, f, ensure_ascii=False, indent=2)
            
            logger.debug(f"ä¸€è‡´æ€§æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
            
        except Exception as e:
            logger.error(f"ä¿å­˜ä¸€è‡´æ€§æŠ¥å‘Šå¤±è´¥: {e}")
    
    def save_repair_report(self, repair_result: dict):
        """ä¿å­˜ä¿®å¤æŠ¥å‘Š"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            repair_file = os.path.join(self.report_dir, f"repair_report_{timestamp}.json")
            
            with open(repair_file, 'w', encoding='utf-8') as f:
                json.dump(repair_result, f, ensure_ascii=False, indent=2)
            
            logger.debug(f"ä¿®å¤æŠ¥å‘Šå·²ä¿å­˜: {repair_file}")
            
        except Exception as e:
            logger.error(f"ä¿å­˜ä¿®å¤æŠ¥å‘Šå¤±è´¥: {e}")
    
    def get_summary_stats(self) -> dict:
        """è·å–æ±‡æ€»ç»Ÿè®¡ä¿¡æ¯"""
        try:
            if not self.initialize_memory_store():
                return {"error": "æ— æ³•åˆå§‹åŒ–å†…å­˜å­˜å‚¨"}
            
            # è·å–åŸºæœ¬ç»Ÿè®¡
            stats = self.memory_store.check_data_consistency()
            
            # æ·»åŠ é¢å¤–çš„ç»Ÿè®¡ä¿¡æ¯
            extra_stats = {
                "last_check_time": datetime.now().isoformat(),
                "db_file_size": os.path.getsize(self.db_path) if os.path.exists(self.db_path) else 0,
                "index_file_size": os.path.getsize(self.index_path) if os.path.exists(self.index_path) else 0,
                "auto_repair_enabled": self.auto_repair
            }
            
            stats.update(extra_stats)
            return stats
            
        except Exception as e:
            logger.error(f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            return {"error": str(e)}
    
    def cleanup_old_reports(self, days_to_keep: int = 30):
        """æ¸…ç†æ—§çš„æŠ¥å‘Šæ–‡ä»¶"""
        try:
            current_time = time.time()
            cutoff_time = current_time - (days_to_keep * 24 * 60 * 60)
            
            report_files = os.listdir(self.report_dir)
            deleted_count = 0
            
            for file_name in report_files:
                if file_name.endswith('.json'):
                    file_path = os.path.join(self.report_dir, file_name)
                    file_time = os.path.getmtime(file_path)
                    
                    if file_time < cutoff_time:
                        os.remove(file_path)
                        deleted_count += 1
            
            if deleted_count > 0:
                logger.info(f"æ¸…ç†äº† {deleted_count} ä¸ªæ—§æŠ¥å‘Šæ–‡ä»¶")
            
        except Exception as e:
            logger.error(f"æ¸…ç†æ—§æŠ¥å‘Šå¤±è´¥: {e}")

def run_scheduled_check():
    """è¿è¡Œè®¡åˆ’çš„æ£€æŸ¥"""
    logger.info("="*50)
    logger.info("å¼€å§‹è®¡åˆ’çš„æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥")
    
    monitor = DataConsistencyMonitor()
    report = monitor.check_consistency()
    
    # è¾“å‡ºå…³é”®ä¿¡æ¯
    status = report.get("status", "unknown")
    total_memories = report.get("total_memories", 0)
    total_vectors = report.get("total_vectors", 0)
    total_faiss = report.get("total_faiss_vectors", 0)
    
    logger.info(f"æ£€æŸ¥å®Œæˆ - çŠ¶æ€: {status}")
    logger.info(f"è®°å¿†æ•°: {total_memories}, å‘é‡æ•°: {total_vectors}, FAISS: {total_faiss}")
    
    if status != "healthy":
        issues = len(report.get("missing_vectors", [])) + len(report.get("orphaned_vectors", [])) + len(report.get("faiss_sync_issues", []))
        logger.warning(f"å‘ç° {issues} ä¸ªé—®é¢˜")
    
    logger.info("="*50)

def setup_monitoring_schedule():
    """è®¾ç½®ç›‘æ§è®¡åˆ’"""
    # æ¯å°æ—¶æ£€æŸ¥ä¸€æ¬¡
    schedule.every().hour.do(run_scheduled_check)
    
    # æ¯å¤©å‡Œæ™¨3ç‚¹æ‰§è¡Œæ·±åº¦æ£€æŸ¥å’Œæ¸…ç†
    schedule.every().day.at("03:00").do(lambda: DataConsistencyMonitor().cleanup_old_reports())
    
    logger.info("ç›‘æ§è®¡åˆ’å·²è®¾ç½®:")
    logger.info("- æ¯å°æ—¶æ‰§è¡Œä¸€è‡´æ€§æ£€æŸ¥")
    logger.info("- æ¯å¤©å‡Œæ™¨3ç‚¹æ¸…ç†æ—§æŠ¥å‘Š")

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='æ•°æ®ä¸€è‡´æ€§ç›‘æ§è„šæœ¬')
    parser.add_argument('--once', action='store_true', help='åªæ‰§è¡Œä¸€æ¬¡æ£€æŸ¥')
    parser.add_argument('--no-repair', action='store_true', help='ç¦ç”¨è‡ªåŠ¨ä¿®å¤')
    parser.add_argument('--stats', action='store_true', help='æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯')
    parser.add_argument('--cleanup', type=int, metavar='DAYS', help='æ¸…ç†æŒ‡å®šå¤©æ•°å‰çš„æ—§æŠ¥å‘Š')
    
    args = parser.parse_args()
    
    # åˆ›å»ºç›‘æ§å™¨
    monitor = DataConsistencyMonitor(auto_repair=not args.no_repair)
    
    if args.stats:
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        stats = monitor.get_summary_stats()
        print("\nğŸ“Š æ•°æ®ä¸€è‡´æ€§ç»Ÿè®¡ä¿¡æ¯:")
        print(json.dumps(stats, ensure_ascii=False, indent=2))
        return
    
    if args.cleanup:
        # æ¸…ç†æ—§æŠ¥å‘Š
        monitor.cleanup_old_reports(args.cleanup)
        print(f"âœ… å·²æ¸…ç† {args.cleanup} å¤©å‰çš„æ—§æŠ¥å‘Š")
        return
    
    if args.once:
        # åªæ‰§è¡Œä¸€æ¬¡æ£€æŸ¥
        print("ğŸ” æ‰§è¡Œå•æ¬¡æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥...")
        report = monitor.check_consistency()
        print(f"âœ… æ£€æŸ¥å®Œæˆï¼ŒçŠ¶æ€: {report.get('status', 'unknown')}")
        return
    
    # å¯åŠ¨å®šæœŸç›‘æ§
    logger.info("ğŸš€ å¯åŠ¨æ•°æ®ä¸€è‡´æ€§ç›‘æ§æœåŠ¡")
    setup_monitoring_schedule()
    
    try:
        while True:
            schedule.run_pending()
            time.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡æ˜¯å¦æœ‰å¾…æ‰§è¡Œçš„ä»»åŠ¡
    except KeyboardInterrupt:
        logger.info("ğŸ‘‹ ç›‘æ§æœåŠ¡å·²åœæ­¢")

if __name__ == "__main__":
    main() 