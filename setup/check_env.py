#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Estia AIåŠ©æ‰‹ - ç¯å¢ƒæ£€æŸ¥è„šæœ¬
æ£€æŸ¥ç³»ç»Ÿç¯å¢ƒã€GPUã€ä¾èµ–åº“å’Œç½‘ç»œè¿æ¥
"""

import os
import sys
import platform
import subprocess
import importlib.util

def print_header(title):
    """æ‰“å°å¸¦æ¡†çš„æ ‡é¢˜"""
    print("\n" + "="*50)
    print(f" {title}")
    print("="*50)

def check_system_info():
    """æ£€æŸ¥ç³»ç»Ÿä¿¡æ¯"""
    print_header("ğŸ–¥ï¸  ç³»ç»Ÿä¿¡æ¯")
    print(f"æ“ä½œç³»ç»Ÿ: {platform.system()} {platform.release()}")
    print(f"Pythonç‰ˆæœ¬: {sys.version}")
    print(f"Pythonè·¯å¾„: {sys.executable}")
    print(f"å·¥ä½œç›®å½•: {os.getcwd()}")

def check_gpu():
    """æ£€æŸ¥GPUç¯å¢ƒ"""
    print_header("ğŸ® GPUç¯å¢ƒæ£€æŸ¥")
    
    # æ£€æŸ¥NVIDIA GPU
    try:
        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)
        if result.returncode == 0:
            print("âœ… NVIDIA GPUæ£€æµ‹æˆåŠŸ")
            # æå–GPUä¿¡æ¯
            lines = result.stdout.split('\n')
            for line in lines:
                if 'GeForce' in line or 'RTX' in line or 'GTX' in line:
                    parts = line.split('|')
                    if len(parts) >= 2:
                        gpu_name = parts[1].strip()
                        print(f"   GPUå‹å·: {gpu_name}")
                if 'CUDA Version' in line:
                    cuda_version = line.split('CUDA Version: ')[1].split()[0]
                    print(f"   CUDAç‰ˆæœ¬: {cuda_version}")
        else:
            print("âŒ æœªæ£€æµ‹åˆ°NVIDIA GPUæˆ–é©±åŠ¨")
    except FileNotFoundError:
        print("âŒ nvidia-smiå‘½ä»¤æœªæ‰¾åˆ°ï¼Œè¯·å®‰è£…NVIDIAé©±åŠ¨")
    except Exception as e:
        print(f"âŒ GPUæ£€æŸ¥å¤±è´¥: {e}")

def check_pytorch():
    """æ£€æŸ¥PyTorchç¯å¢ƒ"""
    print_header("ğŸ”¥ PyTorchç¯å¢ƒæ£€æŸ¥")
    
    try:
        import torch
        print(f"âœ… PyTorchç‰ˆæœ¬: {torch.__version__}")
        print(f"âœ… CUDAå¯ç”¨: {torch.cuda.is_available()}")
        if torch.cuda.is_available():
            print(f"   CUDAè®¾å¤‡æ•°é‡: {torch.cuda.device_count()}")
            for i in range(torch.cuda.device_count()):
                print(f"   è®¾å¤‡ {i}: {torch.cuda.get_device_name(i)}")
        else:
            print("   âš ï¸  è¿è¡Œåœ¨CPUæ¨¡å¼")
    except ImportError:
        print("âŒ PyTorchæœªå®‰è£…")
    except Exception as e:
        print(f"âŒ PyTorchæ£€æŸ¥å¤±è´¥: {e}")

def check_dependencies():
    """æ£€æŸ¥ä¸»è¦ä¾èµ–"""
    print_header("ğŸ“¦ ä¾èµ–åº“æ£€æŸ¥")
    
    dependencies = {
        'whisper': 'è¯­éŸ³è¯†åˆ«',
        'transformers': 'AIæ¨¡å‹åº“',
        'sentence_transformers': 'æ–‡æœ¬å‘é‡åŒ–',
        'faiss': 'å‘é‡æ£€ç´¢',
        'sounddevice': 'éŸ³é¢‘è®¾å¤‡',
        'edge_tts': 'è¯­éŸ³åˆæˆ',
        'keyboard': 'é”®ç›˜æ§åˆ¶',
        'openai': 'OpenAI API'
    }
    
    for package, description in dependencies.items():
        try:
            spec = importlib.util.find_spec(package)
            if spec is not None:
                module = importlib.import_module(package)
                version = getattr(module, '__version__', 'æœªçŸ¥ç‰ˆæœ¬')
                print(f"âœ… {package} ({description}): {version}")
            else:
                print(f"âŒ {package} ({description}): æœªå®‰è£…")
        except Exception as e:
            print(f"âŒ {package} ({description}): å¯¼å…¥å¤±è´¥ - {e}")

def check_hf_environment():
    """æ£€æŸ¥Hugging Faceç¯å¢ƒ"""
    print_header("ğŸ¤— Hugging Faceç¯å¢ƒæ£€æŸ¥")
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    hf_vars = {
        'HF_ENDPOINT': 'APIç«¯ç‚¹',
        'HF_HUB_OFFLINE': 'ç¦»çº¿æ¨¡å¼',
        'HUGGINGFACE_HUB_CACHE': 'ç¼“å­˜ç›®å½•',
        'HF_HOME': 'ä¸»ç›®å½•'
    }
    
    for var, desc in hf_vars.items():
        value = os.environ.get(var, 'æœªè®¾ç½®')
        if value != 'æœªè®¾ç½®':
            print(f"âœ… {var} ({desc}): {value}")
        else:
            print(f"âšª {var} ({desc}): {value}")
    
    # æµ‹è¯•é•œåƒè¿æ¥
    print("\nğŸŒ ç½‘ç»œè¿æ¥æµ‹è¯•:")
    
    try:
        import requests
        
        # æµ‹è¯•å®˜æ–¹æº
        try:
            response = requests.get("https://huggingface.co", timeout=5)
            print(f"âœ… HFå®˜æ–¹æºè¿æ¥: æˆåŠŸ (çŠ¶æ€ç : {response.status_code})")
        except Exception as e:
            print(f"âŒ HFå®˜æ–¹æºè¿æ¥: å¤±è´¥ - {e}")
        
        # æµ‹è¯•é•œåƒæº
        try:
            response = requests.get("https://hf-mirror.com", timeout=5)
            print(f"âœ… HFé•œåƒæºè¿æ¥: æˆåŠŸ (çŠ¶æ€ç : {response.status_code})")
        except Exception as e:
            print(f"âŒ HFé•œåƒæºè¿æ¥: å¤±è´¥ - {e}")
            
    except ImportError:
        print("âŒ requestsåº“æœªå®‰è£…ï¼Œæ— æ³•æµ‹è¯•ç½‘ç»œè¿æ¥")

def check_sentence_transformers():
    """æµ‹è¯•sentence-transformers"""
    print_header("ğŸ”¤ sentence-transformersæµ‹è¯•")
    
    try:
        from sentence_transformers import SentenceTransformer
        print("âœ… sentence-transformerså¯¼å…¥æˆåŠŸ")
        
        # æµ‹è¯•åˆ›å»ºæ¨¡å‹å®ä¾‹ï¼ˆä¸ä¸‹è½½ï¼‰
        print("ğŸ“ æµ‹è¯•æ¨¡å‹é…ç½®...")
        try:
            # è¿™é‡Œä¸ä¼šå®é™…ä¸‹è½½æ¨¡å‹ï¼Œåªæ˜¯æµ‹è¯•é…ç½®
            print("âœ… å¯ä»¥è®¿é—®æ¨¡å‹ä»“åº“é…ç½®")
        except Exception as e:
            print(f"âš ï¸  æ¨¡å‹ä»“åº“è®¿é—®é—®é¢˜: {e}")
            
    except ImportError:
        print("âŒ sentence-transformersæœªå®‰è£…")
    except Exception as e:
        print(f"âŒ sentence-transformersæµ‹è¯•å¤±è´¥: {e}")

def check_whisper():
    """æµ‹è¯•Whisper"""
    print_header("ğŸ¤ Whisperè¯­éŸ³è¯†åˆ«æµ‹è¯•")
    
    try:
        import whisper
        print("âœ… Whisperå¯¼å…¥æˆåŠŸ")
        
        # åˆ—å‡ºå¯ç”¨æ¨¡å‹
        print("ğŸ“‹ å¯ç”¨æ¨¡å‹:")
        models = whisper.available_models()
        for model in models:
            print(f"   - {model}")
            
    except ImportError:
        print("âŒ Whisperæœªå®‰è£…")
    except Exception as e:
        print(f"âŒ Whisperæµ‹è¯•å¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ Estia AIåŠ©æ‰‹ - ç¯å¢ƒæ£€æŸ¥å·¥å…·")
    
    check_system_info()
    check_gpu()
    check_pytorch()
    check_dependencies()
    check_hf_environment()
    check_sentence_transformers()
    check_whisper()
    
    print_header("ğŸ“‹ æ£€æŸ¥å®Œæˆ")
    print("ğŸ’¡ æç¤º:")
    print("   - å¦‚æœæœ‰âŒæ ‡è®°ï¼Œè¯´æ˜å¯¹åº”ç»„ä»¶éœ€è¦å®‰è£…æˆ–é…ç½®")
    print("   - GPUå’ŒCUDAç¯å¢ƒå¯¹æ€§èƒ½å¾ˆé‡è¦")
    print("   - HFé•œåƒæºå¯ä»¥è§£å†³ç½‘ç»œé—®é¢˜")
    print("   - è¿è¡Œ install.bat å¯ä»¥è‡ªåŠ¨å®‰è£…æ‰€æœ‰ä¾èµ–")

if __name__ == "__main__":
    main() 