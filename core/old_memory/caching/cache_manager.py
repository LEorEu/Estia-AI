#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç»Ÿä¸€ç¼“å­˜ç®¡ç†å™¨æ¨¡å—

æä¾›ç»Ÿä¸€çš„ç¼“å­˜ç®¡ç†ã€ç›‘æ§ä¸åè°ƒåŠŸèƒ½ï¼Œ
ä½œä¸ºæ‰€æœ‰ç¼“å­˜ç³»ç»Ÿçš„ä¸­å¤®ç®¡æ§ç‚¹
"""

import time
import logging
import threading
from typing import Dict, List, Any, Optional, Set, TypeVar, Generic, Type, Union, Tuple, cast
from pathlib import Path

from .cache_interface import (
    CacheInterface, CacheEvent, CacheEventType, CacheListener, CacheLevel
)

# å°è¯•å¯¼å…¥æ—¥å¿—å·¥å…·
try:
    from core.utils.logger import get_logger
    logger = get_logger("estia.memory.caching.manager")
except ImportError:
    # å¦‚æœè¿˜æ²¡æœ‰æ—¥å¿—å·¥å…·ï¼Œä½¿ç”¨æ ‡å‡†æ—¥å¿—
    logging.basicConfig(level=logging.INFO)
    logger = logging.getLogger("estia.memory.caching.manager")

# å®šä¹‰ç±»å‹å˜é‡
K = TypeVar('K')  # é”®ç±»å‹
V = TypeVar('V')  # å€¼ç±»å‹
M = TypeVar('M')  # å…ƒæ•°æ®ç±»å‹


class CacheManagerStats:
    """ç¼“å­˜ç®¡ç†å™¨ç»Ÿè®¡ä¿¡æ¯ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–ç»Ÿè®¡ä¿¡æ¯"""
        # è®¡æ•°å™¨
        self.total_hits = 0
        self.total_misses = 0
        self.cache_hits: Dict[str, int] = {}  # æŒ‰ç¼“å­˜IDç»Ÿè®¡
        self.level_hits: Dict[str, int] = {}  # æŒ‰ç¼“å­˜çº§åˆ«ç»Ÿè®¡
        self.operations: Dict[str, int] = {}  # æŒ‰æ“ä½œç±»å‹ç»Ÿè®¡
        
        # æ€§èƒ½ç»Ÿè®¡
        self.access_times: List[float] = []
        self.last_maintenance = time.time()
        
    def record_hit(self, cache_id: str, cache_level: str, duration: float):
        """è®°å½•ç¼“å­˜å‘½ä¸­"""
        self.total_hits += 1
        
        if cache_id in self.cache_hits:
            self.cache_hits[cache_id] += 1
        else:
            self.cache_hits[cache_id] = 1
            
        if cache_level in self.level_hits:
            self.level_hits[cache_level] += 1
        else:
            self.level_hits[cache_level] = 1
            
        self.access_times.append(duration)
        
    def record_miss(self):
        """è®°å½•ç¼“å­˜æœªå‘½ä¸­"""
        self.total_misses += 1
        
    def record_operation(self, operation: str):
        """è®°å½•æ“ä½œ"""
        if operation in self.operations:
            self.operations[operation] += 1
        else:
            self.operations[operation] = 1
    
    def get_hit_ratio(self) -> float:
        """è·å–å‘½ä¸­ç‡"""
        total = self.total_hits + self.total_misses
        return self.total_hits / total if total > 0 else 0
        
    def get_average_access_time(self) -> float:
        """è·å–å¹³å‡è®¿é—®æ—¶é—´(æ¯«ç§’)"""
        if not self.access_times:
            return 0
        return sum(self.access_times) / len(self.access_times) * 1000
    
    def get_stats_summary(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡æ‘˜è¦"""
        return {
            "hit_ratio": self.get_hit_ratio(),
            "total_hits": self.total_hits,
            "total_misses": self.total_misses,
            "average_access_time_ms": self.get_average_access_time(),
            "cache_hits": self.cache_hits.copy(),
            "level_hits": self.level_hits.copy(),
            "operations": self.operations.copy()
        }
        
    def reset(self):
        """é‡ç½®ç»Ÿè®¡æ•°æ®"""
        self.__init__()


class UnifiedCacheManager(CacheListener, Generic[K, V, M]):
    """
    ç»Ÿä¸€ç¼“å­˜ç®¡ç†å™¨
    
    è´Ÿè´£åè°ƒå¤šä¸ªç¼“å­˜ç³»ç»Ÿï¼Œæä¾›é€æ˜çš„ç¼“å­˜è®¿é—®æ¥å£ï¼Œ
    å¹¶å¤„ç†ç¼“å­˜é—´çš„åŒæ­¥ã€äº‹ä»¶ä¼ é€’å’Œç­–ç•¥æ‰§è¡Œ
    """
    
    # å•ä¾‹æ¨¡å¼æ”¯æŒ
    _instance = None
    _lock = threading.RLock()
    
    @classmethod
    def get_instance(cls, *args, **kwargs):
        """è·å–å•ä¾‹å®ä¾‹"""
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = cls(*args, **kwargs)
        return cls._instance
    
    def __init__(self):
        """åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨"""
        # ç¼“å­˜æ³¨å†Œè¡¨
        self.caches: Dict[str, CacheInterface] = {}
        self.level_caches: Dict[CacheLevel, List[CacheInterface]] = {
            level: [] for level in CacheLevel
        }
        
        # ç»Ÿè®¡ä¸ç›‘æ§
        self.stats = CacheManagerStats()
        
        # ç¼“å­˜é”®æ˜ å°„ (ç”¨äºå¿«é€Ÿå®šä½ç¼“å­˜é¡¹æ‰€åœ¨çš„ç¼“å­˜)
        self.key_cache_map: Dict[K, Set[str]] = {}
        
        # ç¼“å­˜ç­–ç•¥é…ç½®
        self.config = {
            "maintenance_interval": 300,  # ç»´æŠ¤é—´éš”(ç§’)
            "propagation_enabled": True,  # æ˜¯å¦å¯ç”¨è·¨ç¼“å­˜ä¼ æ’­
            "auto_promote": True,         # æ˜¯å¦è‡ªåŠ¨æå‡é¢‘ç¹ä½¿ç”¨çš„é¡¹
            "sync_on_write": True,        # å†™æ“ä½œæ˜¯å¦åŒæ­¥åˆ°å…¶ä»–ç¼“å­˜
            "sync_on_delete": True        # åˆ é™¤æ“ä½œæ˜¯å¦åŒæ­¥åˆ°å…¶ä»–ç¼“å­˜
        }
        
        # åˆå§‹åŒ–ç»´æŠ¤å®šæ—¶å™¨
        self._schedule_maintenance()
        
        logger.info("ç»Ÿä¸€ç¼“å­˜ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def register_cache(self, cache: CacheInterface) -> None:
        """
        æ³¨å†Œç¼“å­˜ç³»ç»Ÿ
        
        å‚æ•°:
            cache: å®ç°CacheInterfaceçš„ç¼“å­˜ç³»ç»Ÿ
        """
        cache_id = cache.cache_id
        
        # ğŸ”¥ å…³é”®ä¿®å¤ï¼šå¦‚æœå·²æ³¨å†Œï¼Œå…ˆæ¸…ç†æ—§çš„ç¼“å­˜
        if cache_id in self.caches:
            logger.warning(f"ç¼“å­˜ç³»ç»Ÿ {cache_id} å·²æ³¨å†Œï¼Œå°†è¢«æ›¿æ¢")
            old_cache = self.caches[cache_id]
            old_level = old_cache.get_cache_level()
            
            # ä»çº§åˆ«åˆ—è¡¨ä¸­ç§»é™¤æ—§ç¼“å­˜
            if old_cache in self.level_caches[old_level]:
                self.level_caches[old_level].remove(old_cache)
            
            # ç§»é™¤æ—§çš„äº‹ä»¶ç›‘å¬
            old_cache.remove_listener(self)
            
        # æ³¨å†Œç¼“å­˜
        self.caches[cache_id] = cache
        
        # æŒ‰ç¼“å­˜çº§åˆ«å½’ç±» (ç°åœ¨ä¸ä¼šé‡å¤äº†)
        cache_level = cache.get_cache_level()
        self.level_caches[cache_level].append(cache)
        
        # æ·»åŠ äº‹ä»¶ç›‘å¬
        cache.add_listener(self)
        
        # é€šçŸ¥ç¼“å­˜åˆå§‹åŒ–äº‹ä»¶
        cache.notify_listeners(CacheEvent(
            event_type=CacheEventType.INIT,
            cache_id=cache_id,
            metadata={"manager_id": id(self)}
        ))
        
        logger.info(f"æ³¨å†Œç¼“å­˜ç³»ç»Ÿ: {cache_id}, çº§åˆ«: {cache_level.value}")
    
    def unregister_cache(self, cache_id: str) -> bool:
        """
        æ³¨é”€ç¼“å­˜ç³»ç»Ÿ
        
        å‚æ•°:
            cache_id: ç¼“å­˜ç³»ç»ŸID
            
        è¿”å›:
            æ˜¯å¦æˆåŠŸæ³¨é”€
        """
        if cache_id not in self.caches:
            logger.warning(f"ç¼“å­˜ç³»ç»Ÿ {cache_id} æœªæ³¨å†Œ")
            return False
            
        cache = self.caches[cache_id]
        
        # ä»çº§åˆ«åˆ—è¡¨ä¸­ç§»é™¤
        cache_level = cache.get_cache_level()
        if cache in self.level_caches[cache_level]:
            self.level_caches[cache_level].remove(cache)
        
        # ç§»é™¤ç›‘å¬å™¨
        cache.remove_listener(self)
        
        # ä»æ³¨å†Œè¡¨åˆ é™¤
        del self.caches[cache_id]
        
        # æ›´æ–°é”®æ˜ å°„
        self._update_key_cache_map()
        
        logger.info(f"æ³¨é”€ç¼“å­˜ç³»ç»Ÿ: {cache_id}")
        return True
    
    def get(self, key: K, default: Optional[V] = None) -> Optional[V]:
        """
        ä»ç¼“å­˜è·å–å€¼ï¼ŒæŒ‰ä¼˜å…ˆçº§é¡ºåºæŸ¥æ‰¾
        
        å‚æ•°:
            key: ç¼“å­˜é”®
            default: é»˜è®¤è¿”å›å€¼
            
        è¿”å›:
            ç¼“å­˜å€¼æˆ–é»˜è®¤å€¼
        """
        start_time = time.time()
        
        # 1. å¦‚æœé”®æ˜ å°„ä¸­æœ‰è®°å½•ï¼Œä¼˜å…ˆæŸ¥æ‰¾å·²çŸ¥ç¼“å­˜
        if key in self.key_cache_map:
            for cache_id in self.key_cache_map[key]:
                if cache_id in self.caches:
                    cache = self.caches[cache_id]
                    value = cache.get(key, None)
                    if value is not None:
                        duration = time.time() - start_time
                        self.stats.record_hit(cache_id, cache.get_cache_level().value, duration)
                        self.stats.record_operation("get")
                        return value
        
        # 2. æŒ‰ç¼“å­˜çº§åˆ«é¡ºåºæŸ¥æ‰¾
        for level in [CacheLevel.HOT, CacheLevel.WARM, CacheLevel.COLD, CacheLevel.PERSISTENT]:
            for cache in self.level_caches[level]:
                value = cache.get(key, None)
                if value is not None:
                    # æ›´æ–°é”®æ˜ å°„
                    if key not in self.key_cache_map:
                        self.key_cache_map[key] = set()
                    self.key_cache_map[key].add(cache.cache_id)
                    
                    duration = time.time() - start_time
                    self.stats.record_hit(cache.cache_id, level.value, duration)
                    self.stats.record_operation("get")
                    
                    # è€ƒè™‘æ˜¯å¦éœ€è¦å°†è¯¥é¡¹æå‡åˆ°æ›´é«˜çº§åˆ«ç¼“å­˜
                    if self.config["auto_promote"]:
                        self._consider_promotion(key, value, cache)
                        
                    return value
        
        # æœªæ‰¾åˆ°
        self.stats.record_miss()
        self.stats.record_operation("get_miss")
        return default
    
    def put(self, key: K, value: V, metadata: Optional[M] = None,
            target_levels: Optional[List[CacheLevel]] = None) -> None:
        """
        æ·»åŠ é¡¹åˆ°ç¼“å­˜ï¼Œå¯æŒ‡å®šç›®æ ‡ç¼“å­˜çº§åˆ«
        
        å‚æ•°:
            key: ç¼“å­˜é”®
            value: ç¼“å­˜å€¼
            metadata: ç¼“å­˜å…ƒæ•°æ®
            target_levels: ç›®æ ‡ç¼“å­˜çº§åˆ«åˆ—è¡¨ï¼Œé»˜è®¤ä¸º[HOT]
        """
        # é»˜è®¤æ”¾å…¥HOTçº§åˆ«ç¼“å­˜
        if target_levels is None:
            target_levels = [CacheLevel.HOT]
            
        self.stats.record_operation("put")
        
        # æ·»åŠ åˆ°æŒ‡å®šçº§åˆ«çš„æ‰€æœ‰ç¼“å­˜
        for level in target_levels:
            for cache in self.level_caches[level]:
                cache.put(key, value, metadata)
                
                # æ›´æ–°é”®æ˜ å°„
                if key not in self.key_cache_map:
                    self.key_cache_map[key] = set()
                self.key_cache_map[key].add(cache.cache_id)
                
        # åŒæ­¥åˆ°å…¶ä»–ç¼“å­˜
        if self.config["sync_on_write"]:
            self._propagate_write(key, value, metadata, exclude_levels=target_levels)
    
    def delete(self, key: K) -> bool:
        """
        ä»æ‰€æœ‰ç¼“å­˜ä¸­åˆ é™¤é¡¹
        
        å‚æ•°:
            key: è¦åˆ é™¤çš„é”®
            
        è¿”å›:
            æ˜¯å¦æˆåŠŸåˆ é™¤
        """
        success = False
        self.stats.record_operation("delete")
        
        # ä»å·²çŸ¥ç¼“å­˜ä¸­åˆ é™¤
        if key in self.key_cache_map:
            cache_ids = list(self.key_cache_map[key])
            for cache_id in cache_ids:
                if cache_id in self.caches:
                    if self.caches[cache_id].delete(key):
                        success = True
            # æ³¨æ„ï¼šä¸è¦æ‰‹åŠ¨åˆ é™¤é”®æ˜ å°„ï¼Œè®©äº‹ä»¶å¤„ç†å™¨è‡ªåŠ¨å¤„ç†
        
        # ä»æ‰€æœ‰ç¼“å­˜ä¸­åˆ é™¤(ä»¥é˜²ä¸‡ä¸€)
        if self.config["sync_on_delete"]:
            for cache in self.caches.values():
                if cache.delete(key):
                    success = True
        
        return success
    
    def clear_all(self) -> None:
        """æ¸…ç©ºæ‰€æœ‰ç¼“å­˜"""
        self.stats.record_operation("clear_all")
        
        for cache in self.caches.values():
            cache.clear()
            
        # æ¸…ç©ºé”®æ˜ å°„
        self.key_cache_map.clear()
        
        logger.info("å·²æ¸…ç©ºæ‰€æœ‰ç¼“å­˜")
    
    def get_stats(self) -> Dict[str, Any]:
        """
        è·å–ç»¼åˆç»Ÿè®¡ä¿¡æ¯
        
        è¿”å›:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        stats = {
            "manager": self.stats.get_stats_summary(),
            "caches": {}
        }
        
        # æ”¶é›†å„ç¼“å­˜çš„ç»Ÿè®¡ä¿¡æ¯
        for cache_id, cache in self.caches.items():
            stats["caches"][cache_id] = cache.get_stats()
            
        return stats
    
    def on_event(self, event: CacheEvent) -> None:
        """
        å¤„ç†ç¼“å­˜äº‹ä»¶(å®ç°CacheListeneræ¥å£)
        
        å‚æ•°:
            event: ç¼“å­˜äº‹ä»¶
        """
        # è®°å½•äº‹ä»¶
        self.stats.record_operation(f"event_{event.event_type.value}")
        
        # å¤„ç†ç‰¹å®šäº‹ä»¶
        if event.event_type == CacheEventType.PUT:
            # æ›´æ–°é”®æ˜ å°„
            if event.key not in self.key_cache_map:
                self.key_cache_map[event.key] = set()
            self.key_cache_map[event.key].add(event.cache_id)
            
        elif event.event_type == CacheEventType.DELETE:
            # æ›´æ–°é”®æ˜ å°„
            if event.key in self.key_cache_map and event.cache_id in self.key_cache_map[event.key]:
                self.key_cache_map[event.key].remove(event.cache_id)
                if not self.key_cache_map[event.key]:
                    del self.key_cache_map[event.key]
    
    def _update_key_cache_map(self) -> None:
        """æ›´æ–°é”®-ç¼“å­˜æ˜ å°„"""
        # æ¸…ç©ºç°æœ‰æ˜ å°„
        self.key_cache_map.clear()
        
        # é‡å»ºæ˜ å°„
        for cache_id, cache in self.caches.items():
            for key in cache.get_all_keys():
                if key not in self.key_cache_map:
                    self.key_cache_map[key] = set()
                self.key_cache_map[key].add(cache_id)
    
    def _consider_promotion(self, key: K, value: V, source_cache: CacheInterface) -> None:
        """
        è€ƒè™‘æ˜¯å¦å°†ç¼“å­˜é¡¹æå‡åˆ°æ›´é«˜çº§åˆ«
        
        å‚æ•°:
            key: ç¼“å­˜é”®
            value: ç¼“å­˜å€¼
            source_cache: æºç¼“å­˜
        """
        source_level = source_cache.get_cache_level()
        
        # å¦‚æœå·²ç»æ˜¯æœ€é«˜çº§åˆ«ï¼Œæ— éœ€æå‡
        if source_level == CacheLevel.HOT:
            return
            
        # è·å–å…ƒæ•°æ®(å¦‚æœæœ‰)
        metadata = source_cache.get_metadata(key)
        
        # ç®€å•æå‡è§„åˆ™: ç›´æ¥æå‡åˆ°HOTç¼“å­˜
        target_level = CacheLevel.HOT
        
        # æ‰§è¡Œæå‡
        for cache in self.level_caches[target_level]:
            if cache.cache_id != source_cache.cache_id:  # é¿å…æå‡åˆ°è‡ªå·±
                cache.put(key, value, metadata)
                
                # æ›´æ–°é”®æ˜ å°„
                if key not in self.key_cache_map:
                    self.key_cache_map[key] = set()
                self.key_cache_map[key].add(cache.cache_id)
                
                logger.debug(f"æå‡ç¼“å­˜é¡¹ {key} ä» {source_level.value} åˆ° {target_level.value}")
    
    def _propagate_write(self, key: K, value: V, metadata: Optional[M],
                        exclude_levels: Optional[List[CacheLevel]] = None) -> None:
        """
        ä¼ æ’­å†™æ“ä½œåˆ°å…¶ä»–ç¼“å­˜
        
        å‚æ•°:
            key: ç¼“å­˜é”®
            value: ç¼“å­˜å€¼
            metadata: å…ƒæ•°æ®
            exclude_levels: æ’é™¤çš„ç¼“å­˜çº§åˆ«
        """
        exclude_levels = exclude_levels or []
        
        # ä¼ æ’­åˆ°æŒä¹…åŒ–ç¼“å­˜
        if CacheLevel.PERSISTENT not in exclude_levels:
            for cache in self.level_caches[CacheLevel.PERSISTENT]:
                cache.put(key, value, metadata)
                
                # æ›´æ–°é”®æ˜ å°„
                if key not in self.key_cache_map:
                    self.key_cache_map[key] = set()
                self.key_cache_map[key].add(cache.cache_id)
    
    def _schedule_maintenance(self) -> None:
        """è°ƒåº¦å®šæœŸç»´æŠ¤"""
        interval = self.config["maintenance_interval"]
        
        # æ‰§è¡Œç»´æŠ¤
        self._perform_maintenance()
        
        # è®¡åˆ’ä¸‹æ¬¡ç»´æŠ¤ (å®ˆæŠ¤çº¿ç¨‹é¿å…é˜»å¡è¿›ç¨‹é€€å‡º)
        timer = threading.Timer(interval, self._schedule_maintenance)
        timer.daemon = True
        timer.start()
    
    def _perform_maintenance(self) -> None:
        """æ‰§è¡Œç¼“å­˜ç»´æŠ¤"""
        logger.debug("æ‰§è¡Œç¼“å­˜ç»´æŠ¤...")
        
        # è®°å½•ç»´æŠ¤æ“ä½œ
        self.stats.record_operation("maintenance")
        self.stats.last_maintenance = time.time()
        
        # æ‰§è¡Œé”®æ˜ å°„æ¸…ç†
        self._clean_key_cache_map()
        
        # é€šçŸ¥æ‰€æœ‰ç¼“å­˜æ‰§è¡Œç»´æŠ¤
        for cache in self.caches.values():
            try:
                # å‘é€ç»´æŠ¤äº‹ä»¶
                cache.notify_listeners(CacheEvent(
                    event_type=CacheEventType.MAINTENANCE,
                    cache_id=cache.cache_id
                ))
            except Exception as e:
                logger.error(f"ç¼“å­˜ {cache.cache_id} ç»´æŠ¤å¤±è´¥: {e}")
    
    def _clean_key_cache_map(self) -> None:
        """æ¸…ç†é”®æ˜ å°„ä¸­çš„æ— æ•ˆå¼•ç”¨"""
        to_remove = []
        
        for key, cache_ids in self.key_cache_map.items():
            valid_ids = set()
            for cache_id in cache_ids:
                if cache_id in self.caches and self.caches[cache_id].contains(key):
                    valid_ids.add(cache_id)
            
            if valid_ids:
                self.key_cache_map[key] = valid_ids
            else:
                to_remove.append(key)
        
        # åˆ é™¤æ— æ•ˆé”®
        for key in to_remove:
            del self.key_cache_map[key]
    
    # ============== ä¸šåŠ¡å‹å¥½çš„APIæ–¹æ³• ==============
    
    def record_memory_access(self, memory_id: str, access_weight: float = 1.0) -> None:
        """
        è®°å½•è®°å¿†è®¿é—®ï¼Œæ›´æ–°ç¼“å­˜ä¼˜å…ˆçº§
        
        å‚æ•°:
            memory_id: è®°å¿†ID
            access_weight: è®¿é—®æƒé‡
        """
        try:
            # æ„é€ è®¿é—®è®°å½•é”®
            access_key = f"memory_access_{memory_id}"
            
            # è®°å½•è®¿é—®ä¿¡æ¯
            access_info = {
                "memory_id": memory_id,
                "access_time": time.time(),
                "access_weight": access_weight,
                "access_count": 1
            }
            
            # æ£€æŸ¥æ˜¯å¦å·²æœ‰è®¿é—®è®°å½•
            existing_access = self.get(access_key)  # type: ignore
            if existing_access:
                if hasattr(existing_access, 'get'):
                    access_info["access_count"] = existing_access.get("access_count", 0) + 1  # type: ignore
                    access_info["total_weight"] = existing_access.get("total_weight", 0) + access_weight  # type: ignore
                else:
                    access_info["total_weight"] = access_weight
            else:
                access_info["total_weight"] = access_weight
            
            # å­˜å‚¨åˆ°ç»Ÿä¸€ç¼“å­˜
            self.put(access_key, access_info, {"type": "memory_access"})  # type: ignore
            
            # å°è¯•å§”æ‰˜ç»™æ•°æ®åº“ç¼“å­˜é€‚é…å™¨
            for cache in self.caches.values():
                if hasattr(cache, 'record_memory_access'):
                    try:
                        cache.record_memory_access(memory_id, access_weight)
                        logger.debug(f"å§”æ‰˜è®°å½•è®°å¿†è®¿é—®: {memory_id} -> {cache.cache_id}")
                        break
                    except Exception as e:
                        logger.debug(f"å§”æ‰˜è®°å½•è®¿é—®å¤±è´¥ {cache.cache_id}: {e}")
                        
            logger.debug(f"è®°å½•è®°å¿†è®¿é—®: {memory_id}, æƒé‡: {access_weight}")
            
        except Exception as e:
            logger.error(f"è®°å½•è®°å¿†è®¿é—®å¤±è´¥: {e}")
    
    def get_cached_memories(self, cache_level: str = None, limit: int = 50) -> List[str]:
        """
        è·å–ç¼“å­˜çš„è®°å¿†IDåˆ—è¡¨
        
        å‚æ•°:
            cache_level: ç¼“å­˜çº§åˆ«è¿‡æ»¤('hot', 'warm', Noneä¸ºå…¨éƒ¨)
            limit: è¿”å›æ•°é‡é™åˆ¶
            
        è¿”å›:
            è®°å¿†IDåˆ—è¡¨
        """
        try:
            memory_ids = []
            
            # å°è¯•å§”æ‰˜ç»™æ•°æ®åº“ç¼“å­˜é€‚é…å™¨
            for cache in self.caches.values():
                if hasattr(cache, 'get_cached_memories'):
                    try:
                        cached_ids = cache.get_cached_memories(cache_level, limit)
                        if cached_ids:
                            memory_ids.extend(cached_ids)
                            logger.debug(f"ä» {cache.cache_id} è·å–ç¼“å­˜è®°å¿†: {len(cached_ids)} æ¡")
                            break
                    except Exception as e:
                        logger.debug(f"ä» {cache.cache_id} è·å–ç¼“å­˜è®°å¿†å¤±è´¥: {e}")
            
            # å¦‚æœæ²¡æœ‰å§”æ‰˜æˆåŠŸï¼Œä»è®¿é—®è®°å½•ä¸­æ¨å¯¼
            if not memory_ids:
                access_keys = [key for key in self.key_cache_map.keys() 
                             if str(key).startswith("memory_access_")]
                
                # æŒ‰è®¿é—®æƒé‡æ’åº
                access_records = []
                for key in access_keys:
                    access_info = self.get(key)
                    if access_info:
                        memory_id = access_info.get("memory_id", str(key).replace("memory_access_", ""))
                        weight = access_info.get("total_weight", 0)
                        access_records.append((memory_id, weight))
                
                # æ’åºå¹¶å–å‰Nä¸ª
                access_records.sort(key=lambda x: x[1], reverse=True)
                memory_ids = [record[0] for record in access_records[:limit]]
                
                logger.debug(f"ä»è®¿é—®è®°å½•æ¨å¯¼ç¼“å­˜è®°å¿†: {len(memory_ids)} æ¡")
            
            return memory_ids
            
        except Exception as e:
            logger.error(f"è·å–ç¼“å­˜è®°å¿†å¤±è´¥: {e}")
            return []
    
    def search_by_content(self, query: str, limit: int = 10) -> List[Dict[str, Any]]:
        """
        åŸºäºå†…å®¹æœç´¢ç¼“å­˜è®°å¿†
        
        å‚æ•°:
            query: æœç´¢æŸ¥è¯¢
            limit: é™åˆ¶æ•°é‡
            
        è¿”å›:
            è®°å¿†åˆ—è¡¨
        """
        try:
            results = []
            
            # å°è¯•å§”æ‰˜ç»™å…·æœ‰æœç´¢èƒ½åŠ›çš„ç¼“å­˜
            for cache in self.caches.values():
                if hasattr(cache, 'search_by_content'):
                    try:
                        search_results = cache.search_by_content(query, limit)
                        if search_results:
                            results.extend(search_results)
                            logger.debug(f"ä» {cache.cache_id} æœç´¢åˆ°: {len(search_results)} æ¡")
                            break
                    except Exception as e:
                        logger.debug(f"ä» {cache.cache_id} æœç´¢å¤±è´¥: {e}")
            
            return results[:limit]
            
        except Exception as e:
            logger.error(f"å†…å®¹æœç´¢å¤±è´¥: {e}")
            return []
    
    def get_business_cache_stats(self) -> Dict[str, Any]:
        """
        è·å–ä¸šåŠ¡å‹å¥½çš„ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
        
        è¿”å›:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        try:
            # åŸºç¡€ç»Ÿè®¡
            basic_stats = self.get_stats()
            
            # ä¸šåŠ¡ç»Ÿè®¡
            business_stats = {
                "unified_cache_manager": {
                    "total_caches": len(self.caches),
                    "registered_caches": list(self.caches.keys()),
                    "total_keys": len(self.key_cache_map),
                    "hit_ratio": basic_stats["manager"]["hit_ratio"],
                    "average_access_time_ms": basic_stats["manager"]["average_access_time_ms"]
                },
                "cache_details": basic_stats["caches"],
                "memory_access_records": 0,
                "cache_levels": {level.value: len(caches) for level, caches in self.level_caches.items()}
            }
            
            # ç»Ÿè®¡è®¿é—®è®°å½•æ•°é‡
            access_count = len([key for key in self.key_cache_map.keys() 
                              if str(key).startswith("memory_access_")])
            business_stats["memory_access_records"] = access_count
            
            # å°è¯•è·å–å…·ä½“ç¼“å­˜çš„ä¸šåŠ¡ç»Ÿè®¡
            for cache_id, cache in self.caches.items():
                if hasattr(cache, 'get_cache_stats'):
                    try:
                        cache_business_stats = cache.get_cache_stats()
                        business_stats["cache_details"][cache_id].update({
                            "business_stats": cache_business_stats
                        })
                    except Exception as e:
                        logger.debug(f"è·å– {cache_id} ä¸šåŠ¡ç»Ÿè®¡å¤±è´¥: {e}")
            
            return business_stats
            
        except Exception as e:
            logger.error(f"è·å–ä¸šåŠ¡ç¼“å­˜ç»Ÿè®¡å¤±è´¥: {e}")
            return {"error": str(e)}
    
    def clear_memory_cache(self, memory_type: str = None) -> None:
        """
        æ¸…é™¤ç‰¹å®šç±»å‹çš„è®°å¿†ç¼“å­˜
        
        å‚æ•°:
            memory_type: è®°å¿†ç±»å‹ï¼ŒNoneè¡¨ç¤ºæ¸…é™¤æ‰€æœ‰
        """
        try:
            if memory_type is None:
                # æ¸…é™¤æ‰€æœ‰ç¼“å­˜
                self.clear_all()
                logger.info("å·²æ¸…é™¤æ‰€æœ‰ç»Ÿä¸€ç¼“å­˜")
            else:
                # æ¸…é™¤ç‰¹å®šç±»å‹çš„ç¼“å­˜
                to_remove = []
                for key in self.key_cache_map.keys():
                    if memory_type in str(key):
                        to_remove.append(key)
                
                for key in to_remove:
                    self.delete(key)
                
                logger.info(f"å·²æ¸…é™¤ {memory_type} ç±»å‹ç¼“å­˜ï¼Œå…± {len(to_remove)} é¡¹")
            
            # å°è¯•å§”æ‰˜ç»™å…·ä½“ç¼“å­˜
            for cache in self.caches.values():
                if hasattr(cache, 'clear_memory_cache'):
                    try:
                        cache.clear_memory_cache(memory_type)
                    except Exception as e:
                        logger.debug(f"å§”æ‰˜æ¸…é™¤ {cache.cache_id} ç¼“å­˜å¤±è´¥: {e}")
                        
        except Exception as e:
            logger.error(f"æ¸…é™¤è®°å¿†ç¼“å­˜å¤±è´¥: {e}") 