# core/audio/input.py

"""
æœ¬æ¨¡å—è´Ÿè´£å¤„ç†æ‰€æœ‰çš„éŸ³é¢‘è¾“å…¥åŠŸèƒ½ï¼Œä¸»è¦åŒ…å«ä¸¤å¤§æ ¸å¿ƒä»»åŠ¡ï¼š
1. ä»ç”¨æˆ·çš„éº¦å…‹é£å½•åˆ¶éŸ³é¢‘ã€‚
2. ä½¿ç”¨åŸºäº Hugging Face Transformers çš„ Whisper æ¨¡å‹å°†å½•åˆ¶çš„éŸ³é¢‘è½¬å½•æˆæ–‡å­—ã€‚
"""

# -----------------------------------------------------------------------------
# å¯¼å…¥å¿…è¦çš„åº“
# -----------------------------------------------------------------------------

import os                           # å¯¼å…¥ os æ¨¡å—ï¼Œç”¨äºå¤„ç†æ–‡ä»¶å’Œç›®å½•è·¯å¾„ï¼Œå®ç°è·¨å¹³å°å…¼å®¹æ€§ã€‚
from datetime import datetime       # å¯¼å…¥ datetime æ¨¡å—ï¼Œç”¨äºç”Ÿæˆå¸¦æœ‰æ—¶é—´æˆ³çš„å”¯ä¸€æ–‡ä»¶åã€‚

import sounddevice as sd            # å¯¼å…¥ sounddevice åº“ï¼Œè¿™æ˜¯å½•åˆ¶å’Œæ’­æ”¾éŸ³é¢‘çš„æ ¸å¿ƒå·¥å…·ã€‚
import soundfile as sf              # å¯¼å…¥ soundfile åº“ï¼Œç”¨äºå°†å½•åˆ¶çš„éŸ³é¢‘æ•°æ®ä»¥é«˜è´¨é‡çš„ WAV æ ¼å¼ä¿å­˜åˆ°æ–‡ä»¶ã€‚
import numpy as np                  # å¯¼å…¥ numpy åº“ï¼Œsounddevice å½•åˆ¶çš„éŸ³é¢‘æ˜¯ numpy æ•°ç»„æ ¼å¼ï¼Œè¿›è¡Œå¤„ç†æ—¶å¯èƒ½ä¼šç”¨åˆ°ã€‚
import torch                        # å¯¼å…¥ torch (PyTorch)ï¼Œä¸»è¦ç”¨äºæŒ‡å®šæ¨¡å‹è®¡ç®—æ—¶çš„æ•°æ®ç±»å‹å’Œä½¿ç”¨çš„è®¾å¤‡(CPU/GPU)ã€‚
import msvcrt                       # å¯¼å…¥ msvcrt åº“ï¼Œç”¨äºåœ¨ Windows ä¸Šæ£€æµ‹é”®ç›˜è¾“å…¥
import time                         # å¯¼å…¥ time æ¨¡å—ï¼Œç”¨äºå®ç°çŸ­æš‚çš„ç¡çœ 
from pathlib import Path

# é¢„å…ˆè®¾ç½®ç¯å¢ƒå˜é‡æ¥ä½¿ç”¨é¡¹ç›®å†…éƒ¨ç¼“å­˜
project_root = Path(__file__).parent.parent.parent  # å›åˆ°é¡¹ç›®æ ¹ç›®å½•
cache_dir = str(project_root / "cache")

# è®¾ç½®ç¯å¢ƒå˜é‡ä½¿ç”¨é¡¹ç›®å†…éƒ¨ç¼“å­˜
os.environ["HUGGINGFACE_HUB_CACHE"] = cache_dir
os.environ["HF_HOME"] = cache_dir
os.environ["TRANSFORMERS_CACHE"] = cache_dir

# ä¼˜å…ˆä½¿ç”¨ç¦»çº¿æ¨¡å¼ï¼Œå¦‚æœç¼“å­˜å­˜åœ¨çš„è¯
whisper_model_cache = project_root / "cache" / "models--openai--whisper-large-v3-turbo"
if whisper_model_cache.exists():
    # ğŸ”¥ å¼ºåˆ¶ç¦»çº¿æ¨¡å¼ï¼Œé¿å…ä»»ä½•ç½‘ç»œè¿æ¥
    os.environ["HF_HUB_OFFLINE"] = "1"
    os.environ["TRANSFORMERS_OFFLINE"] = "1"
    os.environ["HF_DATASETS_OFFLINE"] = "1"
    os.environ["HF_HUB_DISABLE_TELEMETRY"] = "1"
    os.environ["HF_HUB_DISABLE_SYMLINKS_WARNING"] = "1"
    os.environ["HF_HUB_DISABLE_IMPLICIT_TOKEN"] = "1"
    os.environ["HF_HUB_DISABLE_PROGRESS_BARS"] = "1"
    print(f"âœ… æ£€æµ‹åˆ°é¡¹ç›®ç¼“å­˜ä¸­çš„Whisperæ¨¡å‹ï¼Œä½¿ç”¨å¼ºåˆ¶ç¦»çº¿æ¨¡å¼")
else:
    # å¦‚æœæœ¬åœ°ç¼“å­˜ä¸å­˜åœ¨ï¼Œä½¿ç”¨é•œåƒç«™ä¸‹è½½
    os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"
    print(f"âš ï¸ æœªæ£€æµ‹åˆ°é¡¹ç›®ç¼“å­˜ï¼Œå°†ä½¿ç”¨é•œåƒç«™ä¸‹è½½æ¨¡å‹")

print(f"ğŸ“ Whisperæ¨¡å‹ç¼“å­˜ç›®å½•: {cache_dir}")

from transformers import pipeline   # ä»å¼ºå¤§çš„ transformers åº“ä¸­å¯¼å…¥ pipelineï¼Œè¿™æ˜¯ä½¿ç”¨ Hugging Face æ¨¡å‹æœ€ç®€å•ã€æœ€é«˜æ•ˆçš„æ–¹å¼ã€‚
from config import settings         # ä»æˆ‘ä»¬çš„é…ç½®æ–‡ä»¶ä¸­å¯¼å…¥ settingsï¼Œè¿™æ ·å°±å¯ä»¥æ–¹ä¾¿åœ°ç®¡ç†å’Œæ›´æ”¹æ¨¡å‹IDã€‚


# -----------------------------------------------------------------------------
# åˆå§‹åŒ–è®¾ç½®å’Œæ¨¡å‹åŠ è½½
# -----------------------------------------------------------------------------

# å®šä¹‰å¹¶åˆ›å»ºç”¨äºå­˜æ”¾å½•éŸ³æ–‡ä»¶çš„ç›®å½•è·¯å¾„
# ä½¿ç”¨ os.path.join ç¡®ä¿è·¯å¾„åœ¨ Windows, macOS, Linux ä¸Šéƒ½èƒ½æ­£ç¡®ç»„åˆ
AUDIO_DIR = os.path.join("assets", "audio")
os.makedirs(AUDIO_DIR, exist_ok=True)  # ä½¿ç”¨ os.makedirs åˆ›å»ºç›®å½•ï¼Œexist_ok=True è¡¨ç¤ºå¦‚æœç›®å½•å·²å­˜åœ¨ï¼Œåˆ™ä¸ä¼šæŠ¥é”™ã€‚

# --- æ¨¡å‹åŠ è½½æ ¸å¿ƒéƒ¨åˆ† ---
# è¿™éƒ¨åˆ†ä»£ç åªåœ¨ç¨‹åºå¯åŠ¨æ—¶æ‰§è¡Œä¸€æ¬¡ï¼Œå°†æ¨¡å‹åŠ è½½åˆ°æ˜¾å­˜ä¸­ï¼Œä¹‹åå¯ä»¥å¿«é€Ÿè°ƒç”¨ã€‚
print(f"ğŸš€ æ­£åœ¨ä»é…ç½®åŠ è½½ Whisper æ¨¡å‹: {settings.WHISPER_MODEL_ID}")

# ä½¿ç”¨ transformers.pipeline åˆ›å»ºä¸€ä¸ªè‡ªåŠ¨è¯­éŸ³è¯†åˆ«(ASR)ä»»åŠ¡ç®¡é“
try:
    print(f"ğŸ”„ æ­£åœ¨åŠ è½½Whisperæ¨¡å‹: {settings.WHISPER_MODEL_ID}")
    
    # ğŸ”¥ å¼ºåˆ¶ä½¿ç”¨æœ¬åœ°è·¯å¾„åŠ è½½ï¼Œé¿å…ä»»ä½•ç½‘ç»œè¿æ¥
    if whisper_model_cache.exists():
        # æ‰¾åˆ°æœ¬åœ°æ¨¡å‹è·¯å¾„
        snapshots_dir = whisper_model_cache / "snapshots"
        if snapshots_dir.exists():
            snapshot_dirs = list(snapshots_dir.iterdir())
            if snapshot_dirs:
                local_model_path = str(snapshot_dirs[0])
                print(f"ğŸ“¦ ä½¿ç”¨æœ¬åœ°æ¨¡å‹è·¯å¾„: {local_model_path}")
                
                pipe = pipeline(
                    "automatic-speech-recognition",
                    model=local_model_path,  # ç›´æ¥ä½¿ç”¨æœ¬åœ°è·¯å¾„
                    torch_dtype=torch.float16,
                    device="cuda:0" if torch.cuda.is_available() else "cpu"
                )
                print("ğŸ“± ä½¿ç”¨è®¾å¤‡:", pipe.device)
                print("âœ… Whisper pipeline è®¾ç½®å®Œæˆï¼Œéšæ—¶å¯ä»¥å¼€å§‹è¯†åˆ«ï¼")
            else:
                raise Exception("æœ¬åœ°æ¨¡å‹å¿«ç…§ç›®å½•ä¸ºç©º")
        else:
            raise Exception("æœ¬åœ°æ¨¡å‹å¿«ç…§ç›®å½•ä¸å­˜åœ¨")
    else:
        # å¦‚æœæœ¬åœ°ç¼“å­˜ä¸å­˜åœ¨ï¼Œä½¿ç”¨åœ¨çº¿æ¨¡å¼
        print("âš ï¸ æœ¬åœ°ç¼“å­˜ä¸å­˜åœ¨ï¼Œä½¿ç”¨åœ¨çº¿æ¨¡å¼...")
        pipe = pipeline(
            "automatic-speech-recognition",
            model=settings.WHISPER_MODEL_ID,
            torch_dtype=torch.float16,
            device="cuda:0" if torch.cuda.is_available() else "cpu"
        )
        print("ğŸ“± ä½¿ç”¨è®¾å¤‡:", pipe.device)
        print("âœ… Whisper pipeline è®¾ç½®å®Œæˆï¼Œéšæ—¶å¯ä»¥å¼€å§‹è¯†åˆ«ï¼")
        
except Exception as e:
    print(f"âŒ Whisper æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
    print("âš ï¸ è¯­éŸ³è½¬æ–‡æœ¬åŠŸèƒ½å°†ä¸å¯ç”¨ã€‚")
    
    # å¦‚æœç¦»çº¿æ¨¡å¼å¤±è´¥ï¼Œå°è¯•åœ¨çº¿æ¨¡å¼
    if "HF_HUB_OFFLINE" in os.environ:
        print("ğŸŒ å°è¯•åœ¨çº¿æ¨¡å¼é‡æ–°åŠ è½½...")
        del os.environ["HF_HUB_OFFLINE"]
        del os.environ["TRANSFORMERS_OFFLINE"]
        os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"
        
        try:
            pipe = pipeline(
                "automatic-speech-recognition",
                model=settings.WHISPER_MODEL_ID,
                torch_dtype=torch.float16,
                device="cuda:0" if torch.cuda.is_available() else "cpu"
            )
            print("âœ… åœ¨çº¿æ¨¡å¼åŠ è½½æˆåŠŸï¼")
        except Exception as e2:
            print(f"âŒ åœ¨çº¿æ¨¡å¼ä¹Ÿå¤±è´¥: {str(e2)}")
            pipe = None
    else:
        pipe = None


# -----------------------------------------------------------------------------
# åŠŸèƒ½å‡½æ•°å®šä¹‰
# -----------------------------------------------------------------------------

def record_audio(duration=5, samplerate=16000):
    """
    ä»é»˜è®¤çš„éº¦å…‹é£å½•åˆ¶éŸ³é¢‘ï¼Œæ”¯æŒæŒ‰ç©ºæ ¼é”®æå‰ç»“æŸå½•éŸ³ã€‚

    å‚æ•°:
        duration (int): æœ€å¤§å½•éŸ³æ—¶é•¿ï¼Œå•ä½ä¸ºç§’ã€‚é»˜è®¤æ˜¯ 5 ç§’ã€‚
        samplerate (int): é‡‡æ ·ç‡ï¼Œå•ä½ä¸ºèµ«å…¹(Hz)ã€‚Whisper æ¨¡å‹æ¨èå¹¶è®­ç»ƒæ—¶ä½¿ç”¨çš„é‡‡æ ·ç‡æ˜¯ 16000 Hzã€‚

    è¿”å›:
        str: ä¿å­˜åçš„éŸ³é¢‘æ–‡ä»¶çš„å®Œæ•´è·¯å¾„ã€‚
    """
    # æ‰“å°æç¤ºä¿¡æ¯ï¼Œå‘ŠçŸ¥ç”¨æˆ·å¯ä»¥å¼€å§‹è¯´è¯
    print(f"ğŸ™ï¸  è¯·åœ¨æ¥ä¸‹æ¥çš„ {duration} ç§’å†…è¯´è¯...")
    print("æŒ‰ä¸‹ç©ºæ ¼é”®å¯ä»¥æå‰ç»“æŸå½•éŸ³...")

    # è®¾ç½®å½•éŸ³å‚æ•°
    frames = []
    stream = sd.InputStream(samplerate=samplerate, channels=1, dtype='float32')
    stream.start()
    
    # è®¡ç®—å½•éŸ³ç»“æŸæ—¶é—´
    end_time = time.time() + duration
    recording = True
    
    # å½•éŸ³å¾ªç¯
    try:
        while recording and time.time() < end_time:
            # æ£€æŸ¥æ˜¯å¦æœ‰æŒ‰é”®è¾“å…¥
            if msvcrt.kbhit():
                key = msvcrt.getch().decode('utf-8', errors='ignore')
                if key == ' ':  # ç©ºæ ¼é”®
                    recording = False
                    print("ç”¨æˆ·æŒ‰ä¸‹ç©ºæ ¼é”®ï¼Œæå‰ç»“æŸå½•éŸ³ã€‚")
            
            # è¯»å–éŸ³é¢‘æ•°æ®
            data, overflowed = stream.read(samplerate // 10)  # æ¯æ¬¡è¯»å– 0.1 ç§’çš„æ•°æ®
            frames.append(data.copy())
            time.sleep(0.05)  # çŸ­æš‚ä¼‘çœ ï¼Œé¿å…CPUä½¿ç”¨è¿‡é«˜
            
    finally:
        stream.stop()
        stream.close()
    
    # å°†æ‰€æœ‰å¸§åˆå¹¶åˆ°ä¸€ä¸ªæ•°ç»„
    if frames:
        audio_data = np.concatenate(frames, axis=0)
    else:
        audio_data = np.array([], dtype='float32').reshape(0, 1)
        
    # å¦‚æœæ²¡æœ‰å½•åˆ¶åˆ°ä»»ä½•å†…å®¹ï¼Œè¿”å›None
    if len(audio_data) == 0:
        print("âŒ æœªå½•åˆ¶åˆ°ä»»ä½•éŸ³é¢‘ã€‚")
        return None

    # å½•éŸ³ç»“æŸåç»™äºˆç”¨æˆ·åé¦ˆ
    print("ğŸ¤ å½•éŸ³ç»“æŸã€‚")

    # ---- æ–‡ä»¶ä¿å­˜ ----
    # ä½¿ç”¨å½“å‰æ—¶é—´ç”Ÿæˆä¸€ä¸ªç‹¬ä¸€æ— äºŒçš„æ–‡ä»¶åï¼Œé¿å…æ–‡ä»¶è¢«è¦†ç›–ã€‚
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    # ç»„åˆå‡ºå®Œæ•´çš„æ–‡ä»¶ä¿å­˜è·¯å¾„ã€‚
    filename = os.path.join(AUDIO_DIR, f"record_{timestamp}.wav")

    # ä½¿ç”¨ soundfile.write å°†å½•åˆ¶çš„ numpy æ•°ç»„ (audio_data) ä¿å­˜æˆ WAV æ–‡ä»¶ã€‚
    sf.write(filename, audio_data, samplerate)

    # æ‰“å°ä¿å­˜æˆåŠŸçš„ä¿¡æ¯ï¼Œæ–¹ä¾¿è°ƒè¯•ã€‚
    print(f"âœ… å½•éŸ³æ–‡ä»¶å·²ä¿å­˜è‡³: {filename}")

    # è¿”å›ä¿å­˜çš„æ–‡ä»¶è·¯å¾„ï¼Œä»¥ä¾¿åç»­å‡½æ•°å¯ä»¥æ‰¾åˆ°å¹¶å¤„ç†è¿™ä¸ªæ–‡ä»¶ã€‚
    return filename


def transcribe_audio(filepath):
    """
    ä½¿ç”¨é¢„å…ˆåŠ è½½çš„ Whisper pipeline æ¥è½¬å½•æŒ‡å®šçš„éŸ³é¢‘æ–‡ä»¶ã€‚

    å‚æ•°:
        filepath (str): éœ€è¦è¿›è¡Œè¯­éŸ³è¯†åˆ«çš„éŸ³é¢‘æ–‡ä»¶çš„è·¯å¾„ã€‚

    è¿”å›:
        str: ä»éŸ³é¢‘ä¸­è¯†åˆ«å‡ºçš„ä¸­æ–‡æ–‡æœ¬å†…å®¹ã€‚
    """
    # æ£€æŸ¥æ˜¯å¦æˆåŠŸåŠ è½½äº†æ¨¡å‹
    if pipe is None:
        print("âŒ Whisper æ¨¡å‹æœªæˆåŠŸåŠ è½½ï¼Œæ— æ³•è¿›è¡Œè¯­éŸ³è¯†åˆ«")
        return None
    
    # æ‰“å°æç¤ºä¿¡æ¯ï¼Œè¡¨ç¤ºAIæ­£åœ¨è¿›è¡Œæ€è€ƒï¼ˆè½¬å½•ï¼‰ã€‚
    print("ğŸ§  Whisper æ­£åœ¨è¯†åˆ«ä¸­...")

    try:
        # è°ƒç”¨æˆ‘ä»¬å·²ç»åˆ›å»ºå¥½çš„ pipeline (pipe) æ¥å¤„ç†éŸ³é¢‘æ–‡ä»¶ã€‚
        # pipeline ä¼šè‡ªåŠ¨å®ŒæˆéŸ³é¢‘æ–‡ä»¶çš„è¯»å–ã€é¢„å¤„ç†ã€æ¨¡å‹æ¨ç†ç­‰æ‰€æœ‰æ­¥éª¤ã€‚
        # æˆ‘ä»¬é€šè¿‡ generate_kwargs å‚æ•°æ¥ä¼ é€’ç‰¹å®šäºæœ¬æ¬¡è¯†åˆ«çš„æŒ‡ä»¤ã€‚
        result = pipe(
            filepath, 
            generate_kwargs={
                "language": "chinese",  # æŒ‡ç¤º Whisper æˆ‘ä»¬æœŸæœ›å¾—åˆ°çš„æ˜¯ä¸­æ–‡ç»“æœã€‚
                "task": "transcribe",   # æ˜ç¡®ä»»åŠ¡æ˜¯"è½¬å½•"ï¼Œè€Œä¸æ˜¯"ç¿»è¯‘"ã€‚
                "return_timestamps": True  # å¯ç”¨æ—¶é—´æˆ³è¿”å›ï¼Œè§£å†³é•¿éŸ³é¢‘é—®é¢˜
            }
        )

        # ä»è¿”å›çš„ç»“æœä¸­æå–æ–‡æœ¬
        if isinstance(result, dict) and "text" in result:
            transcribed_text = result["text"]
        else:
            # å¦‚æœè¿”å›çš„ä¸æ˜¯å­—å…¸æˆ–æ²¡æœ‰textå­—æ®µï¼Œå°è¯•è½¬æ¢ä¸ºå­—ç¬¦ä¸²
            transcribed_text = str(result)
            if "text" in transcribed_text:
                # æå–æ–‡æœ¬å†…å®¹
                import re
                match = re.search(r"'text':\s*'([^']*)'", transcribed_text)
                if match:
                    transcribed_text = match.group(1)

        # æ‰“å°æœ€ç»ˆçš„è¯†åˆ«ç»“æœã€‚
        print(f"ğŸ“ è¯†åˆ«ç»“æœ: {transcribed_text}")

        # å°†çº¯æ–‡æœ¬ç»“æœè¿”å›ç»™è°ƒç”¨è€…ã€‚
        return transcribed_text
    
    except Exception as e:
        print(f"è½¬å½•å¤±è´¥: {str(e)}")
        return None


# -----------------------------------------------------------------------------
# æ¨¡å—ç‹¬ç«‹æµ‹è¯•åŒºåŸŸ
# -----------------------------------------------------------------------------

# è¿™æ®µä»£ç åªæœ‰åœ¨ç›´æ¥è¿è¡Œ `python core/audio_input.py` æ—¶æ‰ä¼šæ‰§è¡Œã€‚
# å¦‚æœè¿™ä¸ªæ–‡ä»¶è¢«å…¶ä»–æ–‡ä»¶ï¼ˆå¦‚ main.pyï¼‰å¯¼å…¥ï¼Œè¿™éƒ¨åˆ†ä»£ç ä¸ä¼šæ‰§è¡Œã€‚
# è¿™ä½¿å¾—æˆ‘ä»¬å¯ä»¥æ–¹ä¾¿åœ°å¯¹æœ¬æ¨¡å—çš„åŠŸèƒ½è¿›è¡Œç‹¬ç«‹æµ‹è¯•ã€‚
if __name__ == '__main__':
    print("\n--- æ­£åœ¨ç‹¬ç«‹æµ‹è¯• audio_input æ¨¡å— ---")
    
    # ç¬¬ä¸€æ­¥ï¼šè°ƒç”¨å½•éŸ³åŠŸèƒ½ï¼Œå½•åˆ¶ä¸€æ®µ5ç§’çš„éŸ³é¢‘ã€‚
    audio_file_path = record_audio(duration=5)
    
    # ç¬¬äºŒæ­¥ï¼šå°†å½•å¥½çš„éŸ³é¢‘æ–‡ä»¶è·¯å¾„ä¼ é€’ç»™è¯†åˆ«åŠŸèƒ½ã€‚
    if audio_file_path:
        recognized_text = transcribe_audio(audio_file_path)
        print("\n--- æµ‹è¯•å®Œæˆ ---")
        print(f"æœ€ç»ˆè¯†åˆ«å‡ºçš„æ–‡æœ¬æ˜¯: '{recognized_text}'")
    else:
        print("\n--- æµ‹è¯•æœªå®Œæˆï¼šæœªå½•åˆ¶åˆ°æœ‰æ•ˆéŸ³é¢‘ ---")