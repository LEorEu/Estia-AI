#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è®°å¿†æµç¨‹ç›‘æ§å™¨
==============

å®ç°13æ­¥è®°å¿†å¤„ç†æµç¨‹çš„å®Œæ•´ç›‘æ§ï¼ŒåŒ…æ‹¬çŠ¶æ€è·Ÿè¸ªã€æ€§èƒ½æµ‹é‡å’Œé”™è¯¯ç›‘æ§ã€‚
"""

import time
import uuid
import threading
from enum import Enum
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Any, Union
from collections import defaultdict
import logging

logger = logging.getLogger(__name__)


class MemoryPipelineStep(Enum):
    """13æ­¥è®°å¿†å¤„ç†æµç¨‹æšä¸¾"""
    # é˜¶æ®µä¸€ï¼šç³»ç»Ÿåˆå§‹åŒ– (Step 1-3)
    STEP_1_DB_INIT = "step_1_database_initialization"
    STEP_2_COMPONENT_INIT = "step_2_component_initialization" 
    STEP_3_ASYNC_INIT = "step_3_async_evaluator_initialization"
    
    # é˜¶æ®µäºŒï¼šå®æ—¶è®°å¿†å¢å¼º (Step 4-9) - æŸ¥è¯¢é˜¶æ®µ
    STEP_4_CACHE_VECTORIZE = "step_4_unified_cache_vectorization"
    STEP_5_FAISS_SEARCH = "step_5_faiss_vector_retrieval"
    STEP_6_ASSOCIATION_EXPAND = "step_6_association_network_expansion"
    STEP_7_HISTORY_AGGREGATE = "step_7_history_dialogue_aggregation"
    STEP_8_WEIGHT_RANKING = "step_8_weight_ranking_deduplication"
    STEP_9_CONTEXT_BUILD = "step_9_final_context_assembly"
    
    # é˜¶æ®µä¸‰ï¼šå¯¹è¯å­˜å‚¨ä¸å¼‚æ­¥è¯„ä¼° (Step 10-14) - å­˜å‚¨é˜¶æ®µ
    STEP_10_LLM_GENERATE = "step_10_llm_response_generation"
    STEP_11_IMMEDIATE_STORE = "step_11_immediate_dialogue_storage"
    STEP_12_ASYNC_EVALUATE = "step_12_async_llm_evaluation"
    STEP_13_SAVE_RESULTS = "step_13_save_evaluation_results"
    STEP_14_CREATE_ASSOCIATIONS = "step_14_auto_association_creation"


class StepStatus(Enum):
    """æ­¥éª¤æ‰§è¡ŒçŠ¶æ€"""
    PENDING = "pending"          # ç­‰å¾…æ‰§è¡Œ
    RUNNING = "running"          # æ­£åœ¨æ‰§è¡Œ
    SUCCESS = "success"          # æ‰§è¡ŒæˆåŠŸ
    FAILED = "failed"            # æ‰§è¡Œå¤±è´¥
    SKIPPED = "skipped"          # è·³è¿‡æ‰§è¡Œ
    TIMEOUT = "timeout"          # æ‰§è¡Œè¶…æ—¶


@dataclass
class MonitorMetrics:
    """ç›‘æ§æŒ‡æ ‡æ•°æ®ç±»"""
    # åŸºç¡€ä¿¡æ¯
    step: MemoryPipelineStep
    session_id: str
    start_time: float
    end_time: Optional[float] = None
    status: StepStatus = StepStatus.PENDING
    
    # æ€§èƒ½æŒ‡æ ‡
    duration: Optional[float] = None
    memory_usage: Optional[float] = None
    cpu_usage: Optional[float] = None
    
    # ä¸šåŠ¡æŒ‡æ ‡
    input_size: Optional[int] = None
    output_size: Optional[int] = None
    processed_count: Optional[int] = None
    cache_hit_rate: Optional[float] = None
    
    # é”™è¯¯ä¿¡æ¯
    error_message: Optional[str] = None
    error_traceback: Optional[str] = None
    
    # æ‰©å±•å…ƒæ•°æ®
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    def finish(self, status: StepStatus, error: Optional[Exception] = None):
        """æ ‡è®°æ­¥éª¤å®Œæˆ"""
        self.end_time = time.time()
        self.duration = self.end_time - self.start_time
        self.status = status
        
        if error:
            self.error_message = str(error)
            self.error_traceback = getattr(error, '__traceback__', None)


@dataclass  
class PipelineSession:
    """æµç¨‹ä¼šè¯ï¼Œè·Ÿè¸ªä¸€æ¬¡å®Œæ•´çš„è®°å¿†å¤„ç†è¿‡ç¨‹"""
    session_id: str
    start_time: float
    phase: str  # 'initialization', 'query_enhancement', 'storage_evaluation'
    
    # æ­¥éª¤ç›‘æ§
    steps: Dict[MemoryPipelineStep, MonitorMetrics] = field(default_factory=dict)
    current_step: Optional[MemoryPipelineStep] = None
    
    # ä¼šè¯çº§æŒ‡æ ‡
    total_duration: Optional[float] = None
    success_count: int = 0
    failed_count: int = 0
    skipped_count: int = 0
    
    # ä¸šåŠ¡ä¸Šä¸‹æ–‡
    user_input: Optional[str] = None
    ai_response: Optional[str] = None
    enhanced_context_size: Optional[int] = None
    retrieved_memories_count: Optional[int] = None
    
    def get_phase_by_step(self, step: MemoryPipelineStep) -> str:
        """æ ¹æ®æ­¥éª¤è·å–æ‰€å±é˜¶æ®µ"""
        if step in [MemoryPipelineStep.STEP_1_DB_INIT, 
                   MemoryPipelineStep.STEP_2_COMPONENT_INIT,
                   MemoryPipelineStep.STEP_3_ASYNC_INIT]:
            return "initialization"
        elif step in [MemoryPipelineStep.STEP_4_CACHE_VECTORIZE,
                     MemoryPipelineStep.STEP_5_FAISS_SEARCH,
                     MemoryPipelineStep.STEP_6_ASSOCIATION_EXPAND,
                     MemoryPipelineStep.STEP_7_HISTORY_AGGREGATE, 
                     MemoryPipelineStep.STEP_8_WEIGHT_RANKING,
                     MemoryPipelineStep.STEP_9_CONTEXT_BUILD]:
            return "query_enhancement"
        else:
            return "storage_evaluation"


class MemoryPipelineMonitor:
    """
    è®°å¿†æµç¨‹ç›‘æ§å™¨
    
    è´Ÿè´£ç›‘æ§13æ­¥è®°å¿†å¤„ç†æµç¨‹çš„æ‰§è¡ŒçŠ¶æ€ã€æ€§èƒ½æŒ‡æ ‡å’Œé”™è¯¯ä¿¡æ¯ã€‚
    æ”¯æŒå®æ—¶ç›‘æ§ã€å†å²åˆ†æå’Œæ€§èƒ½ä¼˜åŒ–å»ºè®®ã€‚
    """
    
    # å•ä¾‹æ¨¡å¼
    _instance = None
    _lock = threading.RLock()
    
    @classmethod
    def get_instance(cls):
        """è·å–å•ä¾‹å®ä¾‹"""
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = cls()
        return cls._instance
    
    def __init__(self):
        """åˆå§‹åŒ–ç›‘æ§å™¨"""
        # ä¼šè¯ç®¡ç†
        self.sessions: Dict[str, PipelineSession] = {}
        self.current_session_id: Optional[str] = None
        
        # å†å²æ•°æ®
        self.completed_sessions: List[PipelineSession] = []
        self.max_history_size = 1000  # æœ€å¤§å†å²è®°å½•æ•°
        
        # æ€§èƒ½ç»Ÿè®¡
        self.step_statistics: Dict[MemoryPipelineStep, Dict[str, Any]] = defaultdict(dict)
        self.phase_statistics: Dict[str, Dict[str, Any]] = defaultdict(dict)
        
        # ç›‘æ§é…ç½®
        self.config = {
            "enable_memory_tracking": True,
            "enable_cpu_tracking": False,  # CPUè·Ÿè¸ªå¯é€‰ï¼Œé¿å…æ€§èƒ½å½±å“
            "step_timeout_seconds": 60,    # æ­¥éª¤è¶…æ—¶æ—¶é—´
            "enable_detailed_logging": True,
            "performance_threshold": {      # æ€§èƒ½å‘Šè­¦é˜ˆå€¼
                "step_duration_ms": 5000,   # å•æ­¥éª¤è¶…è¿‡5ç§’å‘Šè­¦
                "total_duration_ms": 30000, # æ€»æµç¨‹è¶…è¿‡30ç§’å‘Šè­¦
                "memory_usage_mb": 500       # å†…å­˜ä½¿ç”¨è¶…è¿‡500MBå‘Šè­¦
            }
        }
        
        # çº¿ç¨‹å®‰å…¨
        self._lock = threading.RLock()
        
        logger.info("ğŸ“Š è®°å¿†æµç¨‹ç›‘æ§å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def start_session(self, session_id: Optional[str] = None, 
                     user_input: Optional[str] = None) -> str:
        """
        å¼€å§‹æ–°çš„ç›‘æ§ä¼šè¯
        
        å‚æ•°:
            session_id: ä¼šè¯IDï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨ç”Ÿæˆ
            user_input: ç”¨æˆ·è¾“å…¥å†…å®¹
            
        è¿”å›:
            ä¼šè¯ID
        """
        with self._lock:
            if session_id is None:
                session_id = f"session_{int(time.time() * 1000)}_{uuid.uuid4().hex[:8]}"
            
            session = PipelineSession(
                session_id=session_id,
                start_time=time.time(),
                phase="initialization",
                user_input=user_input
            )
            
            self.sessions[session_id] = session
            self.current_session_id = session_id
            
            logger.info(f"ğŸ“Š å¼€å§‹ç›‘æ§ä¼šè¯: {session_id}")
            return session_id
    
    def start_step(self, step: MemoryPipelineStep, 
                   session_id: Optional[str] = None,
                   input_data: Optional[Any] = None) -> MonitorMetrics:
        """
        å¼€å§‹ç›‘æ§æŒ‡å®šæ­¥éª¤
        
        å‚æ•°:
            step: æµç¨‹æ­¥éª¤
            session_id: ä¼šè¯IDï¼Œå¦‚æœä¸ºNoneä½¿ç”¨å½“å‰ä¼šè¯
            input_data: è¾“å…¥æ•°æ®ï¼Œç”¨äºè®¡ç®—è¾“å…¥å¤§å°
            
        è¿”å›:
            ç›‘æ§æŒ‡æ ‡å¯¹è±¡
        """
        with self._lock:
            if session_id is None:
                session_id = self.current_session_id
                
            if session_id is None:
                logger.warning("æ²¡æœ‰æ´»è·ƒçš„ç›‘æ§ä¼šè¯ï¼Œè‡ªåŠ¨åˆ›å»ºæ–°ä¼šè¯")
                session_id = self.start_session()
            
            session = self.sessions.get(session_id)
            if session is None:
                logger.error(f"ä¼šè¯ä¸å­˜åœ¨: {session_id}")
                # åˆ›å»ºä¸€ä¸ªç©ºçš„ç›‘æ§æŒ‡æ ‡ä½œä¸ºé™çº§å¤„ç†
                return MonitorMetrics(
                    step=step,
                    session_id=session_id or "unknown",
                    start_time=time.time(),
                    status=StepStatus.FAILED,
                    error_message="ä¼šè¯ä¸å­˜åœ¨"
                )
            
            # æ›´æ–°ä¼šè¯é˜¶æ®µ
            session.phase = session.get_phase_by_step(step)
            session.current_step = step
            
            # åˆ›å»ºæ­¥éª¤ç›‘æ§æŒ‡æ ‡
            metrics = MonitorMetrics(
                step=step,
                session_id=session_id,
                start_time=time.time(),
                status=StepStatus.RUNNING
            )
            
            # è®¡ç®—è¾“å…¥å¤§å°
            if input_data is not None:
                metrics.input_size = self._calculate_data_size(input_data)
            
            # åˆå§‹å†…å­˜ä½¿ç”¨æƒ…å†µï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if self.config["enable_memory_tracking"]:
                metrics.memory_usage = self._get_memory_usage()
            
            session.steps[step] = metrics
            
            logger.debug(f"ğŸ“Š å¼€å§‹ç›‘æ§æ­¥éª¤: {step.value} (ä¼šè¯: {session_id})")
            return metrics
    
    def finish_step(self, step: MemoryPipelineStep,
                   status: StepStatus = StepStatus.SUCCESS,
                   session_id: Optional[str] = None,
                   output_data: Optional[Any] = None,
                   error: Optional[Exception] = None,
                   metadata: Optional[Dict[str, Any]] = None) -> bool:
        """
        å®Œæˆæ­¥éª¤ç›‘æ§
        
        å‚æ•°:
            step: æµç¨‹æ­¥éª¤
            status: æ­¥éª¤çŠ¶æ€
            session_id: ä¼šè¯ID
            output_data: è¾“å‡ºæ•°æ®
            error: é”™è¯¯ä¿¡æ¯
            metadata: æ‰©å±•å…ƒæ•°æ®
            
        è¿”å›:
            æ˜¯å¦æˆåŠŸå®Œæˆ
        """
        with self._lock:
            if session_id is None:
                session_id = self.current_session_id
                
            if session_id is None:
                logger.error("æ²¡æœ‰æ´»è·ƒçš„ç›‘æ§ä¼šè¯")
                return False
                
            session = self.sessions.get(session_id)
            if session is None or step not in session.steps:
                logger.error(f"æ­¥éª¤ç›‘æ§ä¸å­˜åœ¨: {step.value} (ä¼šè¯: {session_id})")
                return False
            
            metrics = session.steps[step]
            metrics.finish(status, error)
            
            # æ›´æ–°è¾“å‡ºå¤§å°
            if output_data is not None:
                metrics.output_size = self._calculate_data_size(output_data)
            
            # æ›´æ–°å…ƒæ•°æ®
            if metadata:
                metrics.metadata.update(metadata)
            
            # æ›´æ–°ä¼šè¯ç»Ÿè®¡
            if status == StepStatus.SUCCESS:
                session.success_count += 1
            elif status == StepStatus.FAILED:
                session.failed_count += 1
            elif status == StepStatus.SKIPPED:
                session.skipped_count += 1
            
            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            self._update_step_statistics(step, metrics)
            
            # æ€§èƒ½å‘Šè­¦æ£€æŸ¥
            self._check_performance_alerts(metrics)
            
            logger.debug(f"ğŸ“Š å®Œæˆæ­¥éª¤ç›‘æ§: {step.value} -> {status.value} "
                        f"(è€—æ—¶: {metrics.duration:.3f}s)")
            
            return True
    
    def finish_session(self, session_id: Optional[str] = None,
                      ai_response: Optional[str] = None) -> Optional[PipelineSession]:
        """
        å®Œæˆç›‘æ§ä¼šè¯
        
        å‚æ•°:
            session_id: ä¼šè¯ID
            ai_response: AIå›å¤å†…å®¹
            
        è¿”å›:
            å®Œæˆçš„ä¼šè¯å¯¹è±¡
        """
        with self._lock:
            if session_id is None:
                session_id = self.current_session_id
                
            if session_id is None:
                logger.error("æ²¡æœ‰æ´»è·ƒçš„ç›‘æ§ä¼šè¯")
                return None
                
            session = self.sessions.pop(session_id, None)
            if session is None:
                logger.error(f"ä¼šè¯ä¸å­˜åœ¨: {session_id}")
                return None
            
            # è®¡ç®—æ€»è€—æ—¶
            session.total_duration = time.time() - session.start_time
            session.ai_response = ai_response
            
            # è®¡ç®—ä¸šåŠ¡æŒ‡æ ‡
            if session.steps:
                session.enhanced_context_size = sum(
                    step.output_size or 0 for step in session.steps.values()
                    if step.step == MemoryPipelineStep.STEP_9_CONTEXT_BUILD
                )
                
                session.retrieved_memories_count = sum(
                    step.processed_count or 0 for step in session.steps.values()
                    if step.step == MemoryPipelineStep.STEP_5_FAISS_SEARCH
                )
            
            # æ›´æ–°é˜¶æ®µç»Ÿè®¡
            self._update_phase_statistics(session)
            
            # æ·»åŠ åˆ°å†å²è®°å½•
            self.completed_sessions.append(session)
            
            # é™åˆ¶å†å²è®°å½•å¤§å°
            if len(self.completed_sessions) > self.max_history_size:
                self.completed_sessions.pop(0)
            
            # æ¸…é™¤å½“å‰ä¼šè¯
            if self.current_session_id == session_id:
                self.current_session_id = None
            
            logger.info(f"ğŸ“Š å®Œæˆç›‘æ§ä¼šè¯: {session_id} "
                       f"(æ€»è€—æ—¶: {session.total_duration:.3f}s, "
                       f"æˆåŠŸ: {session.success_count}, å¤±è´¥: {session.failed_count})")
            
            return session
    
    def get_current_session(self) -> Optional[PipelineSession]:
        """è·å–å½“å‰ä¼šè¯"""
        if self.current_session_id:
            return self.sessions.get(self.current_session_id)
        return None
    
    def get_session_status(self, session_id: Optional[str] = None) -> Dict[str, Any]:
        """
        è·å–ä¼šè¯çŠ¶æ€æ‘˜è¦
        
        å‚æ•°:
            session_id: ä¼šè¯IDï¼Œå¦‚æœä¸ºNoneä½¿ç”¨å½“å‰ä¼šè¯
            
        è¿”å›:
            ä¼šè¯çŠ¶æ€å­—å…¸
        """
        if session_id is None:
            session_id = self.current_session_id
            
        if session_id is None:
            return {"error": "æ²¡æœ‰æ´»è·ƒçš„ç›‘æ§ä¼šè¯"}
            
        session = self.sessions.get(session_id)
        if session is None:
            return {"error": "ä¼šè¯ä¸å­˜åœ¨"}
        
        running_time = time.time() - session.start_time
        completed_steps = [step for step, metrics in session.steps.items() 
                          if metrics.status in [StepStatus.SUCCESS, StepStatus.FAILED, StepStatus.SKIPPED]]
        
        return {
            "session_id": session_id,
            "phase": session.phase,
            "current_step": session.current_step.value if session.current_step else None,
            "running_time": running_time,
            "completed_steps": len(completed_steps),
            "total_steps": len(session.steps),
            "success_count": session.success_count,
            "failed_count": session.failed_count,
            "skipped_count": session.skipped_count
        }
    
    def get_performance_summary(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½æ‘˜è¦"""
        total_sessions = len(self.completed_sessions)
        if total_sessions == 0:
            return {"message": "æš‚æ— å†å²æ•°æ®"}
        
        # è®¡ç®—å¹³å‡æ€§èƒ½
        avg_duration = sum(s.total_duration or 0 for s in self.completed_sessions) / total_sessions
        success_rate = sum(1 for s in self.completed_sessions 
                          if s.failed_count == 0) / total_sessions
        
        # æœ€æ…¢å’Œæœ€å¿«çš„æ­¥éª¤
        step_durations = defaultdict(list)
        for session in self.completed_sessions:
            for step, metrics in session.steps.items():
                if metrics.duration:
                    step_durations[step].append(metrics.duration)
        
        slowest_step = None
        fastest_step = None
        if step_durations:
            avg_step_times = {step: sum(times) / len(times) 
                             for step, times in step_durations.items()}
            slowest_step = max(avg_step_times.items(), key=lambda x: x[1])
            fastest_step = min(avg_step_times.items(), key=lambda x: x[1])
        
        return {
            "total_sessions": total_sessions,
            "average_duration": avg_duration,
            "success_rate": success_rate,
            "slowest_step": {
                "step": slowest_step[0].value if slowest_step else None,
                "avg_duration": slowest_step[1] if slowest_step else None
            },
            "fastest_step": {
                "step": fastest_step[0].value if fastest_step else None,
                "avg_duration": fastest_step[1] if fastest_step else None
            },
            "step_statistics": dict(self.step_statistics),
            "phase_statistics": dict(self.phase_statistics)
        }
    
    def _calculate_data_size(self, data: Any) -> int:
        """è®¡ç®—æ•°æ®å¤§å°ï¼ˆå­—èŠ‚ï¼‰"""
        try:
            if isinstance(data, str):
                return len(data.encode('utf-8'))
            elif isinstance(data, (list, tuple)):
                return sum(self._calculate_data_size(item) for item in data)
            elif isinstance(data, dict):
                return sum(self._calculate_data_size(k) + self._calculate_data_size(v) 
                          for k, v in data.items())
            else:
                return len(str(data).encode('utf-8'))
        except Exception:
            return 0
    
    def _get_memory_usage(self) -> float:
        """è·å–å½“å‰å†…å­˜ä½¿ç”¨æƒ…å†µï¼ˆMBï¼‰"""
        try:
            import psutil
            process = psutil.Process()
            return process.memory_info().rss / 1024 / 1024
        except ImportError:
            return 0.0
        except Exception:
            return 0.0
    
    def _update_step_statistics(self, step: MemoryPipelineStep, metrics: MonitorMetrics):
        """æ›´æ–°æ­¥éª¤ç»Ÿè®¡ä¿¡æ¯"""
        stats = self.step_statistics[step]
        
        # æ‰§è¡Œæ¬¡æ•°
        stats["count"] = stats.get("count", 0) + 1
        
        # å¹³å‡è€—æ—¶
        if metrics.duration:
            total_duration = stats.get("total_duration", 0) + metrics.duration
            stats["total_duration"] = total_duration
            stats["avg_duration"] = total_duration / stats["count"]
            stats["min_duration"] = min(stats.get("min_duration", float('inf')), metrics.duration)
            stats["max_duration"] = max(stats.get("max_duration", 0), metrics.duration)
        
        # æˆåŠŸç‡
        if metrics.status == StepStatus.SUCCESS:
            stats["success_count"] = stats.get("success_count", 0) + 1
        elif metrics.status == StepStatus.FAILED:
            stats["failed_count"] = stats.get("failed_count", 0) + 1
        
        stats["success_rate"] = stats.get("success_count", 0) / stats["count"]
    
    def _update_phase_statistics(self, session: PipelineSession):
        """æ›´æ–°é˜¶æ®µç»Ÿè®¡ä¿¡æ¯"""
        for phase in ["initialization", "query_enhancement", "storage_evaluation"]:
            phase_steps = [metrics for step, metrics in session.steps.items()
                          if session.get_phase_by_step(step) == phase]
            
            if not phase_steps:
                continue
                
            stats = self.phase_statistics[phase]
            stats["count"] = stats.get("count", 0) + 1
            
            phase_duration = sum(m.duration or 0 for m in phase_steps)
            total_duration = stats.get("total_duration", 0) + phase_duration
            stats["total_duration"] = total_duration
            stats["avg_duration"] = total_duration / stats["count"]
    
    def _check_performance_alerts(self, metrics: MonitorMetrics):
        """æ£€æŸ¥æ€§èƒ½å‘Šè­¦"""
        threshold = self.config["performance_threshold"]
        
        # æ­¥éª¤è€—æ—¶å‘Šè­¦
        if (metrics.duration and 
            metrics.duration * 1000 > threshold["step_duration_ms"]):
            logger.warning(f"âš ï¸ æ­¥éª¤è€—æ—¶å‘Šè­¦: {metrics.step.value} "
                          f"è€—æ—¶ {metrics.duration:.3f}s (é˜ˆå€¼: {threshold['step_duration_ms']/1000}s)")
        
        # å†…å­˜ä½¿ç”¨å‘Šè­¦
        if (metrics.memory_usage and 
            metrics.memory_usage > threshold["memory_usage_mb"]):
            logger.warning(f"âš ï¸ å†…å­˜ä½¿ç”¨å‘Šè­¦: {metrics.step.value} "
                          f"ä½¿ç”¨ {metrics.memory_usage:.1f}MB (é˜ˆå€¼: {threshold['memory_usage_mb']}MB)") 