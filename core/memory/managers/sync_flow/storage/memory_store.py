"""
è®°å¿†å­˜å‚¨ç®¡ç†å™¨ - è´Ÿè´£è®°å¿†çš„å­˜å‚¨ã€æ£€ç´¢å’Œç®¡ç†
æ•´åˆæ•°æ®åº“ç®¡ç†å™¨ã€å‘é‡ç´¢å¼•ç®¡ç†å™¨å’Œæ–‡æœ¬å‘é‡åŒ–å™¨
"""

import os
import time
import json
import uuid
import logging
import numpy as np
from typing import List, Dict, Any, Optional, Union, Tuple
from datetime import datetime
from pathlib import Path

# å¯¼å…¥è®°å¿†ç³»ç»Ÿç»„ä»¶ï¼ˆå‚è€ƒæ—§ç³»ç»Ÿçš„ç®€æ´æ–¹å¼ï¼‰
try:
    from ..init import DatabaseManager, VectorIndexManager
    from ....shared.embedding import TextVectorizer, EmbeddingCache
    from ....utils.logger import get_logger
    logger = get_logger("estia.memory.storage")
except ImportError:
    # å¦‚æœè¿˜æ²¡æœ‰æ—¥å¿—å·¥å…·ï¼Œä½¿ç”¨æ ‡å‡†æ—¥å¿—
    logging.basicConfig(level=logging.INFO)
    logger = logging.getLogger("estia.memory.storage")
    
    # å°è¯•å¯¼å…¥å¿…è¦ç»„ä»¶
    try:
        from ..init import DatabaseManager, VectorIndexManager
    except ImportError:
        logger.error("æ— æ³•å¯¼å…¥DatabaseManageræˆ–VectorIndexManager")
        DatabaseManager = None
        VectorIndexManager = None
    
    try:
        from ....shared.embedding import TextVectorizer, EmbeddingCache
    except ImportError:
        logger.error("æ— æ³•å¯¼å…¥TextVectorizeræˆ–EmbeddingCache")
        TextVectorizer = None
        EmbeddingCache = None

class MemoryStore:
    """
    è®°å¿†å­˜å‚¨ç®¡ç†å™¨ç±»
    è´Ÿè´£è®°å¿†çš„å­˜å‚¨ã€æ£€ç´¢å’Œç®¡ç†
    æ•´åˆæ•°æ®åº“ã€å‘é‡ç´¢å¼•å’Œå‘é‡åŒ–åŠŸèƒ½
    """
    
    def __init__(self, db_manager: Optional["DatabaseManager"] = None,
                 db_path: Optional[str] = None, 
                 index_path: Optional[str] = None,
                 cache_dir: Optional[str] = None,
                 vector_dim: int = 1024,
                 model_type: str = "sentence-transformers",
                 model_name: str = "Qwen/Qwen3-Embedding-0.6B"):
        """
        åˆå§‹åŒ–è®°å¿†å­˜å‚¨ç®¡ç†å™¨
        
        å‚æ•°:
            db_manager: å¯é€‰çš„å·²å­˜åœ¨çš„æ•°æ®åº“ç®¡ç†å™¨ï¼Œå¦‚æœæä¾›åˆ™å¤ç”¨
            db_path: æ•°æ®åº“è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤è·¯å¾„
            index_path: å‘é‡ç´¢å¼•è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤è·¯å¾„
            cache_dir: ç¼“å­˜ç›®å½•ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤è·¯å¾„
            vector_dim: å‘é‡ç»´åº¦ï¼Œé»˜è®¤ä¸º1024ï¼ˆé€‚ç”¨äºQwenæ¨¡å‹ï¼‰
            model_type: å‘é‡åŒ–æ¨¡å‹ç±»å‹
            model_name: å‘é‡åŒ–æ¨¡å‹åç§°
        """
        # è®¾ç½®é»˜è®¤è·¯å¾„ - ä½¿ç”¨ç»Ÿä¸€çš„é…ç½®
        if db_path is None:
            try:
                from .. import get_default_db_path
                db_path = get_default_db_path()
            except ImportError:
                # å¤‡ç”¨æ–¹æ¡ˆ
                db_path = os.path.join("assets", "memory.db")
            
        if index_path is None:
            index_path = os.path.join("data", "vectors", "memory_index.bin")
            
        if cache_dir is None:
            # ä½¿ç”¨data/memory/cacheä½œä¸ºè¿è¡Œæ—¶ç¼“å­˜ç›®å½•ï¼ˆä¿æŒç°æœ‰æ•°æ®ï¼‰
            cache_dir = os.path.join("data", "memory", "cache")
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(db_path), exist_ok=True)
        os.makedirs(os.path.dirname(index_path), exist_ok=True)
        os.makedirs(cache_dir, exist_ok=True)
        
        self.db_path = db_path
        self.index_path = index_path
        self.cache_dir = cache_dir
        self.vector_dim = vector_dim
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.vector_index: Optional["VectorIndexManager"] = None
        self.vectorizer: Optional["TextVectorizer"] = None
        
        # ğŸ”¥ ä¼˜åŒ–ï¼šå¤ç”¨å·²å­˜åœ¨çš„æ•°æ®åº“ç®¡ç†å™¨ï¼Œé¿å…é‡å¤åˆå§‹åŒ–
        if db_manager is not None:
            self.db_manager = db_manager
            logger.info(f"âœ… å¤ç”¨ç°æœ‰æ•°æ®åº“ç®¡ç†å™¨: {db_manager.db_path}")
        else:
            self.db_manager = None
            # åˆå§‹åŒ–æ–°çš„æ•°æ®åº“ç®¡ç†å™¨
            self._init_db_manager()
        
        # ğŸ”¥ ä¿®å¤ï¼šå…ˆåˆå§‹åŒ–å‘é‡åŒ–å™¨ï¼Œå†åˆå§‹åŒ–å‘é‡ç´¢å¼•
        # åˆå§‹åŒ–æ–‡æœ¬å‘é‡åŒ–å™¨
        self._init_vectorizer(model_type, model_name)
        
        # åˆå§‹åŒ–å‘é‡ç´¢å¼•ç®¡ç†å™¨ï¼ˆä½¿ç”¨å‘é‡åŒ–å™¨çš„å®é™…ç»´åº¦ï¼‰
        self._init_vector_index()
        
        logger.info(f"è®°å¿†å­˜å‚¨ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆï¼Œæ•°æ®åº“: {db_path}, å‘é‡ç´¢å¼•: {index_path}")
    
    def _init_db_manager(self):
        """åˆå§‹åŒ–æ•°æ®åº“ç®¡ç†å™¨"""
        try:
            if DatabaseManager is None:
                logger.error("DatabaseManagerç±»æœªå¯¼å…¥")
                return
                
            self.db_manager = DatabaseManager(self.db_path)
            if self.db_manager and self.db_manager.connect():
                self.db_manager.initialize_database()
                logger.info(f"æ•°æ®åº“ç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ: {self.db_path}")
            else:
                logger.error("æ•°æ®åº“è¿æ¥å¤±è´¥")
                self.db_manager = None
        except Exception as e:
            logger.error(f"åˆå§‹åŒ–æ•°æ®åº“ç®¡ç†å™¨å¤±è´¥: {e}")
            self.db_manager = None
    
    def _init_vector_index(self):
        """åˆå§‹åŒ–å‘é‡ç´¢å¼•ç®¡ç†å™¨"""
        try:
            if VectorIndexManager is None:
                logger.error("VectorIndexManagerç±»æœªå¯¼å…¥")
                return
                
            # ğŸ”¥ ä¿®å¤ï¼šä½¿ç”¨å‘é‡åŒ–å™¨çš„å®é™…ç»´åº¦
            actual_vector_dim = self.vector_dim  # é»˜è®¤å€¼
            if self.vectorizer and hasattr(self.vectorizer, 'vector_dim'):
                actual_vector_dim = self.vectorizer.vector_dim
                logger.info(f"ä½¿ç”¨å‘é‡åŒ–å™¨çš„å®é™…ç»´åº¦: {actual_vector_dim}")
            else:
                logger.warning(f"æ— æ³•è·å–å‘é‡åŒ–å™¨ç»´åº¦ï¼Œä½¿ç”¨é»˜è®¤å€¼: {actual_vector_dim}")
                
            self.vector_index = VectorIndexManager(
                index_path=self.index_path,
                vector_dim=actual_vector_dim
            )
            
            if self.vector_index and not self.vector_index.available:
                logger.warning("FAISSä¸å¯ç”¨ï¼Œå‘é‡ç´¢å¼•åŠŸèƒ½å°†è¢«ç¦ç”¨")
                return
            
            # åŠ è½½æˆ–åˆ›å»ºç´¢å¼•
            if self.vector_index and os.path.exists(self.index_path):
                success = self.vector_index.load_index()
                if success:
                    logger.info(f"åŠ è½½å‘é‡ç´¢å¼•æˆåŠŸ: {self.index_path}")
                else:
                    logger.warning(f"åŠ è½½å‘é‡ç´¢å¼•å¤±è´¥ï¼Œåˆ›å»ºæ–°ç´¢å¼•")
                    self.vector_index.create_index()
            elif self.vector_index:
                self.vector_index.create_index()
                logger.info(f"åˆ›å»ºæ–°å‘é‡ç´¢å¼•: {self.index_path}")
        except Exception as e:
            logger.error(f"åˆå§‹åŒ–å‘é‡ç´¢å¼•ç®¡ç†å™¨å¤±è´¥: {e}")
            self.vector_index = None
    
    def _init_vectorizer(self, model_type, model_name):
        """åˆå§‹åŒ–æ–‡æœ¬å‘é‡åŒ–å™¨"""
        try:
            if TextVectorizer is None:
                logger.error("TextVectorizerç±»æœªå¯¼å…¥")
                return
                
            self.vectorizer = TextVectorizer(
                model_type=model_type,
                model_name=model_name,
                cache_dir=self.cache_dir,
                use_cache=True
            )
            logger.info(f"æ–‡æœ¬å‘é‡åŒ–å™¨åˆå§‹åŒ–æˆåŠŸï¼Œæ¨¡å‹: {model_type}/{model_name}")
        except Exception as e:
            logger.error(f"åˆå§‹åŒ–æ–‡æœ¬å‘é‡åŒ–å™¨å¤±è´¥: {e}")
            self.vectorizer = None
    
    def add_memory(self, content: str, source: str = "user", 
                  importance: float = 0.5, metadata: Optional[Dict[str, Any]] = None) -> Optional[str]:
        """
        æ·»åŠ æ–°è®°å¿†
        
        å‚æ•°:
            content: è®°å¿†å†…å®¹
            source: è®°å¿†æ¥æºï¼Œå¦‚"user"ã€"system"ç­‰
            importance: é‡è¦æ€§åˆ†æ•°ï¼Œ0-1ä¹‹é—´
            metadata: å…¶ä»–å…ƒæ•°æ®
            
        è¿”å›:
            Optional[str]: è®°å¿†IDï¼Œå¤±è´¥æ—¶è¿”å›None
        """
        if not content.strip():
            logger.warning("è®°å¿†å†…å®¹ä¸ºç©ºï¼Œä¸æ·»åŠ ")
            return None
            
        if self.db_manager is None:
            logger.error("æ•°æ®åº“ç®¡ç†å™¨æœªåˆå§‹åŒ–ï¼Œæ— æ³•æ·»åŠ è®°å¿†")
            return None
            
        try:
            # ç”Ÿæˆè®°å¿†ID
            memory_id = str(uuid.uuid4())
            
            # è·å–å½“å‰æ—¶é—´æˆ³
            timestamp = int(time.time())
            
            # å‡†å¤‡å…ƒæ•°æ®
            if metadata is None:
                metadata = {}
                
            metadata_json = json.dumps(metadata, ensure_ascii=False)
            
            # æ­¥éª¤1ï¼šå°†è®°å¿†å­˜å…¥æ•°æ®åº“
            self.db_manager.execute_query(
                """
                INSERT INTO memories 
                (id, content, type, role, session_id, timestamp, weight, last_accessed, metadata)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                """,
                (memory_id, content, "memory", source, "", timestamp, importance, timestamp, metadata_json)
            )
            
            # æäº¤æ•°æ®åº“äº‹åŠ¡
            if self.db_manager.conn:
                self.db_manager.conn.commit()
            
            # æ­¥éª¤2ï¼šå¯¹å†…å®¹è¿›è¡Œå‘é‡åŒ–
            vector = self._vectorize_text(content)
            
            if vector is not None:
                # æ­¥éª¤3ï¼šå°†å‘é‡å­˜å…¥å‘é‡è¡¨
                vector_id = f"vec_{memory_id}"
                
                # å°†å‘é‡è½¬æ¢ä¸ºäºŒè¿›åˆ¶æ ¼å¼å­˜å‚¨
                vector_blob = vector.tobytes()
                
                self.db_manager.execute_query(
                    """
                    INSERT INTO memory_vectors
                    (id, memory_id, vector, model_name, timestamp)
                    VALUES (?, ?, ?, ?, ?)
                    """,
                    (vector_id, memory_id, vector_blob, f"{self.vectorizer.model_type}/{self.vectorizer.model_name}", timestamp)
                )
                
                # æäº¤å‘é‡æ•°æ®
                if self.db_manager.conn:
                    self.db_manager.conn.commit()
                
                # æ­¥éª¤4ï¼šå°†å‘é‡æ·»åŠ åˆ°å‘é‡ç´¢å¼•
                if self.vector_index and self.vector_index.available:
                    success = self.vector_index.add_vectors(
                        vectors=vector.reshape(1, -1),
                        ids=[memory_id]
                    )
                    
                    if success:
                        # ä¿å­˜ç´¢å¼•
                        self.vector_index.save_index()
                    else:
                        logger.warning("æ·»åŠ å‘é‡åˆ°ç´¢å¼•å¤±è´¥ï¼Œä½†è®°å¿†å·²ä¿å­˜åˆ°æ•°æ®åº“")
                else:
                    logger.warning("å‘é‡ç´¢å¼•ä¸å¯ç”¨ï¼Œä»…ä¿å­˜åˆ°æ•°æ®åº“")
                
            logger.info(f"æˆåŠŸæ·»åŠ è®°å¿†: {memory_id}, å†…å®¹: {content[:30]}...")
            return memory_id
            
        except Exception as e:
            logger.error(f"æ·»åŠ è®°å¿†å¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return None
    
    def add_interaction_memory(self, content: str, memory_type: str, role: str,
                              session_id: str, timestamp: float, weight: float = 5.0) -> Optional[str]:
        """
        æ·»åŠ äº¤äº’è®°å¿†ï¼ˆä½¿ç”¨äº‹åŠ¡æ€§åŒå†™æœºåˆ¶ï¼‰
        
        å‚æ•°:
            content: è®°å¿†å†…å®¹
            memory_type: è®°å¿†ç±»å‹ï¼ˆuser_input, assistant_replyç­‰ï¼‰
            role: è§’è‰²ï¼ˆuser, assistant, systemï¼‰
            session_id: ä¼šè¯ID
            timestamp: æ—¶é—´æˆ³
            weight: æƒé‡
            
        è¿”å›:
            Optional[str]: è®°å¿†IDï¼Œå¤±è´¥æ—¶è¿”å›None
        """
        if not content.strip():
            logger.warning("è®°å¿†å†…å®¹ä¸ºç©ºï¼Œä¸æ·»åŠ ")
            return None
            
        if self.db_manager is None:
            logger.error("æ•°æ®åº“ç®¡ç†å™¨æœªåˆå§‹åŒ–ï¼Œæ— æ³•æ·»åŠ è®°å¿†")
            return None
        
        # ç”Ÿæˆè®°å¿†ID
        memory_id = f"mem_{uuid.uuid4().hex[:12]}"
            
        # ğŸ”¥ äº‹åŠ¡æ€§åŒå†™æœºåˆ¶å¼€å§‹
        logger.debug(f"å¼€å§‹äº‹åŠ¡æ€§åŒå†™æ“ä½œ: {memory_id}")
        
        # å¼€å§‹æ•°æ®åº“äº‹åŠ¡
        if not self.db_manager.begin_transaction():
            logger.error("æ— æ³•å¼€å§‹æ•°æ®åº“äº‹åŠ¡")
            return None
            
        try:
            # ç¬¬ä¸€æ­¥ï¼šå‡†å¤‡å…ƒæ•°æ®
            metadata = {
                "session_id": session_id,
                "memory_type": memory_type,
                "role": role
            }
            metadata_json = json.dumps(metadata, ensure_ascii=False)
            
            # ç¬¬äºŒæ­¥ï¼šå‘é‡åŒ–ï¼ˆåœ¨äº‹åŠ¡å¤–è¿›è¡Œï¼Œé¿å…é•¿æ—¶é—´é”å®šï¼‰
            vector = self._vectorize_text(content)
            if vector is None:
                self.db_manager.rollback_transaction()
                logger.error(f"æ–‡æœ¬å‘é‡åŒ–å¤±è´¥ï¼Œå›æ»šäº‹åŠ¡: {memory_id}")
                return None
            
            # ç¬¬ä¸‰æ­¥ï¼šåœ¨äº‹åŠ¡ä¸­å­˜å‚¨åˆ°memoriesè¡¨
            result = self.db_manager.execute_in_transaction(
                """
                INSERT INTO memories 
                (id, content, type, role, session_id, timestamp, weight, last_accessed, metadata)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                """,
                (memory_id, content, memory_type, role, session_id, timestamp, weight, timestamp, metadata_json)
            )
            
            if result is None:
                self.db_manager.rollback_transaction()
                logger.error(f"å†™å…¥memoriesè¡¨å¤±è´¥ï¼Œå›æ»šäº‹åŠ¡: {memory_id}")
                return None
            
            # ç¬¬å››æ­¥ï¼šåœ¨äº‹åŠ¡ä¸­å­˜å‚¨å‘é‡åˆ°memory_vectorsè¡¨
            vector_id = f"vec_{memory_id}"
            vector_blob = vector.tobytes()
            model_name = f"{self.vectorizer.model_type}/{self.vectorizer.model_name}" if self.vectorizer else "unknown"
                    
            result = self.db_manager.execute_in_transaction(
                """
                INSERT INTO memory_vectors
                (id, memory_id, vector, model_name, timestamp)
                VALUES (?, ?, ?, ?, ?)
                """,
                (vector_id, memory_id, vector_blob, model_name, timestamp)
            )
            
            if result is None:
                self.db_manager.rollback_transaction()
                logger.error(f"å†™å…¥memory_vectorsè¡¨å¤±è´¥ï¼Œå›æ»šäº‹åŠ¡: {memory_id}")
                return None
                    
            # ç¬¬äº”æ­¥ï¼šå°è¯•FAISSç´¢å¼•æ“ä½œ
            faiss_success = False
            if self.vector_index and self.vector_index.available:
                try:
                    faiss_success = self.vector_index.add_vectors(
                        vectors=vector.reshape(1, -1),
                        ids=[memory_id]
                    )
                    
                    if faiss_success:
                        # ä¿å­˜FAISSç´¢å¼•
                        self.vector_index.save_index()
                        logger.debug(f"FAISSç´¢å¼•æ·»åŠ æˆåŠŸ: {memory_id}")
                    else:
                        logger.error(f"FAISSç´¢å¼•æ·»åŠ å¤±è´¥: {memory_id}")
                except Exception as e:
                    logger.error(f"FAISSç´¢å¼•æ“ä½œå¼‚å¸¸: {e}")
                    faiss_success = False
            else:
                logger.warning("FAISSç´¢å¼•ä¸å¯ç”¨ï¼Œè·³è¿‡å‘é‡ç´¢å¼•")
                faiss_success = True  # å…è®¸åœ¨æ²¡æœ‰FAISSçš„æƒ…å†µä¸‹ç»§ç»­
            
            # ç¬¬å…­æ­¥ï¼šæ ¹æ®FAISSæ“ä½œç»“æœå†³å®šæäº¤æˆ–å›æ»š
            if faiss_success:
                # æäº¤æ•°æ®åº“äº‹åŠ¡
                if self.db_manager.commit_transaction():
                    logger.info(f"âœ… äº‹åŠ¡æ€§åŒå†™æˆåŠŸ: {memory_id}")
                    return memory_id
                else:
                    logger.error(f"æ•°æ®åº“äº‹åŠ¡æäº¤å¤±è´¥: {memory_id}")
                    return None
            else:
                # FAISSå¤±è´¥ï¼Œå›æ»šæ•°æ®åº“äº‹åŠ¡
                self.db_manager.rollback_transaction()
                logger.error(f"âŒ FAISSç´¢å¼•å¤±è´¥ï¼Œå›æ»šæ•°æ®åº“äº‹åŠ¡: {memory_id}")
                return None
            
        except Exception as e:
            # å¼‚å¸¸æƒ…å†µä¸‹å›æ»šäº‹åŠ¡
            self.db_manager.rollback_transaction()
            logger.error(f"âŒ äº¤äº’è®°å¿†å­˜å‚¨å¼‚å¸¸ï¼Œå·²å›æ»šäº‹åŠ¡: {e}")
            return None
    
    def _vectorize_text(self, text: str) -> np.ndarray:
        """
        å°†æ–‡æœ¬å‘é‡åŒ–
        
        å‚æ•°:
            text: è¾“å…¥æ–‡æœ¬
            
        è¿”å›:
            np.ndarray: å‘é‡è¡¨ç¤º
        """
        try:
            # æ£€æŸ¥å‘é‡åŒ–å™¨æ˜¯å¦å¯ç”¨
            if self.vectorizer is None:
                logger.error("å‘é‡åŒ–å™¨æœªåˆå§‹åŒ–")
                return None
                
            # ä½¿ç”¨å‘é‡åŒ–å™¨å°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡
            vector = self.vectorizer.encode(text)
            return vector
        except Exception as e:
            logger.error(f"æ–‡æœ¬å‘é‡åŒ–å¤±è´¥: {e}")
            return None
    
    def search_similar(self, query: str, limit: int = 5) -> List[Dict[str, Any]]:
        """
        æœç´¢ä¸æŸ¥è¯¢æ–‡æœ¬ç›¸ä¼¼çš„è®°å¿†
        
        å‚æ•°:
            query: æŸ¥è¯¢æ–‡æœ¬
            limit: è¿”å›ç»“æœæ•°é‡
            
        è¿”å›:
            List[Dict[str, Any]]: ç›¸ä¼¼è®°å¿†åˆ—è¡¨
        """
        try:
            # å¯¹æŸ¥è¯¢æ–‡æœ¬è¿›è¡Œå‘é‡åŒ–
            query_vector = self._vectorize_text(query)
            
            if query_vector is None:
                logger.error("æŸ¥è¯¢å‘é‡åŒ–å¤±è´¥")
                return []
            
            # åœ¨å‘é‡ç´¢å¼•ä¸­æœç´¢ç›¸ä¼¼å‘é‡
            memory_ids, scores = self.vector_index.search(
                query_vector.reshape(1, -1), 
                k=limit
            )
            
            if not memory_ids:
                logger.info(f"æœªæ‰¾åˆ°ä¸æŸ¥è¯¢ç›¸ä¼¼çš„è®°å¿†: {query[:30]}...")
                return []
            
            # ä»æ•°æ®åº“ä¸­è·å–è®°å¿†è¯¦æƒ…
            placeholders = ','.join(['?'] * len(memory_ids))
            results = self.db_manager.query(
                f"""
                SELECT m.id as memory_id, m.content, m.role as source, m.timestamp as created_at, 
                       m.weight as importance, m.metadata
                FROM memories m
                WHERE m.id IN ({placeholders})
                ORDER BY m.timestamp DESC
                """,
                memory_ids
            )
            
            # æ„å»ºç»“æœåˆ—è¡¨
            memories = []
            for i, row in enumerate(results):
                # æŸ¥æ‰¾å¯¹åº”çš„ç›¸ä¼¼åº¦åˆ†æ•°
                score = 0.0
                for j, mid in enumerate(memory_ids):
                    if mid == row[0]:  # memory_id
                        score = scores[j]
                        break
                
                # è§£æå…ƒæ•°æ®
                try:
                    metadata = json.loads(row[5]) if row[5] else {}
                except:
                    metadata = {}
                
                # æ·»åŠ åˆ°ç»“æœåˆ—è¡¨
                memories.append({
                    "memory_id": row[0],
                    "content": row[1],
                    "source": row[2],
                    "created_at": row[3],
                    "timestamp": datetime.fromtimestamp(row[3]).strftime('%Y-%m-%d %H:%M:%S'),
                    "importance": row[4],
                    "similarity": score,
                    "metadata": metadata
                })
            
            # æŒ‰ç›¸ä¼¼åº¦æ’åº
            memories.sort(key=lambda x: x["similarity"], reverse=True)
            
            logger.info(f"æ‰¾åˆ° {len(memories)} æ¡ä¸æŸ¥è¯¢ç›¸ä¼¼çš„è®°å¿†")
            return memories
            
        except Exception as e:
            logger.error(f"æœç´¢ç›¸ä¼¼è®°å¿†å¤±è´¥: {e}")
            return []
    
    def get_memory(self, memory_id: str) -> Optional[Dict[str, Any]]:
        """
        è·å–æŒ‡å®šIDçš„è®°å¿†
        
        å‚æ•°:
            memory_id: è®°å¿†ID
            
        è¿”å›:
            Optional[Dict[str, Any]]: è®°å¿†è¯¦æƒ…ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å›None
        """
        try:
            result = self.db_manager.query(
                """
                SELECT id as memory_id, content, role as source, timestamp as created_at, 
                       weight as importance, metadata
                FROM memories
                WHERE id = ?
                """,
                (memory_id,)
            )
            
            if not result:
                logger.warning(f"æœªæ‰¾åˆ°è®°å¿†: {memory_id}")
                return None
            
            row = result[0]
            
            # è§£æå…ƒæ•°æ®
            try:
                metadata = json.loads(row[5]) if row[5] else {}
            except:
                metadata = {}
            
            # æ„å»ºè®°å¿†è¯¦æƒ…
            memory = {
                "memory_id": row[0],
                "content": row[1],
                "source": row[2],
                "created_at": row[3],
                "timestamp": datetime.fromtimestamp(row[3]).strftime('%Y-%m-%d %H:%M:%S'),
                "importance": row[4],
                "metadata": metadata
            }
            
            return memory
            
        except Exception as e:
            logger.error(f"è·å–è®°å¿†å¤±è´¥: {e}")
            return None
    
    def update_memory_importance(self, memory_id: str, importance: float) -> bool:
        """
        æ›´æ–°è®°å¿†çš„é‡è¦æ€§åˆ†æ•°
        
        å‚æ•°:
            memory_id: è®°å¿†ID
            importance: æ–°çš„é‡è¦æ€§åˆ†æ•°ï¼Œ0-1ä¹‹é—´
            
        è¿”å›:
            bool: æ˜¯å¦æ›´æ–°æˆåŠŸ
        """
        if self.db_manager is None:
            logger.error("æ•°æ®åº“ç®¡ç†å™¨æœªåˆå§‹åŒ–ï¼Œæ— æ³•æ›´æ–°è®°å¿†")
            return False
            
        try:
            # é™åˆ¶é‡è¦æ€§åˆ†æ•°èŒƒå›´
            importance = max(0.0, min(1.0, importance))
            
            # æ›´æ–°æ•°æ®åº“
            self.db_manager.execute_query(
                """
                UPDATE memories
                SET weight = ?
                WHERE id = ?
                """,
                (importance, memory_id)
            )
            
            # æäº¤äº‹åŠ¡
            if self.db_manager.conn:
                self.db_manager.conn.commit()
            
            logger.info(f"æ›´æ–°è®°å¿†é‡è¦æ€§æˆåŠŸ: {memory_id}, æ–°é‡è¦æ€§: {importance}")
            return True
            
        except Exception as e:
            logger.error(f"æ›´æ–°è®°å¿†é‡è¦æ€§å¤±è´¥: {e}")
            return False
    
    def delete_memory(self, memory_id: str) -> bool:
        """
        åˆ é™¤æŒ‡å®šIDçš„è®°å¿†
        
        å‚æ•°:
            memory_id: è®°å¿†ID
            
        è¿”å›:
            bool: æ˜¯å¦åˆ é™¤æˆåŠŸ
        """
        if self.db_manager is None:
            logger.error("æ•°æ®åº“ç®¡ç†å™¨æœªåˆå§‹åŒ–ï¼Œæ— æ³•åˆ é™¤è®°å¿†")
            return False
            
        try:
            # ä»æ•°æ®åº“ä¸­åˆ é™¤è®°å¿†
            self.db_manager.execute_query(
                "DELETE FROM memories WHERE id = ?",
                (memory_id,)
            )
            
            # åˆ é™¤å¯¹åº”çš„å‘é‡
            self.db_manager.execute_query(
                "DELETE FROM memory_vectors WHERE memory_id = ?",
                (memory_id,)
            )
            
            # æäº¤äº‹åŠ¡
            if self.db_manager.conn:
                self.db_manager.conn.commit()
            
            # ä»å‘é‡ç´¢å¼•ä¸­åˆ é™¤ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if self.vector_index and self.vector_index.available:
                success = self.vector_index.delete_vectors([memory_id])
                if success:
                    self.vector_index.save_index()
            
            logger.info(f"åˆ é™¤è®°å¿†æˆåŠŸ: {memory_id}")
            return True
            
        except Exception as e:
            logger.error(f"åˆ é™¤è®°å¿†å¤±è´¥: {e}")
            return False
    
    def get_recent_memories(self, limit: int = 10) -> List[Dict[str, Any]]:
        """
        è·å–æœ€è¿‘çš„è®°å¿†
        
        å‚æ•°:
            limit: è¿”å›ç»“æœæ•°é‡
            
        è¿”å›:
            List[Dict[str, Any]]: è®°å¿†åˆ—è¡¨
        """
        try:
            results = self.db_manager.query(
                """
                SELECT id as memory_id, content, role as source, timestamp as created_at, 
                       weight as importance, metadata
                FROM memories
                ORDER BY timestamp DESC
                LIMIT ?
                """,
                (limit,)
            )
            
            memories = []
            for row in results:
                # è§£æå…ƒæ•°æ®
                try:
                    metadata = json.loads(row[5]) if row[5] else {}
                except:
                    metadata = {}
                
                # æ·»åŠ åˆ°ç»“æœåˆ—è¡¨
                memories.append({
                    "memory_id": row[0],
                    "content": row[1],
                    "source": row[2],
                    "created_at": row[3],
                    "timestamp": datetime.fromtimestamp(row[3]).strftime('%Y-%m-%d %H:%M:%S'),
                    "importance": row[4],
                    "metadata": metadata
                })
            
            logger.info(f"è·å–æœ€è¿‘ {len(memories)} æ¡è®°å¿†")
            return memories
            
        except Exception as e:
            logger.error(f"è·å–æœ€è¿‘è®°å¿†å¤±è´¥: {e}")
            return []
    
    def get_memories_by_ids(self, memory_ids: List[str]) -> List[Dict[str, Any]]:
        """
        æ ¹æ®IDåˆ—è¡¨æ‰¹é‡è·å–è®°å¿†ï¼ˆå…¼å®¹EstiaMemorySystemæ¥å£ï¼‰
        
        å‚æ•°:
            memory_ids: è®°å¿†IDåˆ—è¡¨
            
        è¿”å›:
            List[Dict[str, Any]]: è®°å¿†åˆ—è¡¨
        """
        if not memory_ids or not self.db_manager:
            return []
        
        try:
            placeholders = ','.join(['?' for _ in memory_ids])
            results = self.db_manager.query(f"""
                SELECT id, content, type, role, session_id, timestamp, weight, group_id, summary, metadata
                FROM memories WHERE id IN ({placeholders})
                ORDER BY timestamp DESC
            """, memory_ids)
            
            memories = []
            for row in results:
                # è§£æå…ƒæ•°æ®
                try:
                    metadata = json.loads(row[9]) if row[9] else {}
                except:
                    metadata = {}
                
                memories.append({
                    'memory_id': row[0],
                    'content': row[1], 
                    'type': row[2],
                    'role': row[3],
                    'session_id': row[4] or "",
                    'timestamp': row[5],
                    'weight': row[6] or 5.0,
                    'group_id': row[7] or "",
                    'summary': row[8] or "",
                    'metadata': metadata
                })
            
            logger.debug(f"æ‰¹é‡è·å– {len(memories)} æ¡è®°å¿†")
            return memories
            
        except Exception as e:
            logger.error(f"æ‰¹é‡è·å–è®°å¿†å¤±è´¥: {e}")
            return []
    
    def add_association(self, source_id: str, target_id: str, 
                       association_type: str = "related", 
                       strength: float = 0.5) -> bool:
        """
        æ·»åŠ è®°å¿†ä¹‹é—´çš„å…³è”
        
        å‚æ•°:
            source_id: æºè®°å¿†ID
            target_id: ç›®æ ‡è®°å¿†ID
            association_type: å…³è”ç±»å‹ï¼Œå¦‚"related"ã€"cause_effect"ç­‰
            strength: å…³è”å¼ºåº¦ï¼Œ0-1ä¹‹é—´
            
        è¿”å›:
            bool: æ˜¯å¦æ·»åŠ æˆåŠŸ
        """
        if self.db_manager is None:
            logger.error("æ•°æ®åº“ç®¡ç†å™¨æœªåˆå§‹åŒ–ï¼Œæ— æ³•æ·»åŠ å…³è”")
            return False
            
        try:
            # ç”Ÿæˆå…³è”ID
            association_id = str(uuid.uuid4())
            
            # è·å–å½“å‰æ—¶é—´æˆ³
            timestamp = int(time.time())
            
            # æ·»åŠ å…³è”
            self.db_manager.execute_query(
                """
                INSERT INTO memory_association
                (id, source_key, target_key, association_type, strength, created_at, last_activated)
                VALUES (?, ?, ?, ?, ?, ?, ?)
                """,
                (association_id, source_id, target_id, association_type, strength, timestamp, timestamp)
            )
            
            # æäº¤äº‹åŠ¡
            if self.db_manager.conn:
                self.db_manager.conn.commit()
            
            logger.info(f"æ·»åŠ è®°å¿†å…³è”æˆåŠŸ: {source_id} -> {target_id}, ç±»å‹: {association_type}")
            return True
            
        except Exception as e:
            logger.error(f"æ·»åŠ è®°å¿†å…³è”å¤±è´¥: {e}")
            return False
    
    def get_associated_memories(self, memory_id: str, 
                              association_type: str = None) -> List[Dict[str, Any]]:
        """
        è·å–ä¸æŒ‡å®šè®°å¿†ç›¸å…³è”çš„è®°å¿†
        
        å‚æ•°:
            memory_id: è®°å¿†ID
            association_type: å…³è”ç±»å‹ï¼Œå¦‚æœä¸ºNoneåˆ™è·å–æ‰€æœ‰ç±»å‹
            
        è¿”å›:
            List[Dict[str, Any]]: å…³è”è®°å¿†åˆ—è¡¨
        """
        try:
            query = """
                SELECT a.id as association_id, a.source_key, a.target_key, 
                       a.association_type, a.strength, a.created_at,
                       m.content, m.role as source, m.weight as importance, m.metadata
                FROM memory_association a
                JOIN memories m ON a.target_key = m.id
                WHERE a.source_key = ?
            """
            
            params = [memory_id]
            
            if association_type:
                query += " AND a.association_type = ?"
                params.append(association_type)
                
            query += " ORDER BY a.strength DESC"
            
            results = self.db_manager.query(query, params)
            
            associations = []
            for row in results:
                # è§£æå…ƒæ•°æ®
                try:
                    metadata = json.loads(row[9]) if row[9] else {}
                except:
                    metadata = {}
                
                # æ·»åŠ åˆ°ç»“æœåˆ—è¡¨
                associations.append({
                    "association_id": row[0],
                    "source_id": row[1],
                    "target_id": row[2],
                    "association_type": row[3],
                    "strength": row[4],
                    "created_at": row[5],
                    "content": row[6],
                    "source": row[7],
                    "importance": row[8],
                    "metadata": metadata
                })
            
            logger.info(f"è·å–è®°å¿†å…³è”æˆåŠŸ: {memory_id}, æ‰¾åˆ° {len(associations)} æ¡å…³è”")
            return associations
            
        except Exception as e:
            logger.error(f"è·å–è®°å¿†å…³è”å¤±è´¥: {e}")
            return []
    
    def close(self):
        """
        å…³é—­èµ„æº
        """
        try:
            if self.vector_index:
                self.vector_index.close()
            if self.db_manager:
                self.db_manager.close()
        except Exception as e:
            logger.error(f"å…³é—­MemoryStoreå¤±è´¥: {e}")
    
    def check_data_consistency(self) -> Dict[str, Any]:
        """
        æ£€æŸ¥æ•°æ®ä¸€è‡´æ€§
        
        è¿”å›:
            Dict[str, Any]: ä¸€è‡´æ€§æ£€æŸ¥æŠ¥å‘Š
        """
        report = {
            "timestamp": datetime.now().isoformat(),
            "status": "unknown",
            "total_memories": 0,
            "total_vectors": 0,
            "total_faiss_vectors": 0,
            "missing_vectors": [],
            "orphaned_vectors": [],
            "faiss_sync_issues": [],
            "recommendations": []
        }
        
        try:
            # æ£€æŸ¥memoriesè¡¨è®°å½•æ•°
            memories_result = self.db_manager.query("SELECT COUNT(*) FROM memories")
            report["total_memories"] = memories_result[0][0] if memories_result else 0
            
            # æ£€æŸ¥memory_vectorsè¡¨è®°å½•æ•°
            vectors_result = self.db_manager.query("SELECT COUNT(*) FROM memory_vectors")
            report["total_vectors"] = vectors_result[0][0] if vectors_result else 0
            
            # æ£€æŸ¥FAISSç´¢å¼•è®°å½•æ•°
            if self.vector_index and self.vector_index.available:
                report["total_faiss_vectors"] = self.vector_index.get_total_count()
            else:
                report["total_faiss_vectors"] = -1  # è¡¨ç¤ºä¸å¯ç”¨
            
            # æŸ¥æ‰¾ç¼ºå¤±å‘é‡çš„è®°å¿†
            missing_vectors_query = """
            SELECT m.id, m.content
            FROM memories m
            LEFT JOIN memory_vectors mv ON m.id = mv.memory_id
            WHERE mv.memory_id IS NULL
            """
            missing_result = self.db_manager.query(missing_vectors_query)
            if missing_result:
                report["missing_vectors"] = [
                    {"memory_id": row[0], "content": row[1][:50] + "..."}
                    for row in missing_result
                ]
            
            # æŸ¥æ‰¾å­¤ç«‹çš„å‘é‡ï¼ˆæ²¡æœ‰å¯¹åº”è®°å¿†ï¼‰
            orphaned_vectors_query = """
            SELECT mv.id, mv.memory_id
            FROM memory_vectors mv
            LEFT JOIN memories m ON mv.memory_id = m.id
            WHERE m.id IS NULL
            """
            orphaned_result = self.db_manager.query(orphaned_vectors_query)
            if orphaned_result:
                report["orphaned_vectors"] = [
                    {"vector_id": row[0], "memory_id": row[1]}
                    for row in orphaned_result
                ]
            
            # æ£€æŸ¥FAISSåŒæ­¥é—®é¢˜
            if report["total_faiss_vectors"] >= 0:
                db_vector_count = report["total_vectors"]
                faiss_vector_count = report["total_faiss_vectors"]
                
                if db_vector_count != faiss_vector_count:
                    report["faiss_sync_issues"].append({
                        "issue": "count_mismatch",
                        "db_count": db_vector_count,
                        "faiss_count": faiss_vector_count,
                        "difference": abs(db_vector_count - faiss_vector_count)
                    })
            
            # ç”ŸæˆçŠ¶æ€è¯„ä¼°
            issues_count = (
                len(report["missing_vectors"]) +
                len(report["orphaned_vectors"]) +
                len(report["faiss_sync_issues"])
            )
            
            if issues_count == 0:
                report["status"] = "healthy"
            elif issues_count <= 3:
                report["status"] = "warning"
            else:
                report["status"] = "critical"
            
            # ç”Ÿæˆå»ºè®®
            if report["missing_vectors"]:
                report["recommendations"].append(
                    f"ä¿®å¤ {len(report['missing_vectors'])} ä¸ªç¼ºå¤±å‘é‡çš„è®°å¿†"
                )
            
            if report["orphaned_vectors"]:
                report["recommendations"].append(
                    f"æ¸…ç† {len(report['orphaned_vectors'])} ä¸ªå­¤ç«‹å‘é‡"
                )
            
            if report["faiss_sync_issues"]:
                report["recommendations"].append(
                    "é‡å»ºFAISSç´¢å¼•ä»¥ä¿®å¤åŒæ­¥é—®é¢˜"
                )
            
            logger.info(f"æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥å®Œæˆï¼ŒçŠ¶æ€: {report['status']}")
            return report
            
        except Exception as e:
            logger.error(f"æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥å¤±è´¥: {e}")
            report["status"] = "error"
            report["error"] = str(e)
            return report
    
    def repair_data_consistency(self, repair_options: Dict[str, bool] = None) -> Dict[str, Any]:
        """
        ä¿®å¤æ•°æ®ä¸€è‡´æ€§é—®é¢˜
        
        å‚æ•°:
            repair_options: ä¿®å¤é€‰é¡¹
                - fix_missing_vectors: ä¸ºç¼ºå¤±å‘é‡çš„è®°å¿†ç”Ÿæˆå‘é‡
                - remove_orphaned_vectors: åˆ é™¤å­¤ç«‹å‘é‡
                - rebuild_faiss: é‡å»ºFAISSç´¢å¼•
        
        è¿”å›:
            Dict[str, Any]: ä¿®å¤ç»“æœæŠ¥å‘Š
        """
        if repair_options is None:
            repair_options = {
                "fix_missing_vectors": True,
                "remove_orphaned_vectors": True,
                "rebuild_faiss": True
            }
        
        repair_report = {
            "timestamp": datetime.now().isoformat(),
            "operations": [],
            "success_count": 0,
            "error_count": 0,
            "status": "unknown"
        }
        
        try:
            # é¦–å…ˆæ£€æŸ¥å½“å‰çŠ¶æ€
            consistency_report = self.check_data_consistency()
            
            # ä¿®å¤ç¼ºå¤±å‘é‡
            if repair_options.get("fix_missing_vectors", False) and consistency_report["missing_vectors"]:
                logger.info("å¼€å§‹ä¿®å¤ç¼ºå¤±å‘é‡...")
                for missing in consistency_report["missing_vectors"]:
                    try:
                        memory_id = missing["memory_id"]
                        
                        # è·å–è®°å¿†å†…å®¹
                        memory_result = self.db_manager.query(
                            "SELECT content, timestamp FROM memories WHERE id = ?",
                            (memory_id,)
                        )
                        
                        if memory_result:
                            content = memory_result[0][0]
                            timestamp = memory_result[0][1]
                            
                            # ç”Ÿæˆå‘é‡
                            vector = self._vectorize_text(content)
                            if vector is not None:
                                vector_id = f"vec_{memory_id}"
                                vector_blob = vector.tobytes()
                                model_name = f"{self.vectorizer.model_type}/{self.vectorizer.model_name}" if self.vectorizer else "unknown"
                                
                                # å­˜å‚¨å‘é‡
                                self.db_manager.execute_query(
                                    """
                                    INSERT INTO memory_vectors
                                    (id, memory_id, vector, model_name, timestamp)
                                    VALUES (?, ?, ?, ?, ?)
                                    """,
                                    (vector_id, memory_id, vector_blob, model_name, timestamp)
                                )
                                
                                repair_report["operations"].append({
                                    "type": "fix_missing_vector",
                                    "memory_id": memory_id,
                                    "status": "success"
                                })
                                repair_report["success_count"] += 1
                                
                    except Exception as e:
                        logger.error(f"ä¿®å¤ç¼ºå¤±å‘é‡å¤±è´¥ {memory_id}: {e}")
                        repair_report["operations"].append({
                            "type": "fix_missing_vector",
                            "memory_id": memory_id,
                            "status": "error",
                            "error": str(e)
                        })
                        repair_report["error_count"] += 1
            
            # åˆ é™¤å­¤ç«‹å‘é‡
            if repair_options.get("remove_orphaned_vectors", False) and consistency_report["orphaned_vectors"]:
                logger.info("å¼€å§‹åˆ é™¤å­¤ç«‹å‘é‡...")
                for orphaned in consistency_report["orphaned_vectors"]:
                    try:
                        vector_id = orphaned["vector_id"]
                        
                        self.db_manager.execute_query(
                            "DELETE FROM memory_vectors WHERE id = ?",
                            (vector_id,)
                        )
                        
                        repair_report["operations"].append({
                            "type": "remove_orphaned_vector",
                            "vector_id": vector_id,
                            "status": "success"
                        })
                        repair_report["success_count"] += 1
                        
                    except Exception as e:
                        logger.error(f"åˆ é™¤å­¤ç«‹å‘é‡å¤±è´¥ {vector_id}: {e}")
                        repair_report["operations"].append({
                            "type": "remove_orphaned_vector",
                            "vector_id": vector_id,
                            "status": "error",
                            "error": str(e)
                        })
                        repair_report["error_count"] += 1
            
            # é‡å»ºFAISSç´¢å¼•
            if repair_options.get("rebuild_faiss", False):
                logger.info("å¼€å§‹é‡å»ºFAISSç´¢å¼•...")
                try:
                    # è·å–æ‰€æœ‰å‘é‡æ•°æ®
                    vectors_data = self.db_manager.query(
                        """
                        SELECT memory_id, vector FROM memory_vectors
                        ORDER BY timestamp
                        """
                    )
                    
                    if vectors_data and self.vector_index:
                        # æ¸…ç©ºå½“å‰ç´¢å¼•
                        self.vector_index.clear()
                        
                        # æ‰¹é‡æ·»åŠ å‘é‡
                        memory_ids = []
                        vectors = []
                        
                        for row in vectors_data:
                            memory_id = row[0]
                            vector_blob = row[1]
                            
                            try:
                                vector = np.frombuffer(vector_blob, dtype=np.float32)
                                memory_ids.append(memory_id)
                                vectors.append(vector)
                            except Exception as e:
                                logger.warning(f"è§£æå‘é‡å¤±è´¥ {memory_id}: {e}")
                        
                        if vectors:
                            vectors_array = np.array(vectors)
                            success = self.vector_index.add_vectors(
                                vectors=vectors_array,
                                ids=memory_ids
                            )
                            
                            if success:
                                self.vector_index.save_index()
                                repair_report["operations"].append({
                                    "type": "rebuild_faiss",
                                    "vectors_count": len(vectors),
                                    "status": "success"
                                })
                                repair_report["success_count"] += 1
                            else:
                                raise Exception("FAISSç´¢å¼•æ·»åŠ å¤±è´¥")
                
                except Exception as e:
                    logger.error(f"é‡å»ºFAISSç´¢å¼•å¤±è´¥: {e}")
                    repair_report["operations"].append({
                        "type": "rebuild_faiss",
                        "status": "error",
                        "error": str(e)
                    })
                    repair_report["error_count"] += 1
            
            # ç¡®å®šæœ€ç»ˆçŠ¶æ€
            if repair_report["error_count"] == 0:
                repair_report["status"] = "success"
            elif repair_report["success_count"] > repair_report["error_count"]:
                repair_report["status"] = "partial_success"
            else:
                repair_report["status"] = "failed"
            
            logger.info(f"æ•°æ®ä¸€è‡´æ€§ä¿®å¤å®Œæˆï¼ŒçŠ¶æ€: {repair_report['status']}")
            return repair_report
            
        except Exception as e:
            logger.error(f"æ•°æ®ä¸€è‡´æ€§ä¿®å¤å¤±è´¥: {e}")
            repair_report["status"] = "error"
            repair_report["error"] = str(e)
            return repair_report

    def get_memory_by_id(self, memory_id: str) -> Optional[Dict[str, Any]]:
        """
        æ ¹æ®IDè·å–è®°å¿†
        
        å‚æ•°:
            memory_id: è®°å¿†ID
            
        è¿”å›:
            Optional[Dict[str, Any]]: è®°å¿†æ•°æ®ï¼Œä¸å­˜åœ¨æ—¶è¿”å›None
        """
        try:
            if not self.db_manager:
                logger.error("æ•°æ®åº“ç®¡ç†å™¨æœªåˆå§‹åŒ–")
                return None
            
            result = self.db_manager.query(
                """
                SELECT id as memory_id, content, type as memory_type, role, 
                       session_id, timestamp, weight, metadata
                FROM memories 
                WHERE id = ?
                """,
                (memory_id,)
            )
            
            if result:
                memory = dict(result[0])
                # è§£æmetadata
                if memory.get('metadata'):
                    try:
                        memory['metadata'] = json.loads(memory['metadata'])
                    except:
                        memory['metadata'] = {}
                return memory
            return None
            
        except Exception as e:
            logger.error(f"è·å–è®°å¿†å¤±è´¥: {e}")
            return None
    
    def get_session_memories(self, session_id: str, limit: int = 50) -> List[Dict[str, Any]]:
        """
        è·å–æŒ‡å®šä¼šè¯çš„æ‰€æœ‰è®°å¿†
        
        å‚æ•°:
            session_id: ä¼šè¯ID
            limit: è¿”å›ç»“æœæ•°é‡é™åˆ¶
            
        è¿”å›:
            List[Dict[str, Any]]: ä¼šè¯è®°å¿†åˆ—è¡¨
        """
        try:
            if not self.db_manager:
                logger.error("æ•°æ®åº“ç®¡ç†å™¨æœªåˆå§‹åŒ–")
                return []
            
            results = self.db_manager.query(
                """
                SELECT id as memory_id, content, type as memory_type, role, 
                       session_id, timestamp, weight, metadata
                FROM memories 
                WHERE session_id = ?
                ORDER BY timestamp DESC
                LIMIT ?
                """,
                (session_id, limit)
            )
            
            memories = []
            for row in results:
                memory = dict(row)
                # è§£æmetadata
                if memory.get('metadata'):
                    try:
                        memory['metadata'] = json.loads(memory['metadata'])
                    except:
                        memory['metadata'] = {}
                memories.append(memory)
            
            return memories
            
        except Exception as e:
            logger.error(f"è·å–ä¼šè¯è®°å¿†å¤±è´¥: {e}")
            return []

# æ¨¡å—æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    print("æµ‹è¯•è®°å¿†å­˜å‚¨ç®¡ç†å™¨...")
    
    # ä½¿ç”¨æµ‹è¯•æ•°æ®åº“å’Œç´¢å¼•
    test_db_path = os.path.join("assets", "test_memory.db")
    test_index_path = os.path.join("data", "vectors", "test_memory_index.bin")
    
    # åˆå§‹åŒ–è®°å¿†å­˜å‚¨ç®¡ç†å™¨
    memory_store = MemoryStore(
        db_path=test_db_path,
        index_path=test_index_path
    )
    
    # æµ‹è¯•æ·»åŠ è®°å¿†
    print("\n1. æµ‹è¯•æ·»åŠ è®°å¿†")
    test_memories = [
        "ä»Šå¤©å¤©æ°”çœŸå¥½ï¼Œé˜³å…‰æ˜åªš",
        "æˆ‘å–œæ¬¢ç¼–ç¨‹ï¼Œå°¤å…¶æ˜¯Pythonå’Œäººå·¥æ™ºèƒ½",
        "è®°å¿†ç³»ç»Ÿæ˜¯AIåŠ©æ‰‹çš„é‡è¦ç»„æˆéƒ¨åˆ†",
        "å‘é‡æ•°æ®åº“å¯ä»¥é«˜æ•ˆåœ°è¿›è¡Œç›¸ä¼¼æ€§æœç´¢"
    ]
    
    memory_ids = []
    for i, content in enumerate(test_memories):
        memory_id = memory_store.add_memory(
            content=content,
            source="test",
            importance=0.5 + i * 0.1,
            metadata={"test_index": i}
        )
        if memory_id:
            memory_ids.append(memory_id)
            print(f"æ·»åŠ è®°å¿†æˆåŠŸ: {memory_id}, å†…å®¹: {content}")
    
    # æµ‹è¯•è·å–è®°å¿†
    print("\n2. æµ‹è¯•è·å–è®°å¿†")
    if memory_ids:
        memory = memory_store.get_memory(memory_ids[0])
        if memory:
            print(f"è·å–è®°å¿†æˆåŠŸ:")
            print(f"  ID: {memory['memory_id']}")
            print(f"  å†…å®¹: {memory['content']}")
            print(f"  æ—¶é—´: {memory['timestamp']}")
            print(f"  é‡è¦æ€§: {memory['importance']}")
            print(f"  å…ƒæ•°æ®: {memory['metadata']}")
    
    # æµ‹è¯•æœç´¢ç›¸ä¼¼è®°å¿†
    print("\n3. æµ‹è¯•æœç´¢ç›¸ä¼¼è®°å¿†")
    query = "AIç³»ç»Ÿä¸­çš„è®°å¿†åŠŸèƒ½"
    similar_memories = memory_store.search_similar(query, limit=3)
    
    print(f"æŸ¥è¯¢: {query}")
    print(f"æ‰¾åˆ° {len(similar_memories)} æ¡ç›¸ä¼¼è®°å¿†:")
    
    for i, memory in enumerate(similar_memories):
        print(f"\nç»“æœ {i+1}:")
        print(f"  ID: {memory['memory_id']}")
        print(f"  å†…å®¹: {memory['content']}")
        print(f"  ç›¸ä¼¼åº¦: {memory['similarity']:.4f}")
        print(f"  é‡è¦æ€§: {memory['importance']}")
    
    # æµ‹è¯•æ·»åŠ å…³è”
    print("\n4. æµ‹è¯•æ·»åŠ å…³è”")
    if len(memory_ids) >= 2:
        success = memory_store.add_association(
            source_id=memory_ids[0],
            target_id=memory_ids[1],
            association_type="related",
            strength=0.8
        )
        print(f"æ·»åŠ å…³è”: {'æˆåŠŸ' if success else 'å¤±è´¥'}")
        
        # è·å–å…³è”è®°å¿†
        associations = memory_store.get_associated_memories(memory_ids[0])
        print(f"è·å–å…³è”è®°å¿†: {len(associations)} æ¡")
        
        for i, assoc in enumerate(associations):
            print(f"\nå…³è” {i+1}:")
            print(f"  å…³è”ID: {assoc['association_id']}")
            print(f"  ç›®æ ‡ID: {assoc['target_id']}")
            print(f"  å†…å®¹: {assoc['content']}")
            print(f"  å…³è”ç±»å‹: {assoc['association_type']}")
            print(f"  å¼ºåº¦: {assoc['strength']}")
    
    # æµ‹è¯•è·å–æœ€è¿‘è®°å¿†
    print("\n5. æµ‹è¯•è·å–æœ€è¿‘è®°å¿†")
    recent_memories = memory_store.get_recent_memories(limit=5)
    print(f"è·å–æœ€è¿‘ {len(recent_memories)} æ¡è®°å¿†:")
    
    for i, memory in enumerate(recent_memories):
        print(f"\nè®°å¿† {i+1}:")
        print(f"  ID: {memory['memory_id']}")
        print(f"  å†…å®¹: {memory['content']}")
        print(f"  æ—¶é—´: {memory['timestamp']}")
    
    # å…³é—­è®°å¿†å­˜å‚¨ç®¡ç†å™¨
    memory_store.close()
    print("\næµ‹è¯•å®Œæˆï¼Œè®°å¿†å­˜å‚¨ç®¡ç†å™¨å·²å…³é—­")
